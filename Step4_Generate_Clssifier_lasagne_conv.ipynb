{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from __future__ import print_function\n",
    "import gzip\n",
    "import itertools\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 600\n",
    "NUM_HIDDEN_UNITS = 512\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_iter_functions(dataset, output_layer,\n",
    "                          X_tensor_type=T.matrix,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          learning_rate=LEARNING_RATE, momentum=MOMENTUM):\n",
    "    \"\"\"Create functions for training, validation and testing to iterate one\n",
    "       epoch.\n",
    "    \"\"\"\n",
    "    batch_index = T.iscalar('batch_index')\n",
    "    X_batch = X_tensor_type('x')\n",
    "    y_batch = T.ivector('y')\n",
    "    batch_slice = slice(batch_index * batch_size,\n",
    "                        (batch_index + 1) * batch_size)\n",
    "\n",
    "    objective = lasagne.objectives.Objective(output_layer,\n",
    "        loss_function=lasagne.objectives.categorical_crossentropy)\n",
    "\n",
    "    loss_train = objective.get_loss(X_batch, target=y_batch)\n",
    "    loss_eval = objective.get_loss(X_batch, target=y_batch,\n",
    "                                   deterministic=True)\n",
    "\n",
    "    pred = T.argmax(\n",
    "        lasagne.layers.get_output(output_layer, X_batch, deterministic=True),\n",
    "        axis=1)\n",
    "    accuracy = T.mean(T.eq(pred, y_batch), dtype=theano.config.floatX)\n",
    "\n",
    "    all_params = lasagne.layers.get_all_params(output_layer)\n",
    "    updates = lasagne.updates.nesterov_momentum(\n",
    "        loss_train, all_params, learning_rate, momentum)\n",
    "\n",
    "    iter_train = theano.function(\n",
    "        [batch_index], loss_train,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            X_batch: dataset['X_train'][batch_slice],\n",
    "            y_batch: dataset['y_train'][batch_slice],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    iter_valid = theano.function(\n",
    "        [batch_index], [loss_eval, accuracy],\n",
    "        givens={\n",
    "            X_batch: dataset['X_valid'][batch_slice],\n",
    "            y_batch: dataset['y_valid'][batch_slice],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    iter_test = theano.function(\n",
    "        [batch_index], [loss_eval, accuracy],\n",
    "        givens={\n",
    "            X_batch: dataset['X_test'][batch_slice],\n",
    "            y_batch: dataset['y_test'][batch_slice],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        train=iter_train,\n",
    "        valid=iter_valid,\n",
    "        test=iter_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(iter_funcs, dataset, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Train the model with `dataset` with mini-batch training. Each\n",
    "       mini-batch has `batch_size` recordings.\n",
    "    \"\"\"\n",
    "    num_batches_train = dataset['num_examples_train'] // batch_size\n",
    "    num_batches_valid = dataset['num_examples_valid'] // batch_size\n",
    "\n",
    "    for epoch in itertools.count(1):\n",
    "        batch_train_losses = []\n",
    "        for b in range(num_batches_train):\n",
    "            batch_train_loss = iter_funcs['train'](b)\n",
    "            batch_train_losses.append(batch_train_loss)\n",
    "\n",
    "        avg_train_loss = np.mean(batch_train_losses)\n",
    "\n",
    "        batch_valid_losses = []\n",
    "        batch_valid_accuracies = []\n",
    "        for b in range(num_batches_valid):\n",
    "            batch_valid_loss, batch_valid_accuracy = iter_funcs['valid'](b)\n",
    "            batch_valid_losses.append(batch_valid_loss)\n",
    "            batch_valid_accuracies.append(batch_valid_accuracy)\n",
    "\n",
    "        avg_valid_loss = np.mean(batch_valid_losses)\n",
    "        avg_valid_accuracy = np.mean(batch_valid_accuracies)\n",
    "\n",
    "        yield {\n",
    "            'number': epoch,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'valid_loss': avg_valid_loss,\n",
    "            'valid_accuracy': avg_valid_accuracy,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(features, labels):\n",
    "    \"\"\"Get data with labels, split into training, validation and test set.\"\"\"\n",
    "    X_train = features[:4000]\n",
    "    y_train = labels[:4000]\n",
    "    X_valid = features[4000:5000]\n",
    "    y_valid = labels[4000:5000]\n",
    "    X_test = features[5000:]\n",
    "    y_test = labels[5000:]\n",
    "\n",
    "    # reshape for convolutions\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, 28, 28))\n",
    "    X_valid = X_valid.reshape((X_valid.shape[0], 1, 28, 28))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, 28, 28))\n",
    "\n",
    "    return dict(\n",
    "        X_train=theano.shared(lasagne.utils.floatX(X_train)),\n",
    "        y_train=T.cast(theano.shared(y_train), 'int32'),\n",
    "        X_valid=theano.shared(lasagne.utils.floatX(X_valid)),\n",
    "        y_valid=T.cast(theano.shared(y_valid), 'int32'),\n",
    "        X_test=theano.shared(lasagne.utils.floatX(X_test)),\n",
    "        y_test=T.cast(theano.shared(y_test), 'int32'),\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_height=X_train.shape[2],\n",
    "        input_width=X_train.shape[3],\n",
    "        output_dim=9,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale(X, eps = 0.001):\n",
    "    # scale the data points s.t the columns of the feature space\n",
    "    # (i.e the predictors) are within the range [0, 1]\n",
    "    return (X - np.min(X, axis = 0)) / (np.max(X, axis = 0) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_width, input_height, output_dim,\n",
    "                batch_size=BATCH_SIZE):\n",
    "    l_in = lasagne.layers.InputLayer(\n",
    "        shape=(batch_size, 1, input_width, input_height),\n",
    "        )\n",
    "\n",
    "    l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "        l_in,\n",
    "        num_filters=32,\n",
    "        filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform(),\n",
    "        )\n",
    "    l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))\n",
    "\n",
    "    l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "        l_pool1,\n",
    "        num_filters=32,\n",
    "        filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform(),\n",
    "        )\n",
    "    l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))\n",
    "\n",
    "    l_hidden1 = lasagne.layers.DenseLayer(\n",
    "        l_pool2,\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform(),\n",
    "        )\n",
    "\n",
    "    l_hidden1_dropout = lasagne.layers.DropoutLayer(l_hidden1, p=0.5)\n",
    "\n",
    "    l_hidden2 = lasagne.layers.DenseLayer(\n",
    "        l_hidden1_dropout,\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        )\n",
    "    l_hidden2_dropout = lasagne.layers.DropoutLayer(l_hidden2, p=0.5)\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        l_hidden1_dropout,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        W=lasagne.init.GlorotUniform(),\n",
    "        )\n",
    "\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 15.613s\n",
      "  training loss:\t\t2.177750\n",
      "  validation loss:\t\t2.133109\n",
      "  validation accuracy:\t\t23.83 %%\n",
      "Epoch 2 of 500 took 14.688s\n",
      "  training loss:\t\t2.095396\n",
      "  validation loss:\t\t1.981853\n",
      "  validation accuracy:\t\t56.00 %%\n",
      "Epoch 3 of 500 took 15.201s\n",
      "  training loss:\t\t1.883777\n",
      "  validation loss:\t\t1.566939\n",
      "  validation accuracy:\t\t78.17 %%\n",
      "Epoch 4 of 500 took 15.075s\n",
      "  training loss:\t\t1.387538\n",
      "  validation loss:\t\t0.876188\n",
      "  validation accuracy:\t\t78.67 %%\n",
      "Epoch 5 of 500 took 14.715s\n",
      "  training loss:\t\t0.839850\n",
      "  validation loss:\t\t0.568517\n",
      "  validation accuracy:\t\t87.33 %%\n",
      "Epoch 6 of 500 took 14.691s\n",
      "  training loss:\t\t0.602313\n",
      "  validation loss:\t\t0.513653\n",
      "  validation accuracy:\t\t89.50 %%\n",
      "Epoch 7 of 500 took 14.697s\n",
      "  training loss:\t\t0.512030\n",
      "  validation loss:\t\t0.492230\n",
      "  validation accuracy:\t\t89.33 %%\n",
      "Epoch 8 of 500 took 15.350s\n",
      "  training loss:\t\t0.454129\n",
      "  validation loss:\t\t0.468695\n",
      "  validation accuracy:\t\t89.50 %%\n",
      "Epoch 9 of 500 took 15.303s\n",
      "  training loss:\t\t0.428433\n",
      "  validation loss:\t\t0.447614\n",
      "  validation accuracy:\t\t89.50 %%\n",
      "Epoch 10 of 500 took 14.905s\n",
      "  training loss:\t\t0.402833\n",
      "  validation loss:\t\t0.434295\n",
      "  validation accuracy:\t\t89.83 %%\n",
      "Epoch 11 of 500 took 15.224s\n",
      "  training loss:\t\t0.378005\n",
      "  validation loss:\t\t0.424520\n",
      "  validation accuracy:\t\t89.83 %%\n",
      "Epoch 12 of 500 took 14.693s\n",
      "  training loss:\t\t0.369960\n",
      "  validation loss:\t\t0.416603\n",
      "  validation accuracy:\t\t90.00 %%\n",
      "Epoch 13 of 500 took 17.084s\n",
      "  training loss:\t\t0.356410\n",
      "  validation loss:\t\t0.409425\n",
      "  validation accuracy:\t\t90.17 %%\n",
      "Epoch 14 of 500 took 14.968s\n",
      "  training loss:\t\t0.346408\n",
      "  validation loss:\t\t0.406320\n",
      "  validation accuracy:\t\t90.17 %%\n",
      "Epoch 15 of 500 took 15.898s\n",
      "  training loss:\t\t0.337717\n",
      "  validation loss:\t\t0.402067\n",
      "  validation accuracy:\t\t90.17 %%\n",
      "Epoch 16 of 500 took 15.192s\n",
      "  training loss:\t\t0.333834\n",
      "  validation loss:\t\t0.396856\n",
      "  validation accuracy:\t\t90.17 %%\n",
      "Epoch 17 of 500 took 14.736s\n",
      "  training loss:\t\t0.326766\n",
      "  validation loss:\t\t0.388010\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 18 of 500 took 15.097s\n",
      "  training loss:\t\t0.322106\n",
      "  validation loss:\t\t0.384234\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 19 of 500 took 15.214s\n",
      "  training loss:\t\t0.314068\n",
      "  validation loss:\t\t0.382075\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 20 of 500 took 15.329s\n",
      "  training loss:\t\t0.309595\n",
      "  validation loss:\t\t0.382379\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 21 of 500 took 15.488s\n",
      "  training loss:\t\t0.303682\n",
      "  validation loss:\t\t0.375399\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 22 of 500 took 15.496s\n",
      "  training loss:\t\t0.303888\n",
      "  validation loss:\t\t0.372344\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 23 of 500 took 15.790s\n",
      "  training loss:\t\t0.292383\n",
      "  validation loss:\t\t0.374481\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 24 of 500 took 14.619s\n",
      "  training loss:\t\t0.283198\n",
      "  validation loss:\t\t0.373607\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 25 of 500 took 15.179s\n",
      "  training loss:\t\t0.295503\n",
      "  validation loss:\t\t0.376863\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 26 of 500 took 15.641s\n",
      "  training loss:\t\t0.287795\n",
      "  validation loss:\t\t0.370284\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 27 of 500 took 15.131s\n",
      "  training loss:\t\t0.278563\n",
      "  validation loss:\t\t0.371731\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 28 of 500 took 15.422s\n",
      "  training loss:\t\t0.271697\n",
      "  validation loss:\t\t0.369923\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 29 of 500 took 15.226s\n",
      "  training loss:\t\t0.273716\n",
      "  validation loss:\t\t0.368948\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 30 of 500 took 14.820s\n",
      "  training loss:\t\t0.275672\n",
      "  validation loss:\t\t0.368826\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 31 of 500 took 14.914s\n",
      "  training loss:\t\t0.275256\n",
      "  validation loss:\t\t0.364847\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 32 of 500 took 14.575s\n",
      "  training loss:\t\t0.270180\n",
      "  validation loss:\t\t0.363739\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 33 of 500 took 15.052s\n",
      "  training loss:\t\t0.266817\n",
      "  validation loss:\t\t0.366908\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 34 of 500 took 14.782s\n",
      "  training loss:\t\t0.260481\n",
      "  validation loss:\t\t0.364354\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 35 of 500 took 15.022s\n",
      "  training loss:\t\t0.258571\n",
      "  validation loss:\t\t0.368773\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 36 of 500 took 14.913s\n",
      "  training loss:\t\t0.252644\n",
      "  validation loss:\t\t0.364137\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 37 of 500 took 15.179s\n",
      "  training loss:\t\t0.245260\n",
      "  validation loss:\t\t0.362956\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 38 of 500 took 15.192s\n",
      "  training loss:\t\t0.249372\n",
      "  validation loss:\t\t0.365823\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 39 of 500 took 14.804s\n",
      "  training loss:\t\t0.249229\n",
      "  validation loss:\t\t0.370435\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 40 of 500 took 14.738s\n",
      "  training loss:\t\t0.243195\n",
      "  validation loss:\t\t0.365142\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 41 of 500 took 14.306s\n",
      "  training loss:\t\t0.249559\n",
      "  validation loss:\t\t0.367660\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 42 of 500 took 14.643s\n",
      "  training loss:\t\t0.236356\n",
      "  validation loss:\t\t0.364293\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 43 of 500 took 14.475s\n",
      "  training loss:\t\t0.242250\n",
      "  validation loss:\t\t0.364806\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 44 of 500 took 14.490s\n",
      "  training loss:\t\t0.235097\n",
      "  validation loss:\t\t0.366223\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 45 of 500 took 14.477s\n",
      "  training loss:\t\t0.238587\n",
      "  validation loss:\t\t0.363071\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 46 of 500 took 14.323s\n",
      "  training loss:\t\t0.237356\n",
      "  validation loss:\t\t0.368358\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 47 of 500 took 14.438s\n",
      "  training loss:\t\t0.230697\n",
      "  validation loss:\t\t0.369924\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 48 of 500 took 14.526s\n",
      "  training loss:\t\t0.229979\n",
      "  validation loss:\t\t0.367269\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 49 of 500 took 14.246s\n",
      "  training loss:\t\t0.228087\n",
      "  validation loss:\t\t0.367388\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 50 of 500 took 14.453s\n",
      "  training loss:\t\t0.221999\n",
      "  validation loss:\t\t0.367567\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 51 of 500 took 14.386s\n",
      "  training loss:\t\t0.222880\n",
      "  validation loss:\t\t0.365661\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 52 of 500 took 14.242s\n",
      "  training loss:\t\t0.222771\n",
      "  validation loss:\t\t0.366126\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 53 of 500 took 14.527s\n",
      "  training loss:\t\t0.227040\n",
      "  validation loss:\t\t0.369278\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 54 of 500 took 14.355s\n",
      "  training loss:\t\t0.221592\n",
      "  validation loss:\t\t0.371336\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 55 of 500 took 14.453s\n",
      "  training loss:\t\t0.217344\n",
      "  validation loss:\t\t0.371521\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 56 of 500 took 14.734s\n",
      "  training loss:\t\t0.211970\n",
      "  validation loss:\t\t0.366968\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 57 of 500 took 14.347s\n",
      "  training loss:\t\t0.217570\n",
      "  validation loss:\t\t0.373738\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 58 of 500 took 14.444s\n",
      "  training loss:\t\t0.213430\n",
      "  validation loss:\t\t0.376435\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 59 of 500 took 14.504s\n",
      "  training loss:\t\t0.218060\n",
      "  validation loss:\t\t0.378400\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 60 of 500 took 14.608s\n",
      "  training loss:\t\t0.216176\n",
      "  validation loss:\t\t0.373628\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 61 of 500 took 14.435s\n",
      "  training loss:\t\t0.208065\n",
      "  validation loss:\t\t0.373394\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 62 of 500 took 14.463s\n",
      "  training loss:\t\t0.210697\n",
      "  validation loss:\t\t0.377599\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 63 of 500 took 14.577s\n",
      "  training loss:\t\t0.203661\n",
      "  validation loss:\t\t0.379673\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 64 of 500 took 14.474s\n",
      "  training loss:\t\t0.204591\n",
      "  validation loss:\t\t0.380239\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 65 of 500 took 14.412s\n",
      "  training loss:\t\t0.202028\n",
      "  validation loss:\t\t0.383370\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 66 of 500 took 14.446s\n",
      "  training loss:\t\t0.204072\n",
      "  validation loss:\t\t0.378727\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 67 of 500 took 14.504s\n",
      "  training loss:\t\t0.203826\n",
      "  validation loss:\t\t0.380292\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 68 of 500 took 14.491s\n",
      "  training loss:\t\t0.206487\n",
      "  validation loss:\t\t0.383391\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 69 of 500 took 14.448s\n",
      "  training loss:\t\t0.199048\n",
      "  validation loss:\t\t0.385323\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 70 of 500 took 14.514s\n",
      "  training loss:\t\t0.201380\n",
      "  validation loss:\t\t0.378976\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 71 of 500 took 14.329s\n",
      "  training loss:\t\t0.195748\n",
      "  validation loss:\t\t0.381451\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 72 of 500 took 14.603s\n",
      "  training loss:\t\t0.202880\n",
      "  validation loss:\t\t0.387451\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 73 of 500 took 14.739s\n",
      "  training loss:\t\t0.196753\n",
      "  validation loss:\t\t0.388462\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 74 of 500 took 14.245s\n",
      "  training loss:\t\t0.195288\n",
      "  validation loss:\t\t0.387169\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 75 of 500 took 14.385s\n",
      "  training loss:\t\t0.190307\n",
      "  validation loss:\t\t0.386304\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 76 of 500 took 14.194s\n",
      "  training loss:\t\t0.189408\n",
      "  validation loss:\t\t0.388570\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 77 of 500 took 14.375s\n",
      "  training loss:\t\t0.188332\n",
      "  validation loss:\t\t0.392707\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 78 of 500 took 14.192s\n",
      "  training loss:\t\t0.188272\n",
      "  validation loss:\t\t0.393336\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 79 of 500 took 14.416s\n",
      "  training loss:\t\t0.192628\n",
      "  validation loss:\t\t0.393465\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 80 of 500 took 14.077s\n",
      "  training loss:\t\t0.191901\n",
      "  validation loss:\t\t0.391513\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 81 of 500 took 14.399s\n",
      "  training loss:\t\t0.185679\n",
      "  validation loss:\t\t0.398074\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 82 of 500 took 14.465s\n",
      "  training loss:\t\t0.193831\n",
      "  validation loss:\t\t0.401746\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 83 of 500 took 14.269s\n",
      "  training loss:\t\t0.189201\n",
      "  validation loss:\t\t0.397030\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 84 of 500 took 14.492s\n",
      "  training loss:\t\t0.184385\n",
      "  validation loss:\t\t0.398592\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 85 of 500 took 14.311s\n",
      "  training loss:\t\t0.181810\n",
      "  validation loss:\t\t0.401389\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 86 of 500 took 14.422s\n",
      "  training loss:\t\t0.184749\n",
      "  validation loss:\t\t0.398298\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 87 of 500 took 14.234s\n",
      "  training loss:\t\t0.182146\n",
      "  validation loss:\t\t0.401007\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 88 of 500 took 14.363s\n",
      "  training loss:\t\t0.183868\n",
      "  validation loss:\t\t0.403039\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 89 of 500 took 14.840s\n",
      "  training loss:\t\t0.175790\n",
      "  validation loss:\t\t0.407837\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 90 of 500 took 15.534s\n",
      "  training loss:\t\t0.181957\n",
      "  validation loss:\t\t0.407746\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 91 of 500 took 15.436s\n",
      "  training loss:\t\t0.181076\n",
      "  validation loss:\t\t0.402491\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 92 of 500 took 16.242s\n",
      "  training loss:\t\t0.175703\n",
      "  validation loss:\t\t0.408985\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 93 of 500 took 15.472s\n",
      "  training loss:\t\t0.174799\n",
      "  validation loss:\t\t0.413510\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 94 of 500 took 14.952s\n",
      "  training loss:\t\t0.173826\n",
      "  validation loss:\t\t0.407280\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 95 of 500 took 14.832s\n",
      "  training loss:\t\t0.172744\n",
      "  validation loss:\t\t0.412258\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 96 of 500 took 14.412s\n",
      "  training loss:\t\t0.176666\n",
      "  validation loss:\t\t0.413488\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 97 of 500 took 15.547s\n",
      "  training loss:\t\t0.169568\n",
      "  validation loss:\t\t0.414410\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 98 of 500 took 14.833s\n",
      "  training loss:\t\t0.175358\n",
      "  validation loss:\t\t0.413425\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 99 of 500 took 15.445s\n",
      "  training loss:\t\t0.166353\n",
      "  validation loss:\t\t0.408739\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 100 of 500 took 15.181s\n",
      "  training loss:\t\t0.168960\n",
      "  validation loss:\t\t0.407558\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 101 of 500 took 14.981s\n",
      "  training loss:\t\t0.170446\n",
      "  validation loss:\t\t0.408623\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 102 of 500 took 18.653s\n",
      "  training loss:\t\t0.174430\n",
      "  validation loss:\t\t0.409316\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 103 of 500 took 16.480s\n",
      "  training loss:\t\t0.168815\n",
      "  validation loss:\t\t0.411580\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 104 of 500 took 27.761s\n",
      "  training loss:\t\t0.165797\n",
      "  validation loss:\t\t0.421502\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 105 of 500 took 16.782s\n",
      "  training loss:\t\t0.169146\n",
      "  validation loss:\t\t0.419542\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 106 of 500 took 14.894s\n",
      "  training loss:\t\t0.161556\n",
      "  validation loss:\t\t0.421930\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 107 of 500 took 15.151s\n",
      "  training loss:\t\t0.162867\n",
      "  validation loss:\t\t0.423728\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 108 of 500 took 15.470s\n",
      "  training loss:\t\t0.162167\n",
      "  validation loss:\t\t0.421983\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 109 of 500 took 16.024s\n",
      "  training loss:\t\t0.160314\n",
      "  validation loss:\t\t0.425695\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 110 of 500 took 16.288s\n",
      "  training loss:\t\t0.159228\n",
      "  validation loss:\t\t0.427893\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 111 of 500 took 16.408s\n",
      "  training loss:\t\t0.155178\n",
      "  validation loss:\t\t0.432354\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 112 of 500 took 16.417s\n",
      "  training loss:\t\t0.156494\n",
      "  validation loss:\t\t0.433515\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 113 of 500 took 16.495s\n",
      "  training loss:\t\t0.159907\n",
      "  validation loss:\t\t0.434703\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 114 of 500 took 16.797s\n",
      "  training loss:\t\t0.150653\n",
      "  validation loss:\t\t0.432906\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 115 of 500 took 16.676s\n",
      "  training loss:\t\t0.159441\n",
      "  validation loss:\t\t0.435184\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 116 of 500 took 17.315s\n",
      "  training loss:\t\t0.160398\n",
      "  validation loss:\t\t0.435595\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 117 of 500 took 16.233s\n",
      "  training loss:\t\t0.153771\n",
      "  validation loss:\t\t0.437586\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 118 of 500 took 15.795s\n",
      "  training loss:\t\t0.158236\n",
      "  validation loss:\t\t0.436433\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 119 of 500 took 16.103s\n",
      "  training loss:\t\t0.154975\n",
      "  validation loss:\t\t0.432415\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 120 of 500 took 16.023s\n",
      "  training loss:\t\t0.154486\n",
      "  validation loss:\t\t0.437654\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 121 of 500 took 17.302s\n",
      "  training loss:\t\t0.149077\n",
      "  validation loss:\t\t0.444680\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 122 of 500 took 16.771s\n",
      "  training loss:\t\t0.153178\n",
      "  validation loss:\t\t0.446251\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 123 of 500 took 16.175s\n",
      "  training loss:\t\t0.154288\n",
      "  validation loss:\t\t0.449923\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 124 of 500 took 15.878s\n",
      "  training loss:\t\t0.149554\n",
      "  validation loss:\t\t0.446513\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 125 of 500 took 15.399s\n",
      "  training loss:\t\t0.153389\n",
      "  validation loss:\t\t0.446481\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 126 of 500 took 17.419s\n",
      "  training loss:\t\t0.148437\n",
      "  validation loss:\t\t0.456960\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 127 of 500 took 18.162s\n",
      "  training loss:\t\t0.151947\n",
      "  validation loss:\t\t0.452593\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 128 of 500 took 16.353s\n",
      "  training loss:\t\t0.150928\n",
      "  validation loss:\t\t0.454113\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 129 of 500 took 16.291s\n",
      "  training loss:\t\t0.144195\n",
      "  validation loss:\t\t0.459542\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 130 of 500 took 16.344s\n",
      "  training loss:\t\t0.141157\n",
      "  validation loss:\t\t0.458799\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 131 of 500 took 15.406s\n",
      "  training loss:\t\t0.147481\n",
      "  validation loss:\t\t0.452605\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 132 of 500 took 15.816s\n",
      "  training loss:\t\t0.144634\n",
      "  validation loss:\t\t0.459809\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 133 of 500 took 15.970s\n",
      "  training loss:\t\t0.142039\n",
      "  validation loss:\t\t0.460758\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 134 of 500 took 15.015s\n",
      "  training loss:\t\t0.146137\n",
      "  validation loss:\t\t0.455384\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 135 of 500 took 14.610s\n",
      "  training loss:\t\t0.143337\n",
      "  validation loss:\t\t0.459841\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 136 of 500 took 14.978s\n",
      "  training loss:\t\t0.148285\n",
      "  validation loss:\t\t0.459557\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 137 of 500 took 15.048s\n",
      "  training loss:\t\t0.148549\n",
      "  validation loss:\t\t0.459750\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 138 of 500 took 15.791s\n",
      "  training loss:\t\t0.144936\n",
      "  validation loss:\t\t0.465768\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 139 of 500 took 15.684s\n",
      "  training loss:\t\t0.143865\n",
      "  validation loss:\t\t0.471050\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 140 of 500 took 15.280s\n",
      "  training loss:\t\t0.141252\n",
      "  validation loss:\t\t0.469085\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 141 of 500 took 15.409s\n",
      "  training loss:\t\t0.143331\n",
      "  validation loss:\t\t0.467828\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 142 of 500 took 15.273s\n",
      "  training loss:\t\t0.134498\n",
      "  validation loss:\t\t0.465824\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 143 of 500 took 14.903s\n",
      "  training loss:\t\t0.141362\n",
      "  validation loss:\t\t0.464670\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 144 of 500 took 14.874s\n",
      "  training loss:\t\t0.147339\n",
      "  validation loss:\t\t0.478099\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 145 of 500 took 15.478s\n",
      "  training loss:\t\t0.143584\n",
      "  validation loss:\t\t0.477112\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 146 of 500 took 14.609s\n",
      "  training loss:\t\t0.137736\n",
      "  validation loss:\t\t0.478563\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 147 of 500 took 14.903s\n",
      "  training loss:\t\t0.139209\n",
      "  validation loss:\t\t0.478120\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 148 of 500 took 15.150s\n",
      "  training loss:\t\t0.136105\n",
      "  validation loss:\t\t0.479191\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 149 of 500 took 14.731s\n",
      "  training loss:\t\t0.140546\n",
      "  validation loss:\t\t0.483204\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 150 of 500 took 15.766s\n",
      "  training loss:\t\t0.141653\n",
      "  validation loss:\t\t0.476993\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 151 of 500 took 15.072s\n",
      "  training loss:\t\t0.137456\n",
      "  validation loss:\t\t0.480364\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 152 of 500 took 14.748s\n",
      "  training loss:\t\t0.131263\n",
      "  validation loss:\t\t0.482288\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 153 of 500 took 14.816s\n",
      "  training loss:\t\t0.131058\n",
      "  validation loss:\t\t0.488948\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 154 of 500 took 15.167s\n",
      "  training loss:\t\t0.130883\n",
      "  validation loss:\t\t0.494727\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 155 of 500 took 14.983s\n",
      "  training loss:\t\t0.133929\n",
      "  validation loss:\t\t0.488320\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 156 of 500 took 15.176s\n",
      "  training loss:\t\t0.135216\n",
      "  validation loss:\t\t0.493261\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 157 of 500 took 14.750s\n",
      "  training loss:\t\t0.143826\n",
      "  validation loss:\t\t0.492206\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 158 of 500 took 15.294s\n",
      "  training loss:\t\t0.135008\n",
      "  validation loss:\t\t0.494195\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 159 of 500 took 14.619s\n",
      "  training loss:\t\t0.127546\n",
      "  validation loss:\t\t0.496936\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 160 of 500 took 15.444s\n",
      "  training loss:\t\t0.136585\n",
      "  validation loss:\t\t0.501333\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 161 of 500 took 14.345s\n",
      "  training loss:\t\t0.128761\n",
      "  validation loss:\t\t0.507959\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 162 of 500 took 14.479s\n",
      "  training loss:\t\t0.136669\n",
      "  validation loss:\t\t0.504009\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 163 of 500 took 13.947s\n",
      "  training loss:\t\t0.129853\n",
      "  validation loss:\t\t0.512156\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 164 of 500 took 14.452s\n",
      "  training loss:\t\t0.130049\n",
      "  validation loss:\t\t0.512953\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 165 of 500 took 14.444s\n",
      "  training loss:\t\t0.132312\n",
      "  validation loss:\t\t0.506902\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 166 of 500 took 14.803s\n",
      "  training loss:\t\t0.133717\n",
      "  validation loss:\t\t0.508417\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 167 of 500 took 15.766s\n",
      "  training loss:\t\t0.124107\n",
      "  validation loss:\t\t0.509180\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 168 of 500 took 15.207s\n",
      "  training loss:\t\t0.128255\n",
      "  validation loss:\t\t0.506481\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 169 of 500 took 14.473s\n",
      "  training loss:\t\t0.132261\n",
      "  validation loss:\t\t0.509595\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 170 of 500 took 14.984s\n",
      "  training loss:\t\t0.126124\n",
      "  validation loss:\t\t0.521365\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 171 of 500 took 15.144s\n",
      "  training loss:\t\t0.126753\n",
      "  validation loss:\t\t0.524316\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 172 of 500 took 14.990s\n",
      "  training loss:\t\t0.125087\n",
      "  validation loss:\t\t0.529015\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 173 of 500 took 14.744s\n",
      "  training loss:\t\t0.113482\n",
      "  validation loss:\t\t0.531826\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 174 of 500 took 15.704s\n",
      "  training loss:\t\t0.124884\n",
      "  validation loss:\t\t0.527857\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 175 of 500 took 15.175s\n",
      "  training loss:\t\t0.126291\n",
      "  validation loss:\t\t0.532693\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 176 of 500 took 15.842s\n",
      "  training loss:\t\t0.129868\n",
      "  validation loss:\t\t0.527977\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 177 of 500 took 15.805s\n",
      "  training loss:\t\t0.128262\n",
      "  validation loss:\t\t0.526694\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 178 of 500 took 14.928s\n",
      "  training loss:\t\t0.124912\n",
      "  validation loss:\t\t0.527936\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 179 of 500 took 14.873s\n",
      "  training loss:\t\t0.127371\n",
      "  validation loss:\t\t0.534447\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 180 of 500 took 14.846s\n",
      "  training loss:\t\t0.121934\n",
      "  validation loss:\t\t0.533962\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 181 of 500 took 14.788s\n",
      "  training loss:\t\t0.126794\n",
      "  validation loss:\t\t0.533907\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 182 of 500 took 14.754s\n",
      "  training loss:\t\t0.122501\n",
      "  validation loss:\t\t0.541166\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 183 of 500 took 14.737s\n",
      "  training loss:\t\t0.125137\n",
      "  validation loss:\t\t0.539387\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 184 of 500 took 14.856s\n",
      "  training loss:\t\t0.118068\n",
      "  validation loss:\t\t0.545043\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 185 of 500 took 14.824s\n",
      "  training loss:\t\t0.120979\n",
      "  validation loss:\t\t0.535691\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 186 of 500 took 14.781s\n",
      "  training loss:\t\t0.120663\n",
      "  validation loss:\t\t0.539806\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 187 of 500 took 14.631s\n",
      "  training loss:\t\t0.117819\n",
      "  validation loss:\t\t0.554044\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 188 of 500 took 14.763s\n",
      "  training loss:\t\t0.118676\n",
      "  validation loss:\t\t0.555621\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 189 of 500 took 14.763s\n",
      "  training loss:\t\t0.119358\n",
      "  validation loss:\t\t0.548570\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 190 of 500 took 14.563s\n",
      "  training loss:\t\t0.119297\n",
      "  validation loss:\t\t0.556941\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 191 of 500 took 14.632s\n",
      "  training loss:\t\t0.120507\n",
      "  validation loss:\t\t0.556401\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 192 of 500 took 14.631s\n",
      "  training loss:\t\t0.120985\n",
      "  validation loss:\t\t0.545861\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 193 of 500 took 14.765s\n",
      "  training loss:\t\t0.115065\n",
      "  validation loss:\t\t0.545550\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 194 of 500 took 14.702s\n",
      "  training loss:\t\t0.116163\n",
      "  validation loss:\t\t0.547671\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 195 of 500 took 14.726s\n",
      "  training loss:\t\t0.116766\n",
      "  validation loss:\t\t0.560208\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 196 of 500 took 14.795s\n",
      "  training loss:\t\t0.119119\n",
      "  validation loss:\t\t0.555340\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 197 of 500 took 14.711s\n",
      "  training loss:\t\t0.120003\n",
      "  validation loss:\t\t0.560090\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 198 of 500 took 14.769s\n",
      "  training loss:\t\t0.117758\n",
      "  validation loss:\t\t0.557067\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 199 of 500 took 14.760s\n",
      "  training loss:\t\t0.113235\n",
      "  validation loss:\t\t0.564881\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 200 of 500 took 14.699s\n",
      "  training loss:\t\t0.120386\n",
      "  validation loss:\t\t0.555466\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 201 of 500 took 14.903s\n",
      "  training loss:\t\t0.117320\n",
      "  validation loss:\t\t0.559811\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 202 of 500 took 14.872s\n",
      "  training loss:\t\t0.111478\n",
      "  validation loss:\t\t0.561491\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 203 of 500 took 14.737s\n",
      "  training loss:\t\t0.120155\n",
      "  validation loss:\t\t0.562093\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 204 of 500 took 14.971s\n",
      "  training loss:\t\t0.114316\n",
      "  validation loss:\t\t0.572226\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 205 of 500 took 14.930s\n",
      "  training loss:\t\t0.112437\n",
      "  validation loss:\t\t0.573243\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 206 of 500 took 14.688s\n",
      "  training loss:\t\t0.109178\n",
      "  validation loss:\t\t0.580225\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 207 of 500 took 14.717s\n",
      "  training loss:\t\t0.113106\n",
      "  validation loss:\t\t0.575681\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 208 of 500 took 14.915s\n",
      "  training loss:\t\t0.113159\n",
      "  validation loss:\t\t0.589049\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 209 of 500 took 14.585s\n",
      "  training loss:\t\t0.122286\n",
      "  validation loss:\t\t0.581935\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 210 of 500 took 14.783s\n",
      "  training loss:\t\t0.111197\n",
      "  validation loss:\t\t0.586150\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 211 of 500 took 14.834s\n",
      "  training loss:\t\t0.112937\n",
      "  validation loss:\t\t0.577965\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 212 of 500 took 14.652s\n",
      "  training loss:\t\t0.114348\n",
      "  validation loss:\t\t0.584674\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 213 of 500 took 14.625s\n",
      "  training loss:\t\t0.112628\n",
      "  validation loss:\t\t0.593963\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 214 of 500 took 14.683s\n",
      "  training loss:\t\t0.111435\n",
      "  validation loss:\t\t0.580241\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 215 of 500 took 14.696s\n",
      "  training loss:\t\t0.115978\n",
      "  validation loss:\t\t0.591061\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 216 of 500 took 14.642s\n",
      "  training loss:\t\t0.110993\n",
      "  validation loss:\t\t0.592987\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 217 of 500 took 14.902s\n",
      "  training loss:\t\t0.114132\n",
      "  validation loss:\t\t0.581435\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 218 of 500 took 14.621s\n",
      "  training loss:\t\t0.112400\n",
      "  validation loss:\t\t0.586059\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 219 of 500 took 14.692s\n",
      "  training loss:\t\t0.111381\n",
      "  validation loss:\t\t0.598241\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 220 of 500 took 14.645s\n",
      "  training loss:\t\t0.112426\n",
      "  validation loss:\t\t0.594687\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 221 of 500 took 15.115s\n",
      "  training loss:\t\t0.111531\n",
      "  validation loss:\t\t0.593162\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 222 of 500 took 14.811s\n",
      "  training loss:\t\t0.106386\n",
      "  validation loss:\t\t0.600984\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 223 of 500 took 14.836s\n",
      "  training loss:\t\t0.107183\n",
      "  validation loss:\t\t0.580081\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 224 of 500 took 14.797s\n",
      "  training loss:\t\t0.110986\n",
      "  validation loss:\t\t0.579280\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 225 of 500 took 14.551s\n",
      "  training loss:\t\t0.112224\n",
      "  validation loss:\t\t0.594417\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 226 of 500 took 13.941s\n",
      "  training loss:\t\t0.109566\n",
      "  validation loss:\t\t0.587630\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 227 of 500 took 13.034s\n",
      "  training loss:\t\t0.107882\n",
      "  validation loss:\t\t0.603864\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 228 of 500 took 14.243s\n",
      "  training loss:\t\t0.107045\n",
      "  validation loss:\t\t0.601551\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 229 of 500 took 13.602s\n",
      "  training loss:\t\t0.105510\n",
      "  validation loss:\t\t0.612799\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 230 of 500 took 13.386s\n",
      "  training loss:\t\t0.106549\n",
      "  validation loss:\t\t0.605818\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 231 of 500 took 14.007s\n",
      "  training loss:\t\t0.110335\n",
      "  validation loss:\t\t0.601665\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 232 of 500 took 14.076s\n",
      "  training loss:\t\t0.105505\n",
      "  validation loss:\t\t0.611842\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 233 of 500 took 13.806s\n",
      "  training loss:\t\t0.105381\n",
      "  validation loss:\t\t0.618299\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 234 of 500 took 12.412s\n",
      "  training loss:\t\t0.109010\n",
      "  validation loss:\t\t0.611825\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 235 of 500 took 12.354s\n",
      "  training loss:\t\t0.105571\n",
      "  validation loss:\t\t0.611804\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 236 of 500 took 12.329s\n",
      "  training loss:\t\t0.103155\n",
      "  validation loss:\t\t0.615433\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 237 of 500 took 12.345s\n",
      "  training loss:\t\t0.108585\n",
      "  validation loss:\t\t0.602054\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 238 of 500 took 12.293s\n",
      "  training loss:\t\t0.104699\n",
      "  validation loss:\t\t0.610816\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 239 of 500 took 12.403s\n",
      "  training loss:\t\t0.103662\n",
      "  validation loss:\t\t0.605425\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 240 of 500 took 12.318s\n",
      "  training loss:\t\t0.106268\n",
      "  validation loss:\t\t0.606347\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 241 of 500 took 12.418s\n",
      "  training loss:\t\t0.100278\n",
      "  validation loss:\t\t0.633885\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 242 of 500 took 12.484s\n",
      "  training loss:\t\t0.100692\n",
      "  validation loss:\t\t0.627332\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 243 of 500 took 12.308s\n",
      "  training loss:\t\t0.098719\n",
      "  validation loss:\t\t0.622937\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 244 of 500 took 12.426s\n",
      "  training loss:\t\t0.105605\n",
      "  validation loss:\t\t0.625794\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 245 of 500 took 12.380s\n",
      "  training loss:\t\t0.103088\n",
      "  validation loss:\t\t0.627891\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 246 of 500 took 12.376s\n",
      "  training loss:\t\t0.102295\n",
      "  validation loss:\t\t0.629854\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 247 of 500 took 12.321s\n",
      "  training loss:\t\t0.102102\n",
      "  validation loss:\t\t0.628917\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 248 of 500 took 12.489s\n",
      "  training loss:\t\t0.102609\n",
      "  validation loss:\t\t0.625423\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 249 of 500 took 12.899s\n",
      "  training loss:\t\t0.104198\n",
      "  validation loss:\t\t0.630360\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 250 of 500 took 12.545s\n",
      "  training loss:\t\t0.100093\n",
      "  validation loss:\t\t0.639631\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 251 of 500 took 12.317s\n",
      "  training loss:\t\t0.096704\n",
      "  validation loss:\t\t0.644271\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 252 of 500 took 12.407s\n",
      "  training loss:\t\t0.108666\n",
      "  validation loss:\t\t0.645178\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 253 of 500 took 12.396s\n",
      "  training loss:\t\t0.105203\n",
      "  validation loss:\t\t0.634858\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 254 of 500 took 12.347s\n",
      "  training loss:\t\t0.100120\n",
      "  validation loss:\t\t0.637206\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 255 of 500 took 12.381s\n",
      "  training loss:\t\t0.100472\n",
      "  validation loss:\t\t0.637959\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 256 of 500 took 12.274s\n",
      "  training loss:\t\t0.100072\n",
      "  validation loss:\t\t0.640083\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 257 of 500 took 12.331s\n",
      "  training loss:\t\t0.100262\n",
      "  validation loss:\t\t0.633745\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 258 of 500 took 12.386s\n",
      "  training loss:\t\t0.102347\n",
      "  validation loss:\t\t0.640954\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 259 of 500 took 12.352s\n",
      "  training loss:\t\t0.099085\n",
      "  validation loss:\t\t0.642375\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 260 of 500 took 12.342s\n",
      "  training loss:\t\t0.101169\n",
      "  validation loss:\t\t0.634409\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 261 of 500 took 12.410s\n",
      "  training loss:\t\t0.096180\n",
      "  validation loss:\t\t0.652349\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 262 of 500 took 12.357s\n",
      "  training loss:\t\t0.105125\n",
      "  validation loss:\t\t0.653134\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 263 of 500 took 12.385s\n",
      "  training loss:\t\t0.103500\n",
      "  validation loss:\t\t0.644474\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 264 of 500 took 12.417s\n",
      "  training loss:\t\t0.102418\n",
      "  validation loss:\t\t0.644781\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 265 of 500 took 12.437s\n",
      "  training loss:\t\t0.093070\n",
      "  validation loss:\t\t0.640124\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 266 of 500 took 12.375s\n",
      "  training loss:\t\t0.102860\n",
      "  validation loss:\t\t0.647325\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 267 of 500 took 12.269s\n",
      "  training loss:\t\t0.101763\n",
      "  validation loss:\t\t0.658480\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 268 of 500 took 12.471s\n",
      "  training loss:\t\t0.096806\n",
      "  validation loss:\t\t0.658981\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 269 of 500 took 12.343s\n",
      "  training loss:\t\t0.102269\n",
      "  validation loss:\t\t0.647423\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 270 of 500 took 12.360s\n",
      "  training loss:\t\t0.099707\n",
      "  validation loss:\t\t0.642752\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 271 of 500 took 12.472s\n",
      "  training loss:\t\t0.097755\n",
      "  validation loss:\t\t0.662319\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 272 of 500 took 12.449s\n",
      "  training loss:\t\t0.101648\n",
      "  validation loss:\t\t0.651045\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 273 of 500 took 12.436s\n",
      "  training loss:\t\t0.095483\n",
      "  validation loss:\t\t0.669857\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 274 of 500 took 12.256s\n",
      "  training loss:\t\t0.095150\n",
      "  validation loss:\t\t0.668686\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 275 of 500 took 12.395s\n",
      "  training loss:\t\t0.099356\n",
      "  validation loss:\t\t0.666917\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 276 of 500 took 12.420s\n",
      "  training loss:\t\t0.097288\n",
      "  validation loss:\t\t0.666680\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 277 of 500 took 12.381s\n",
      "  training loss:\t\t0.099630\n",
      "  validation loss:\t\t0.662731\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 278 of 500 took 12.420s\n",
      "  training loss:\t\t0.098221\n",
      "  validation loss:\t\t0.660151\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 279 of 500 took 12.491s\n",
      "  training loss:\t\t0.097574\n",
      "  validation loss:\t\t0.664540\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 280 of 500 took 12.419s\n",
      "  training loss:\t\t0.099949\n",
      "  validation loss:\t\t0.666254\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 281 of 500 took 12.374s\n",
      "  training loss:\t\t0.093837\n",
      "  validation loss:\t\t0.669410\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 282 of 500 took 12.300s\n",
      "  training loss:\t\t0.093626\n",
      "  validation loss:\t\t0.671147\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 283 of 500 took 12.395s\n",
      "  training loss:\t\t0.102178\n",
      "  validation loss:\t\t0.666845\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 284 of 500 took 12.514s\n",
      "  training loss:\t\t0.098249\n",
      "  validation loss:\t\t0.678743\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 285 of 500 took 12.396s\n",
      "  training loss:\t\t0.099978\n",
      "  validation loss:\t\t0.675452\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 286 of 500 took 12.341s\n",
      "  training loss:\t\t0.093044\n",
      "  validation loss:\t\t0.669849\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 287 of 500 took 12.397s\n",
      "  training loss:\t\t0.097552\n",
      "  validation loss:\t\t0.671858\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 288 of 500 took 12.459s\n",
      "  training loss:\t\t0.097172\n",
      "  validation loss:\t\t0.684241\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 289 of 500 took 12.358s\n",
      "  training loss:\t\t0.096215\n",
      "  validation loss:\t\t0.678797\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 290 of 500 took 12.337s\n",
      "  training loss:\t\t0.093488\n",
      "  validation loss:\t\t0.701771\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 291 of 500 took 12.381s\n",
      "  training loss:\t\t0.095348\n",
      "  validation loss:\t\t0.701641\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 292 of 500 took 12.371s\n",
      "  training loss:\t\t0.094558\n",
      "  validation loss:\t\t0.684190\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 293 of 500 took 12.484s\n",
      "  training loss:\t\t0.093005\n",
      "  validation loss:\t\t0.677868\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 294 of 500 took 12.484s\n",
      "  training loss:\t\t0.095606\n",
      "  validation loss:\t\t0.680155\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 295 of 500 took 12.403s\n",
      "  training loss:\t\t0.095034\n",
      "  validation loss:\t\t0.687531\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 296 of 500 took 12.261s\n",
      "  training loss:\t\t0.098244\n",
      "  validation loss:\t\t0.683986\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 297 of 500 took 12.364s\n",
      "  training loss:\t\t0.087603\n",
      "  validation loss:\t\t0.696754\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 298 of 500 took 12.388s\n",
      "  training loss:\t\t0.089136\n",
      "  validation loss:\t\t0.688638\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 299 of 500 took 12.283s\n",
      "  training loss:\t\t0.093867\n",
      "  validation loss:\t\t0.697654\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 300 of 500 took 12.425s\n",
      "  training loss:\t\t0.098609\n",
      "  validation loss:\t\t0.701240\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 301 of 500 took 12.414s\n",
      "  training loss:\t\t0.088318\n",
      "  validation loss:\t\t0.684114\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 302 of 500 took 12.331s\n",
      "  training loss:\t\t0.091626\n",
      "  validation loss:\t\t0.683841\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 303 of 500 took 12.375s\n",
      "  training loss:\t\t0.095021\n",
      "  validation loss:\t\t0.690057\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 304 of 500 took 12.393s\n",
      "  training loss:\t\t0.098754\n",
      "  validation loss:\t\t0.692027\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 305 of 500 took 12.347s\n",
      "  training loss:\t\t0.091377\n",
      "  validation loss:\t\t0.708635\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 306 of 500 took 12.398s\n",
      "  training loss:\t\t0.092293\n",
      "  validation loss:\t\t0.717227\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 307 of 500 took 12.362s\n",
      "  training loss:\t\t0.090100\n",
      "  validation loss:\t\t0.704884\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 308 of 500 took 12.517s\n",
      "  training loss:\t\t0.092809\n",
      "  validation loss:\t\t0.698376\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 309 of 500 took 12.388s\n",
      "  training loss:\t\t0.095931\n",
      "  validation loss:\t\t0.714035\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 310 of 500 took 12.395s\n",
      "  training loss:\t\t0.092692\n",
      "  validation loss:\t\t0.708661\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 311 of 500 took 12.398s\n",
      "  training loss:\t\t0.092951\n",
      "  validation loss:\t\t0.706986\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 312 of 500 took 12.385s\n",
      "  training loss:\t\t0.097184\n",
      "  validation loss:\t\t0.704449\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 313 of 500 took 12.426s\n",
      "  training loss:\t\t0.094573\n",
      "  validation loss:\t\t0.709134\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 314 of 500 took 12.370s\n",
      "  training loss:\t\t0.093677\n",
      "  validation loss:\t\t0.689462\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 315 of 500 took 12.326s\n",
      "  training loss:\t\t0.092826\n",
      "  validation loss:\t\t0.703924\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 316 of 500 took 12.390s\n",
      "  training loss:\t\t0.091875\n",
      "  validation loss:\t\t0.711149\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 317 of 500 took 12.419s\n",
      "  training loss:\t\t0.092476\n",
      "  validation loss:\t\t0.709337\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 318 of 500 took 12.404s\n",
      "  training loss:\t\t0.092442\n",
      "  validation loss:\t\t0.716917\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 319 of 500 took 12.391s\n",
      "  training loss:\t\t0.096853\n",
      "  validation loss:\t\t0.724688\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 320 of 500 took 12.366s\n",
      "  training loss:\t\t0.096380\n",
      "  validation loss:\t\t0.710642\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 321 of 500 took 12.365s\n",
      "  training loss:\t\t0.093212\n",
      "  validation loss:\t\t0.714636\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 322 of 500 took 12.343s\n",
      "  training loss:\t\t0.085309\n",
      "  validation loss:\t\t0.710281\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 323 of 500 took 12.324s\n",
      "  training loss:\t\t0.092953\n",
      "  validation loss:\t\t0.712018\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 324 of 500 took 12.435s\n",
      "  training loss:\t\t0.092673\n",
      "  validation loss:\t\t0.733078\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 325 of 500 took 12.410s\n",
      "  training loss:\t\t0.091195\n",
      "  validation loss:\t\t0.728284\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 326 of 500 took 12.368s\n",
      "  training loss:\t\t0.085421\n",
      "  validation loss:\t\t0.727450\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 327 of 500 took 12.619s\n",
      "  training loss:\t\t0.091355\n",
      "  validation loss:\t\t0.713144\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 328 of 500 took 16.455s\n",
      "  training loss:\t\t0.086183\n",
      "  validation loss:\t\t0.739553\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 329 of 500 took 15.862s\n",
      "  training loss:\t\t0.092945\n",
      "  validation loss:\t\t0.722473\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 330 of 500 took 15.249s\n",
      "  training loss:\t\t0.087642\n",
      "  validation loss:\t\t0.716584\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 331 of 500 took 16.176s\n",
      "  training loss:\t\t0.091751\n",
      "  validation loss:\t\t0.728009\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 332 of 500 took 14.440s\n",
      "  training loss:\t\t0.088144\n",
      "  validation loss:\t\t0.724202\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 333 of 500 took 14.872s\n",
      "  training loss:\t\t0.089360\n",
      "  validation loss:\t\t0.723507\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 334 of 500 took 15.144s\n",
      "  training loss:\t\t0.090591\n",
      "  validation loss:\t\t0.731619\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 335 of 500 took 14.519s\n",
      "  training loss:\t\t0.088721\n",
      "  validation loss:\t\t0.735458\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 336 of 500 took 14.595s\n",
      "  training loss:\t\t0.090685\n",
      "  validation loss:\t\t0.724862\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 337 of 500 took 14.500s\n",
      "  training loss:\t\t0.087382\n",
      "  validation loss:\t\t0.733183\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 338 of 500 took 14.740s\n",
      "  training loss:\t\t0.088040\n",
      "  validation loss:\t\t0.745586\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 339 of 500 took 15.064s\n",
      "  training loss:\t\t0.088510\n",
      "  validation loss:\t\t0.747546\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 340 of 500 took 15.718s\n",
      "  training loss:\t\t0.085188\n",
      "  validation loss:\t\t0.734522\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 341 of 500 took 15.552s\n",
      "  training loss:\t\t0.084454\n",
      "  validation loss:\t\t0.746104\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 342 of 500 took 15.235s\n",
      "  training loss:\t\t0.084039\n",
      "  validation loss:\t\t0.749529\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 343 of 500 took 15.641s\n",
      "  training loss:\t\t0.090936\n",
      "  validation loss:\t\t0.756142\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 344 of 500 took 14.483s\n",
      "  training loss:\t\t0.089929\n",
      "  validation loss:\t\t0.746196\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 345 of 500 took 14.607s\n",
      "  training loss:\t\t0.090182\n",
      "  validation loss:\t\t0.742242\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 346 of 500 took 14.473s\n",
      "  training loss:\t\t0.087123\n",
      "  validation loss:\t\t0.753327\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 347 of 500 took 15.452s\n",
      "  training loss:\t\t0.088786\n",
      "  validation loss:\t\t0.753992\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 348 of 500 took 17.435s\n",
      "  training loss:\t\t0.088779\n",
      "  validation loss:\t\t0.755699\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 349 of 500 took 15.593s\n",
      "  training loss:\t\t0.091895\n",
      "  validation loss:\t\t0.743246\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 350 of 500 took 14.664s\n",
      "  training loss:\t\t0.085901\n",
      "  validation loss:\t\t0.746838\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 351 of 500 took 15.226s\n",
      "  training loss:\t\t0.089652\n",
      "  validation loss:\t\t0.736879\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 352 of 500 took 14.920s\n",
      "  training loss:\t\t0.086254\n",
      "  validation loss:\t\t0.748698\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 353 of 500 took 14.965s\n",
      "  training loss:\t\t0.082709\n",
      "  validation loss:\t\t0.752936\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 354 of 500 took 13.806s\n",
      "  training loss:\t\t0.091443\n",
      "  validation loss:\t\t0.761255\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 355 of 500 took 17.599s\n",
      "  training loss:\t\t0.085173\n",
      "  validation loss:\t\t0.750834\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 356 of 500 took 14.899s\n",
      "  training loss:\t\t0.085047\n",
      "  validation loss:\t\t0.749924\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 357 of 500 took 13.782s\n",
      "  training loss:\t\t0.086190\n",
      "  validation loss:\t\t0.743818\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 358 of 500 took 15.333s\n",
      "  training loss:\t\t0.088813\n",
      "  validation loss:\t\t0.738863\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 359 of 500 took 15.097s\n",
      "  training loss:\t\t0.089537\n",
      "  validation loss:\t\t0.744726\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 360 of 500 took 14.630s\n",
      "  training loss:\t\t0.089740\n",
      "  validation loss:\t\t0.741581\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 361 of 500 took 13.880s\n",
      "  training loss:\t\t0.087820\n",
      "  validation loss:\t\t0.763885\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 362 of 500 took 14.382s\n",
      "  training loss:\t\t0.087931\n",
      "  validation loss:\t\t0.764087\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 363 of 500 took 14.777s\n",
      "  training loss:\t\t0.087395\n",
      "  validation loss:\t\t0.756773\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 364 of 500 took 13.572s\n",
      "  training loss:\t\t0.090858\n",
      "  validation loss:\t\t0.763104\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 365 of 500 took 14.927s\n",
      "  training loss:\t\t0.082645\n",
      "  validation loss:\t\t0.767744\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 366 of 500 took 13.619s\n",
      "  training loss:\t\t0.089539\n",
      "  validation loss:\t\t0.760289\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 367 of 500 took 13.748s\n",
      "  training loss:\t\t0.088793\n",
      "  validation loss:\t\t0.765003\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 368 of 500 took 13.106s\n",
      "  training loss:\t\t0.082192\n",
      "  validation loss:\t\t0.765328\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 369 of 500 took 13.967s\n",
      "  training loss:\t\t0.083732\n",
      "  validation loss:\t\t0.774445\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 370 of 500 took 12.946s\n",
      "  training loss:\t\t0.087769\n",
      "  validation loss:\t\t0.764459\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 371 of 500 took 13.275s\n",
      "  training loss:\t\t0.087681\n",
      "  validation loss:\t\t0.764330\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 372 of 500 took 13.988s\n",
      "  training loss:\t\t0.085386\n",
      "  validation loss:\t\t0.757133\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 373 of 500 took 14.162s\n",
      "  training loss:\t\t0.088865\n",
      "  validation loss:\t\t0.757499\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 374 of 500 took 14.560s\n",
      "  training loss:\t\t0.084104\n",
      "  validation loss:\t\t0.757343\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 375 of 500 took 13.318s\n",
      "  training loss:\t\t0.085045\n",
      "  validation loss:\t\t0.757798\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 376 of 500 took 13.593s\n",
      "  training loss:\t\t0.083405\n",
      "  validation loss:\t\t0.774182\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 377 of 500 took 13.380s\n",
      "  training loss:\t\t0.086119\n",
      "  validation loss:\t\t0.775850\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 378 of 500 took 13.548s\n",
      "  training loss:\t\t0.087539\n",
      "  validation loss:\t\t0.760456\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 379 of 500 took 14.835s\n",
      "  training loss:\t\t0.085188\n",
      "  validation loss:\t\t0.766318\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 380 of 500 took 14.248s\n",
      "  training loss:\t\t0.087393\n",
      "  validation loss:\t\t0.775836\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 381 of 500 took 13.679s\n",
      "  training loss:\t\t0.086860\n",
      "  validation loss:\t\t0.772306\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 382 of 500 took 13.703s\n",
      "  training loss:\t\t0.079331\n",
      "  validation loss:\t\t0.782922\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 383 of 500 took 16.113s\n",
      "  training loss:\t\t0.086979\n",
      "  validation loss:\t\t0.782831\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 384 of 500 took 22.005s\n",
      "  training loss:\t\t0.081304\n",
      "  validation loss:\t\t0.787497\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 385 of 500 took 13.964s\n",
      "  training loss:\t\t0.087595\n",
      "  validation loss:\t\t0.782020\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 386 of 500 took 13.289s\n",
      "  training loss:\t\t0.090994\n",
      "  validation loss:\t\t0.796174\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 387 of 500 took 13.298s\n",
      "  training loss:\t\t0.084319\n",
      "  validation loss:\t\t0.793459\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 388 of 500 took 13.323s\n",
      "  training loss:\t\t0.083130\n",
      "  validation loss:\t\t0.817321\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 389 of 500 took 13.302s\n",
      "  training loss:\t\t0.084013\n",
      "  validation loss:\t\t0.802212\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 390 of 500 took 13.827s\n",
      "  training loss:\t\t0.082990\n",
      "  validation loss:\t\t0.800933\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 391 of 500 took 13.169s\n",
      "  training loss:\t\t0.082853\n",
      "  validation loss:\t\t0.807824\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 392 of 500 took 13.365s\n",
      "  training loss:\t\t0.082436\n",
      "  validation loss:\t\t0.810242\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 393 of 500 took 13.320s\n",
      "  training loss:\t\t0.087987\n",
      "  validation loss:\t\t0.798659\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 394 of 500 took 13.126s\n",
      "  training loss:\t\t0.080891\n",
      "  validation loss:\t\t0.792627\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 395 of 500 took 13.237s\n",
      "  training loss:\t\t0.086364\n",
      "  validation loss:\t\t0.797896\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 396 of 500 took 13.017s\n",
      "  training loss:\t\t0.083936\n",
      "  validation loss:\t\t0.802010\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 397 of 500 took 13.353s\n",
      "  training loss:\t\t0.083242\n",
      "  validation loss:\t\t0.800360\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 398 of 500 took 13.701s\n",
      "  training loss:\t\t0.079912\n",
      "  validation loss:\t\t0.800058\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 399 of 500 took 13.373s\n",
      "  training loss:\t\t0.083907\n",
      "  validation loss:\t\t0.793688\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 400 of 500 took 13.418s\n",
      "  training loss:\t\t0.084680\n",
      "  validation loss:\t\t0.807510\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 401 of 500 took 13.924s\n",
      "  training loss:\t\t0.088235\n",
      "  validation loss:\t\t0.821243\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 402 of 500 took 12.910s\n",
      "  training loss:\t\t0.083461\n",
      "  validation loss:\t\t0.809482\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 403 of 500 took 14.685s\n",
      "  training loss:\t\t0.080498\n",
      "  validation loss:\t\t0.803500\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 404 of 500 took 15.144s\n",
      "  training loss:\t\t0.081122\n",
      "  validation loss:\t\t0.819546\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 405 of 500 took 15.885s\n",
      "  training loss:\t\t0.084413\n",
      "  validation loss:\t\t0.809676\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 406 of 500 took 15.843s\n",
      "  training loss:\t\t0.083077\n",
      "  validation loss:\t\t0.811572\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 407 of 500 took 14.945s\n",
      "  training loss:\t\t0.083631\n",
      "  validation loss:\t\t0.818854\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 408 of 500 took 13.247s\n",
      "  training loss:\t\t0.079245\n",
      "  validation loss:\t\t0.825828\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 409 of 500 took 12.896s\n",
      "  training loss:\t\t0.080114\n",
      "  validation loss:\t\t0.839727\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 410 of 500 took 12.962s\n",
      "  training loss:\t\t0.076433\n",
      "  validation loss:\t\t0.826083\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 411 of 500 took 12.951s\n",
      "  training loss:\t\t0.080757\n",
      "  validation loss:\t\t0.834923\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 412 of 500 took 13.485s\n",
      "  training loss:\t\t0.077437\n",
      "  validation loss:\t\t0.833336\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 413 of 500 took 13.329s\n",
      "  training loss:\t\t0.081637\n",
      "  validation loss:\t\t0.838295\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 414 of 500 took 13.421s\n",
      "  training loss:\t\t0.081457\n",
      "  validation loss:\t\t0.832864\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 415 of 500 took 14.010s\n",
      "  training loss:\t\t0.076298\n",
      "  validation loss:\t\t0.814649\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 416 of 500 took 14.061s\n",
      "  training loss:\t\t0.082889\n",
      "  validation loss:\t\t0.831796\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 417 of 500 took 13.260s\n",
      "  training loss:\t\t0.083871\n",
      "  validation loss:\t\t0.826032\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 418 of 500 took 15.228s\n",
      "  training loss:\t\t0.081330\n",
      "  validation loss:\t\t0.811650\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 419 of 500 took 16.078s\n",
      "  training loss:\t\t0.080035\n",
      "  validation loss:\t\t0.827830\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 420 of 500 took 14.163s\n",
      "  training loss:\t\t0.079936\n",
      "  validation loss:\t\t0.830106\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 421 of 500 took 14.583s\n",
      "  training loss:\t\t0.081829\n",
      "  validation loss:\t\t0.823074\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 422 of 500 took 13.913s\n",
      "  training loss:\t\t0.080422\n",
      "  validation loss:\t\t0.840084\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 423 of 500 took 13.777s\n",
      "  training loss:\t\t0.075479\n",
      "  validation loss:\t\t0.833810\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 424 of 500 took 13.842s\n",
      "  training loss:\t\t0.077504\n",
      "  validation loss:\t\t0.834280\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 425 of 500 took 15.025s\n",
      "  training loss:\t\t0.078617\n",
      "  validation loss:\t\t0.821437\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 426 of 500 took 13.748s\n",
      "  training loss:\t\t0.080581\n",
      "  validation loss:\t\t0.846399\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 427 of 500 took 13.852s\n",
      "  training loss:\t\t0.081819\n",
      "  validation loss:\t\t0.830546\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 428 of 500 took 13.281s\n",
      "  training loss:\t\t0.082903\n",
      "  validation loss:\t\t0.823757\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 429 of 500 took 12.907s\n",
      "  training loss:\t\t0.080563\n",
      "  validation loss:\t\t0.837459\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 430 of 500 took 12.919s\n",
      "  training loss:\t\t0.077160\n",
      "  validation loss:\t\t0.834556\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 431 of 500 took 13.140s\n",
      "  training loss:\t\t0.083025\n",
      "  validation loss:\t\t0.818074\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 432 of 500 took 14.473s\n",
      "  training loss:\t\t0.078628\n",
      "  validation loss:\t\t0.822950\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 433 of 500 took 14.451s\n",
      "  training loss:\t\t0.085392\n",
      "  validation loss:\t\t0.841103\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 434 of 500 took 13.294s\n",
      "  training loss:\t\t0.082896\n",
      "  validation loss:\t\t0.838730\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 435 of 500 took 15.233s\n",
      "  training loss:\t\t0.077558\n",
      "  validation loss:\t\t0.830768\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 436 of 500 took 13.256s\n",
      "  training loss:\t\t0.076949\n",
      "  validation loss:\t\t0.853678\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 437 of 500 took 12.905s\n",
      "  training loss:\t\t0.082347\n",
      "  validation loss:\t\t0.844305\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 438 of 500 took 13.053s\n",
      "  training loss:\t\t0.075043\n",
      "  validation loss:\t\t0.844595\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 439 of 500 took 12.979s\n",
      "  training loss:\t\t0.075056\n",
      "  validation loss:\t\t0.843954\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 440 of 500 took 13.198s\n",
      "  training loss:\t\t0.077187\n",
      "  validation loss:\t\t0.828015\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 441 of 500 took 14.202s\n",
      "  training loss:\t\t0.079349\n",
      "  validation loss:\t\t0.843391\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 442 of 500 took 14.076s\n",
      "  training loss:\t\t0.078051\n",
      "  validation loss:\t\t0.849306\n",
      "  validation accuracy:\t\t90.00 %%\n",
      "Epoch 443 of 500 took 14.277s\n",
      "  training loss:\t\t0.078165\n",
      "  validation loss:\t\t0.865315\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 444 of 500 took 16.670s\n",
      "  training loss:\t\t0.079300\n",
      "  validation loss:\t\t0.847162\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 445 of 500 took 15.276s\n",
      "  training loss:\t\t0.080624\n",
      "  validation loss:\t\t0.848915\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 446 of 500 took 13.918s\n",
      "  training loss:\t\t0.079721\n",
      "  validation loss:\t\t0.866586\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 447 of 500 took 14.306s\n",
      "  training loss:\t\t0.076646\n",
      "  validation loss:\t\t0.851925\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 448 of 500 took 15.051s\n",
      "  training loss:\t\t0.078116\n",
      "  validation loss:\t\t0.870066\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 449 of 500 took 14.105s\n",
      "  training loss:\t\t0.083587\n",
      "  validation loss:\t\t0.869247\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 450 of 500 took 13.354s\n",
      "  training loss:\t\t0.082702\n",
      "  validation loss:\t\t0.866113\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 451 of 500 took 13.250s\n",
      "  training loss:\t\t0.076510\n",
      "  validation loss:\t\t0.854579\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 452 of 500 took 12.968s\n",
      "  training loss:\t\t0.081186\n",
      "  validation loss:\t\t0.865968\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 453 of 500 took 12.730s\n",
      "  training loss:\t\t0.078840\n",
      "  validation loss:\t\t0.874221\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 454 of 500 took 12.953s\n",
      "  training loss:\t\t0.077625\n",
      "  validation loss:\t\t0.893833\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 455 of 500 took 13.324s\n",
      "  training loss:\t\t0.086904\n",
      "  validation loss:\t\t0.861081\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 456 of 500 took 14.110s\n",
      "  training loss:\t\t0.077591\n",
      "  validation loss:\t\t0.870904\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 457 of 500 took 13.188s\n",
      "  training loss:\t\t0.077186\n",
      "  validation loss:\t\t0.873099\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 458 of 500 took 13.274s\n",
      "  training loss:\t\t0.082346\n",
      "  validation loss:\t\t0.870041\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 459 of 500 took 13.324s\n",
      "  training loss:\t\t0.075579\n",
      "  validation loss:\t\t0.873522\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 460 of 500 took 13.435s\n",
      "  training loss:\t\t0.079083\n",
      "  validation loss:\t\t0.879164\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 461 of 500 took 12.805s\n",
      "  training loss:\t\t0.079972\n",
      "  validation loss:\t\t0.873785\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 462 of 500 took 12.974s\n",
      "  training loss:\t\t0.076559\n",
      "  validation loss:\t\t0.880305\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 463 of 500 took 12.908s\n",
      "  training loss:\t\t0.076422\n",
      "  validation loss:\t\t0.887811\n",
      "  validation accuracy:\t\t90.17 %%\n",
      "Epoch 464 of 500 took 13.080s\n",
      "  training loss:\t\t0.077741\n",
      "  validation loss:\t\t0.875562\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 465 of 500 took 12.810s\n",
      "  training loss:\t\t0.079159\n",
      "  validation loss:\t\t0.869138\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 466 of 500 took 12.825s\n",
      "  training loss:\t\t0.074956\n",
      "  validation loss:\t\t0.864841\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 467 of 500 took 12.987s\n",
      "  training loss:\t\t0.077575\n",
      "  validation loss:\t\t0.890454\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 468 of 500 took 12.901s\n",
      "  training loss:\t\t0.080431\n",
      "  validation loss:\t\t0.869509\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 469 of 500 took 12.759s\n",
      "  training loss:\t\t0.077710\n",
      "  validation loss:\t\t0.866576\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 470 of 500 took 12.799s\n",
      "  training loss:\t\t0.073904\n",
      "  validation loss:\t\t0.892297\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 471 of 500 took 12.836s\n",
      "  training loss:\t\t0.079031\n",
      "  validation loss:\t\t0.884220\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 472 of 500 took 12.892s\n",
      "  training loss:\t\t0.075949\n",
      "  validation loss:\t\t0.886111\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 473 of 500 took 12.810s\n",
      "  training loss:\t\t0.074677\n",
      "  validation loss:\t\t0.893909\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 474 of 500 took 12.739s\n",
      "  training loss:\t\t0.076838\n",
      "  validation loss:\t\t0.892782\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 475 of 500 took 12.799s\n",
      "  training loss:\t\t0.075933\n",
      "  validation loss:\t\t0.890018\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 476 of 500 took 12.936s\n",
      "  training loss:\t\t0.077285\n",
      "  validation loss:\t\t0.902416\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 477 of 500 took 12.765s\n",
      "  training loss:\t\t0.080233\n",
      "  validation loss:\t\t0.883894\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 478 of 500 took 12.953s\n",
      "  training loss:\t\t0.075429\n",
      "  validation loss:\t\t0.896772\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 479 of 500 took 12.902s\n",
      "  training loss:\t\t0.077121\n",
      "  validation loss:\t\t0.893507\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 480 of 500 took 12.839s\n",
      "  training loss:\t\t0.076469\n",
      "  validation loss:\t\t0.894257\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 481 of 500 took 12.929s\n",
      "  training loss:\t\t0.073982\n",
      "  validation loss:\t\t0.901037\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 482 of 500 took 12.901s\n",
      "  training loss:\t\t0.077653\n",
      "  validation loss:\t\t0.887064\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 483 of 500 took 12.897s\n",
      "  training loss:\t\t0.078795\n",
      "  validation loss:\t\t0.893793\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 484 of 500 took 12.939s\n",
      "  training loss:\t\t0.076680\n",
      "  validation loss:\t\t0.891402\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 485 of 500 took 12.785s\n",
      "  training loss:\t\t0.075313\n",
      "  validation loss:\t\t0.873367\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 486 of 500 took 12.773s\n",
      "  training loss:\t\t0.080153\n",
      "  validation loss:\t\t0.879656\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 487 of 500 took 12.689s\n",
      "  training loss:\t\t0.073954\n",
      "  validation loss:\t\t0.881050\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 488 of 500 took 13.193s\n",
      "  training loss:\t\t0.076324\n",
      "  validation loss:\t\t0.894080\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 489 of 500 took 14.504s\n",
      "  training loss:\t\t0.070796\n",
      "  validation loss:\t\t0.903357\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 490 of 500 took 13.061s\n",
      "  training loss:\t\t0.079702\n",
      "  validation loss:\t\t0.881504\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 491 of 500 took 12.984s\n",
      "  training loss:\t\t0.072775\n",
      "  validation loss:\t\t0.898181\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 492 of 500 took 12.849s\n",
      "  training loss:\t\t0.073443\n",
      "  validation loss:\t\t0.885640\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 493 of 500 took 12.806s\n",
      "  training loss:\t\t0.078338\n",
      "  validation loss:\t\t0.888102\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 494 of 500 took 12.823s\n",
      "  training loss:\t\t0.079626\n",
      "  validation loss:\t\t0.894487\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 495 of 500 took 12.849s\n",
      "  training loss:\t\t0.076007\n",
      "  validation loss:\t\t0.910098\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 496 of 500 took 12.843s\n",
      "  training loss:\t\t0.076707\n",
      "  validation loss:\t\t0.912291\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 497 of 500 took 12.894s\n",
      "  training loss:\t\t0.074122\n",
      "  validation loss:\t\t0.924463\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 498 of 500 took 12.748s\n",
      "  training loss:\t\t0.073301\n",
      "  validation loss:\t\t0.930138\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 499 of 500 took 12.833s\n",
      "  training loss:\t\t0.074041\n",
      "  validation loss:\t\t0.909516\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 500 of 500 took 12.887s\n",
      "  training loss:\t\t0.075859\n",
      "  validation loss:\t\t0.896478\n",
      "  validation accuracy:\t\t91.00 %%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dikien/anaconda/lib/python2.7/site-packages/Lasagne-0.1.dev0-py2.7.egg/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
      "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n",
      "/Users/dikien/anaconda/lib/python2.7/site-packages/Lasagne-0.1.dev0-py2.7.egg/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
      "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n"
     ]
    }
   ],
   "source": [
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "dataset = load_data(features, labels)\n",
    "\n",
    "print(\"Building model and compiling functions...\")\n",
    "output_layer = build_model(\n",
    "    input_height=dataset['input_height'], # 28\n",
    "    input_width=dataset['input_width'], # 28\n",
    "    output_dim=dataset['output_dim'], # 9\n",
    "    )\n",
    "\n",
    "iter_funcs = create_iter_functions(\n",
    "    dataset,\n",
    "    output_layer,\n",
    "    X_tensor_type=T.tensor4,\n",
    "    )\n",
    "\n",
    "num_epochs = NUM_EPOCHS\n",
    "\n",
    "print(\"Starting training...\")\n",
    "now = time.time()\n",
    "try:\n",
    "    for epoch in train(iter_funcs, dataset):\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch['number'], num_epochs, time.time() - now))\n",
    "        now = time.time()\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(epoch['train_loss']))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(epoch['valid_loss']))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %%\".format(\n",
    "            epoch['valid_accuracy'] * 100))\n",
    "\n",
    "        if epoch['number'] >= num_epochs:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "[[  0 423]\n",
      " [  1 619]\n",
      " [  2 383]\n",
      " [  3 404]\n",
      " [  4 478]\n",
      " [  5 425]\n",
      " [  6 259]\n",
      " [  7 551]\n",
      " [  8 458]]\n",
      "test set\n",
      "[[  0 114]\n",
      " [  1 172]\n",
      " [  2 101]\n",
      " [  3  95]\n",
      " [  4 127]\n",
      " [  5  85]\n",
      " [  6  54]\n",
      " [  7 141]\n",
      " [  8 111]]\n",
      "validation set\n",
      "[[  0 103]\n",
      " [  1 130]\n",
      " [  2 132]\n",
      " [  3  94]\n",
      " [  4 134]\n",
      " [  5 109]\n",
      " [  6  57]\n",
      " [  7 148]\n",
      " [  8  93]]\n"
     ]
    }
   ],
   "source": [
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "unique_train, counts_train = np.unique(labels[:4000], return_counts=True)\n",
    "unique_valid, counts_valid = np.unique(labels[4000:5000], return_counts=True)\n",
    "unique_test, counts_test = np.unique(labels[5000:], return_counts=True)\n",
    "\n",
    "print (\"train set\")\n",
    "print (\"{}\".format(np.asarray((unique_train, counts_train)).T))\n",
    "print (\"test set\")\n",
    "print (\"{}\".format(np.asarray((unique_valid, counts_valid)).T))\n",
    "print (\"validation set\")\n",
    "print (\"{}\".format(np.asarray((unique_test, counts_test)).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 423.,  619.,  383.,  404.,  478.,  425.,  259.,  551.,  458.]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " <a list of 9 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGKCAYAAAD0YbClAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu0ZnV93/H3hwGBiFyCyxmLEbCNoSQKSmmUchGiU0sa\n",
       "k+IlhEBBEmoSiKGEpQUhGdRoSrpwDNJmmUWiwSWiMQQ6qZGLXBoBiRMyKoFIKkMddGa4ZcpVbt/+\n",
       "sfchDw9zeWbmnLPP/M77tdazzrN/+7f3892cYZ7P/PZv752qQpIkaVu33dAFSJIkTQdDjSRJaoKh\n",
       "RpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSE2Y91CRZmeTZ9byW9euTZEmSe5M8luS6JPuP7WPH\n",
       "JBcmuS/JI0muSLLXbB+LJEmaO4YYqTkIWDTyej1QwGX9+vcBZwCnAQcDa4Grk+wyso+lwDHAscBh\n",
       "wK7AsiSOPEmSNE9l6DsKJ/kA8JvAy4Enge8Bv19VH+3X70QXbM6sqk8m2a1fPqmqLu37vAK4B/h3\n",
       "VXXVAIchSZIGNujIRpIAvwR8pqp+AOwLLASeCyZV9QRwI3BI33QQsMNYn1XAHSN9JEnSPDP06Zq3\n",
       "APsAf9gvL+p/rhnrt3Zk3SLgmap6YKzPGrpAJEmS5qGhQ80pwK1V9c0J+vrkTUmStEHbD/XBSV4G\n",
       "vA34tZHm1f3PhcCqkfaFI+tWAwuS7Dk2WrOI7jTV+OcUcN5I0/VVdf3WVS9JkuaawUINcBLwBHDp\n",
       "SNvddKFlMbAcnpsofChwZt9nOfBU32d0ovB+wE3r+6CqWjLdxUuSpLllkFDTTxD+ZeBzVfXYVHtV\n",
       "VZKlwNlJ7gTuAs4BHgY+2/dZl+Ri4Pwka4EHgQuAFcA1s3skkiRprhhqpOZNwD8HjhtfUVXnJ9kZ\n",
       "uAjYA7gFWFxVj450Ox14mu7eNjvThZnja+jr0yVJ0mAGv0/NTEtSVZWh65AkSTNr6KufJEmSpoWh\n",
       "RpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKa\n",
       "YKiRJElNMNRIkqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiS\n",
       "pCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1\n",
       "kiSpCYYaSZLUBEONJElqgqFGkiQ1YfuhC9DWSVJD1zDTqipD1yBJmvsMNQ044oRzhy5hxtxwyYeG\n",
       "LkGStI3w9JMkSWrCIKEmycuTfDrJ2iSPJ7k9yeFjfZYkuTfJY0muS7L/2Podk1yY5L4kjyS5Isle\n",
       "s3skkiRprpj1UJNkd+CrQAFHA/sBpwFrR/q8Hzijbz+4X3d1kl1GdrUUOAY4FjgM2BVYlsTRJ0mS\n",
       "5qEh5tS8D7i3qk4aabtn6k2SAKcDH62qy/u2E+mCzXHAJ5PsBpwMnFRV1/Z9Tuj382bgqlk4DkmS\n",
       "NIcMMarxc8CtSS5LsibJbUlOHVm/L7CQkWBSVU8ANwKH9E0HATuM9VkF3DHSR5IkzSNDhJpXAb8G\n",
       "/AOwGPg48LsjwWZR/3PN2HZrR9YtAp6pqgfG+qyhC0SSJGmeGeL003bArVX1gX55RZIfBU4FLtrE\n",
       "ts3fk0WSJG2ZIULN94C/G2u7E3hl/351/3MhsGqkz8KRdauBBUn2HButWUR3mup5kiwZWby+qq7f\n",
       "osolSdKcNUSo+SrdFU+jXg2s7N/fTRdaFgPLAZLsBBwKnNn3WQ481fe5tO/zin6/N41/YFUtmcb6\n",
       "JUnSHDREqPkYcFOSs4HPA68Dfh04C6CqKslS4OwkdwJ3AecADwOf7fusS3IxcH6StcCDwAXACuCa\n",
       "WT4eSZI0B8x6qKmqryf5OeAjwLl0l2GfU1X/Y6TP+Ul2pptjswdwC7C4qh4d2dXpwNPAZcDOdGHm\n",
       "+Kpy3o0kSfNQWs8ASarlByImqdaf/dTy70+SNH28+64kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiS\n",
       "pCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1\n",
       "kiSpCYYaSZLUBEONJElqgqFGkiQ1YfuhC5AkabYlqaFrmGlVlaFrmG2GGknSvHTECecOXcKMueGS\n",
       "Dw1dwiA8/SRJkppgqJEkSU0w1EiSpCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mS\n",
       "mmCokSRJTTDUSJKkJhhqJElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKaMOuhJsmSJM+O\n",
       "vb63nj73JnksyXVJ9h9bv2OSC5Pcl+SRJFck2Wt2j0SSJM0lQ43U3AksGnm9ZmpFkvcDZwCnAQcD\n",
       "a4Grk+wysv1S4BjgWOAwYFdgWRJHniRJmqe2H+hzn6mqteONSQKcDny0qi7v206kCzbHAZ9Mshtw\n",
       "MnBSVV3b9zkBuAd4M3DV7ByCJEmaS4Ya2XhVf3rpO0kuTbJv374vsJCRYFJVTwA3Aof0TQcBO4z1\n",
       "WQXcMdJHkiTNM0OEmluAE4F/C5xCd/rppiQ/3L8HWDO2zdqRdYvoRnoeGOuzhi4QSZKkeWjWTz9V\n",
       "1V+OLH4ryc3A3XRB52sb23RGC5MkSdu0oebUPKeqHktyO/AvgD/vmxcCq0a6LQRW9+9XAwuS7Dk2\n",
       "WrOI7jTVCyRZMrJ4fVVdPw2lS5KkOWTwUJNkJ+BfAl+pqruTrAYWA8tH1h8KnNlvshx4qu9zad/n\n",
       "FcB+wE3r+4yqWjKDhyBJkuaAWQ81Sf4bcCXwXeBlwLnAzsCn+y5LgbOT3AncBZwDPAx8FqCq1iW5\n",
       "GDg/yVrgQeACYAVwzSweiiRJmkOGGKnZi26E5aXAfcDNwBuq6rsAVXV+kp2Bi4A96CYWL66qR0f2\n",
       "cTrwNHAZXSC6Bji+qpx3I0nSPDXEROFfmKDPecB5G1n/JPDe/iVJkuSznyRJUhsMNZIkqQmGGkmS\n",
       "1ARDjSRJaoKhRpIkNWHwm+9JalOS5m+xUFUZugZJ/8RQI2nGHHHCuUOXMGNuuORDQ5cgaYynnyRJ\n",
       "UhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJnjzPUmSGtTqXb03didv\n",
       "Q40kSQ1q+Y7eG+LpJ0mS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1kiSp\n",
       "CYYaSZLUBEONJElqgqFGkiQ1wVAjSZKaYKiRJElNmBdP6U4yL45TkqT5bJ582efJoSuYGZWhK5Dm\n",
       "syQ1dA0zqcq/Y7RtmReh5ogTzmnyf8yVK27gnm/cOHQZ0rx1xAnnDl3CjLnhkg8NXYK02ZxTI0mS\n",
       "mmCokSRJTTDUSJKkJhhqJElSEwYNNUnOSvJskgvH2pckuTfJY0muS7L/2Podk1yY5L4kjyS5Isle\n",
       "s1u9JEmaSwYLNUneAJwCfAOokfb3A2cApwEHA2uBq5PsMrL5UuAY4FjgMGBXYFkSR54kSZqnBgkB\n",
       "SXYDPgO8G3hopD3A6cBHq+ryqrodOBF4CXDcyLYnA2dW1bVVdRtwAvBa4M2zeiCSJGnOGGpk45PA\n",
       "F6rqBmD0HjL7AguBq6YaquoJ4EbgkL7pIGCHsT6rgDtG+kiSpHlm1m++l+QU4FX0Iy+MnHoCFvU/\n",
       "14xtthb4ZyN9nqmqB8b6rKELRNI2o/U70krSbJrVUJPkx4DfAQ6tqmemmnn+aM2GbPFf/itX3PDc\n",
       "+90X7s3ui/bZ0l1J067Vu9J6R1pJs222R2reCLwUuL2bPgPAAuCwJO8BfqJvWwisGtluIbC6f78a\n",
       "WJBkz7HRmkV0p6leYJ8Djpie6iVJ0pw10ZyaJIcneckG1u2S5PAJP+9yuuByQP86EPg6cGn//i66\n",
       "0LJ4ZP87AYcCN/VNy4Gnxvq8AthvpI8kSZpnJh2puR54A3DretbtB1xHN+KyUVW1Dlg32pbkMeCh\n",
       "qvq7fnkpcHaSO+lCzjnAw8Bnp/aR5GLg/CRrgQeBC4AVwDUTHo8kSWrMdJx+2hF4diu2L0bmy1TV\n",
       "+Ul2Bi4C9gBuARZX1aMj25wOPA1cBuxMF2aOryonXUqSNE9tMNQk2ZfuEuupyS8Hj90AD7pA8UvA\n",
       "/93SAqrqyPW0nQect5FtngTe278kSZI2OlJzIvBbI8sXbqDf03R3/5UkSRrMxkLNp+jm0gB8BTiV\n",
       "7gZ3o34AfHs994yRJEmaVRsMNVW1ElgJkOQoYHlVPTw7ZUmSJG2eiSYKV9X1M1yHtEHedVeSNImJ\n",
       "Qk2SHYGzgF8AXkl3xdOoqqpNXtItbYlW77gL3nVXkqbTpJd0n083p+ZLwJ/RzaUZ5b+kJUnSoCYN\n",
       "Ne8AllTVh2eyGEmSpC010WMSgF3wEQSSJGkOmzTULAMmfb6TJEnSrJv09NPvA5f0V6H8Bd3zlp6n\n",
       "qr4znYVJkiRtjklDzc39z9/uX+OKCR5oKUmSNFMmDTUnz2gVkiRJW2nSm+99aobrkCRJ2iqTThSW\n",
       "JEma0ya9o/Afs+Eb7IXujsKeopIkSYOZdE7NkTw/1AT4Ybr716wD/nGa65IkSdosk86p2Wd97UkO\n",
       "B/4AOH4aa5IkSdpsWzWnpqpuBD5Gdx8bSZKkwUzHROG7gddPw34kSZK22FaFmiQ7ACcCq6anHEmS\n",
       "pC0z6dVP1/HCq592BF4N7An8yjTXJUmStFkmvfopYz8BHga+CHyuqq6fzqIkSZI216RXP71phuuQ\n",
       "JEnaKt5RWJIkNWHiUJPktUm+mOT+JM8kuS/JF5K8ZiYLlCRJmsSkE4UPBm4AHgeuBNYAi4CfAY5O\n",
       "ckRVfX3GqpQkSdqESScKfxT4FvBTVfXwVGOSlwDX9OvfMv3lSZIkTWbS009vAH53NNAA9Mv/FXjj\n",
       "dBcmSZK0OSYNNRt6Qvek6yVJkmbUpKHma8BZSXYdbUyyC/B+4JbpLkySJGlzTDqn5my6icIrkywD\n",
       "vg+8HDga+CHgTTNSnSRJ0oQmvfnerUl+Evgt4K3AHsCDwFeAD1XVN2euREmSpE3bYKhJsh3w08DK\n",
       "qvpmVX0DeMdYn9cA+yT5VlU5r0aSJA1mY3NqfhH4HN0znjbkEeBS4BemsyhJkqTNtbFQcwLwx1W1\n",
       "ckMdqupu4GLgP05zXZIkSZtlY6Hm9cCXJ9jHtcDB01OOJEnSltlYqHkJ8NAE+3io7ytJkjSYjYWa\n",
       "+4G9J9jHj/R9J5Lk1CQrkqzrXzclOXqsz5Ik9yZ5LMl1SfYfW79jkgv7h2o+kuSKJHtNWoMkSWrP\n",
       "xkLNV4ETJ9jHScBfbcZnfhd4H/A64CC6y8L/PMkBAEneD5wBnEZ3WmstcHV/o78pS4FjgGOBw4Bd\n",
       "gWX9FVuSJGke2lgI+BjwU0mWJnnR+MokL0qyFPipvu9EqurKqvpyVX2nqv6hqs6hu8LqXycJcDrw\n",
       "0aq6vKpupwtWLwGO6z93N+Bk4MyquraqbqOb1Pxa4M2T1iFJktqywfvUVNXNSX4TuAA4LslVwD39\n",
       "6r2BxcCewBlVdfOWfHiSBcA7gZ2AG4F9gYXAVSN1PJHkRuAQ4JN0ozs7jPVZleSOvs9z7ZIkaf7Y\n",
       "6B2Fq2ppkr+he77TMXThA+Bx4Hq6J3f/78390P6mfTcDO/b7eldV/X2SQ/oua8Y2WQv8s/79IuCZ\n",
       "qnpgrM8aukAkSZLmoU0+JqGqbgRu7EdVXto3P1BVT2/F595Jd7poN7qRms8lOXJTpWzph61cccNz\n",
       "73dfuDe7L9pnS3clSZLmqEkfaElVPcMLR1C2SFU9BXynX7wtycHAqcAH+7aFwKqRTRYCq/v3q4EF\n",
       "SfYcG61ZRHcK6wX2OeCI6ShbkiTNYXPlaqEFwHb9HYpX083XASDJTsChwE1903LgqbE+rwD2G+kj\n",
       "SZLmmYlHaqZLkt8FltGNxExd1XQE3dO/obtc++wkdwJ3AVNXR30WoKrWJbkYOD/JWrqnhV8ArACu\n",
       "mcVDkSRJc8ishxq6U0mfoTtdtI4ujLy1qq4GqKrzk+wMXATsAdwCLK6qR0f2cTrwNHAZsDNdmDne\n",
       "J4VLkjR/zXqoqap3T9DnPOC8jax/Enhv/5IkSZozc2okSZK2iqFGkiQ1wVAjSZKaYKiRJElNMNRI\n",
       "kqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiSpCYYaiRJUhO2\n",
       "H7oASdLclKSGrkHaHIYaSdJ6HXHCuUOXMGNuuORDQ5egGeDpJ0mS1ARDjSRJaoKhRpIkNcFQI0mS\n",
       "mmCokSRJTTDUSJKkJhhqJElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKaYKiRJElNMNRI\n",
       "kqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkpow66EmyVlJ/jrJuiRrk1yZ5MfX\n",
       "029JknuTPJbkuiT7j63fMcmFSe5L8kiSK5LsNXtHIkmS5pIhRmqOAD4BvBE4CngauCbJHlMdkrwf\n",
       "OAM4DTgYWAtcnWSXkf0sBY4BjgUOA3YFliVx9EmSpHlo+9n+wKp66+hykhOAdcAhwF8kCXA68NGq\n",
       "urzvcyJdsDkO+GSS3YCTgZOq6tqR/dwDvBm4apYOR5IkzRFzYVRjV7o6HuqX9wUWMhJMquoJ4Ea6\n",
       "4ANwELDDWJ9VwB0jfSRJ0jwyF0LNx4HbgJv75UX9zzVj/daOrFsEPFNVD4z1WUMXiCRJ0jwz66ef\n",
       "RiW5gG5k5dCqqgk2maSPJEmahwYLNUk+BrwLOLKqVo6sWt3/XAisGmlfOLJuNbAgyZ5jozWL6E5T\n",
       "Pc/KFTc89373hXuz+6J9trZ8SZI0xwwSapJ8HHgnXaD59tjqu+lCy2Jged9/J+BQ4My+z3Lgqb7P\n",
       "pX2fVwD7ATeNf94+Bxwx/QchSZLmlFkPNUkuAo4Hfg5Yl2RqnszDVfVoVVWSpcDZSe4E7gLOAR4G\n",
       "PgtQVeuSXAycn2Qt8CBwAbACuGZ2j0iSJM0FQ4zU/Crd3Jhrx9qXAB8EqKrzk+wMXATsAdwCLK6q\n",
       "R0f6n053j5vLgJ3pwszxE87NkSRJjRniPjUTXXFVVecB521k/ZPAe/uXJEma5+bCJd2SJElbzVAj\n",
       "SZKaYKiRJElNMNRIkqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w\n",
       "1EiSpCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElS\n",
       "Eww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKaYKiRJElNMNRIkqQmGGokSVITDDWSJKkJhhpJ\n",
       "ktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiSpCYYaiRJUhNmPdQkOTzJlUlWJXk2yYnr6bMk\n",
       "yb1JHktyXZL9x9bvmOTCJPcleSTJFUn2mr2jkCRJc80QIzUvBr4B/AbwOFCjK5O8HzgDOA04GFgL\n",
       "XJ1kl5FuS4FjgGOBw4BdgWVJHHmSJGmemvUQUFVfqqpzquqLwLOj65IEOB34aFVdXlW3AycCLwGO\n",
       "6/vsBpwMnFlV11bVbcAJwGuBN8/ioUiSpDlkro1s7AssBK6aaqiqJ4AbgUP6poOAHcb6rALuGOkj\n",
       "SZLmmbkWahb1P9eMta8dWbcIeKaqHhjrs4YuEEmSpHloroWajalNd5EkSfPV9kMXMGZ1/3MhsGqk\n",
       "feHIutXAgiR7jo3WLKI7TfUCK1fc8Nz73Rfuze6L9pmueiVJ0hwx10LN3XShZTGwHCDJTsChwJl9\n",
       "n+XAU32fS/s+rwD2A25a3073OeCIGS1akiQNb9ZDTZIXAz/aL24H7J3kQOCBqvpukqXA2UnuBO4C\n",
       "zgEeBj4LUFXrklwMnJ9kLfAgcAGwArhmdo9GkiTNFUOM1BwMfKV/X8B5/etTwMlVdX6SnYGLgD2A\n",
       "W4DFVfXoyD5OB54GLgN2pgszx1eV824kSZqnZj3UVNX1bGKCclVNBZ0NrX8SeG//kiRJ2qaufpIk\n",
       "SdogQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiSpCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKh\n",
       "RpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKa\n",
       "YKiRJElNMNRIkqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiS\n",
       "pCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTdimQ02SX0tyd5LHk3w9\n",
       "yaFD1yRJkoaxzYaaJD8PLAU+DBwI3AR8KcmPDFqYJEkaxDYbaoAzgD+uqour6u+r6r3A94FfHbgu\n",
       "SZI0gG0y1CR5EfB64KqxVVcBh8x+RZIkaWjbZKgBXgosANaMta8FFs1+OZIkaWjbD13AbFhx1SXr\n",
       "hq5hJjz+yEM7ATsOXYckSXNBqmroGjZbf/rpUeDYqvriSPtFwP5VdeRI27Z3gJIkaYOqKutr3yZH\n",
       "aqrqySTLgcXAF0dWvQX4wljf9R64JElqyzYZanoXAJckuZXucu5foZtP8weDViVJkgaxzYaaqvp8\n",
       "kj2Bc4CXA98Ejq6q7w5bmSRJGsI2OadGkiRp3LZ6SfdEWn2MQpLDk1yZZFWSZ5OcOHRN0ynJWUn+\n",
       "Osm6JGv7Y/3xoeuaDklOTbKiP7Z1SW5KcvTQdc2U/nf5bJILh65lOiRZ0h/P6Ot7Q9c1nZK8PMmn\n",
       "+//3Hk9ye5LDh65rayVZuZ7f3bNJlg1d23RIsn2SjyT5Tv97+06SDyVZMHRts6nZUNP4YxReDHwD\n",
       "+A3gcaC14bYjgE8AbwSOAp4Grkmyx6BVTY/vAu8DXgccBHwF+PMkBwxa1QxI8gbgFLo/qy39Gb2T\n",
       "bv7e1Os1w5YzfZLsDnyV7vd1NLAfcBrdPcC2dQfx/N/b6+mO87Ihi5pGZwPvAX4d+DG674dfA84a\n",
       "sqjZ1uzppyRfA/62qt4z0vZt4E+r6uzhKpteSR4GTq2qPxm6lpmS5MXAOuBnq+ovhq5nuiV5APgv\n",
       "VfWHQ9cyXZLsBiwHfglYAnyzf5TJNi3JEuDtVdVMkBmV5CPAYVV12NC1zLQkHwB+E3h5Vf1g6Hq2\n",
       "VpL/CdxfVe8eafs0sEdVvW24ymZXkyM1PkahObvS/Vl9aOhCplOSBUmOBXYCbhy6nmn2SeALVXUD\n",
       "0NptFV6V5N5+eP/SJPsOXdA0+jng1iSXJVmT5LYkpw5d1HRLErrA/ZkWAk3vS8BRSX4MIMn+wJHA\n",
       "/xq0qlm2zV79tAk+RqEtHwduA24eupDpkOQ1dMeyI93pw3dV1d8PW9X0SXIK8CrguL6ppeHgW4AT\n",
       "6U5BLaS7+vKmJD9eVQ8OWtn0eBXdKYsLgI/QnSa9MAlVddGglU2vtwD7AM2MjlbVf0/yCuCOJE/T\n",
       "fb9/uKrm1W1OWg01akSSC+hG1w6tds6V3gm8FtgNeCfwuSRHVtXXhy1r6/X/Svwdut/XM1PNNDJa\n",
       "U1V/ObL4rSQ3A3fTBZ2PDVPVtNoOuLWqPtAvr0jyo8CpQEuh5hS64/zm0IVMlyTvBd4NHAvcThdI\n",
       "P55kZVX90aDFzaJWQ839wDN0/5IatRD4/uyXoy2R5GPAu4Ajq2rlwOVMm6p6CvhOv3hbkoPpvjTe\n",
       "veGtthlvpBspvb0b4Qe6UdPDkrwHeHF//E2oqseS3A78i6FrmSbfA/5urO1O4JUD1DIjkrwMeBvd\n",
       "iFRLPkA3MvP5fvn2JHvTTRSeN6GmyTk1VfUk3STFxWOr3kJ3FZTmuCQfB34eOKqqvj10PTNsAe38\n",
       "v3g58BPAAf3rQODrwKXAgS0FGoAkOwH/knb+sfRVuiueRr0aWDn7pcyYk4An6P5MtiTAs2Ntz9LI\n",
       "KOmkWh2pgYYfo9BfDfSj/eJ2wN5JDgQeaOGOyv2DSY+nm7S4LsnUPKiHq+rR4Srbekl+F1gGrAJe\n",
       "Qjfv5AjgrUPWNV2qah3dlWrPSfIY8FBVjY8AbHOS/DfgSrpL818GnAvsDHx6yLqm0cfo5gidDXye\n",
       "7hTGr9PIZcH9BOFfBj5XVY8NXc80+3PgvyS5m2607XXAf6adP5sTafaSboAkv0p3T5Cpxyj856r6\n",
       "q2Gr2npJ3kR3fxPoJmFOJfFPVdXJgxQ1jZI8y/OPa8qSqvrgACVNmyR/THdFwiK6L/8VwO9V1dWD\n",
       "FjaDklxHO5d0XwocTneK7T66Cd/nVtWdgxY2jfqbQX6E7l4n9wCfqKpPDFvV9EhyJHAN8JMtzGEb\n",
       "1f9j9zzg7fzTVItLgQ/2Zy/mhaZDjSRJmj9aOY8vSZLmOUONJElqgqFGkiQ1wVAjSZKaYKiRJElN\n",
       "MNRIkqQmGGokSVITDDXSNijJsxO87t7Kzzip38+0PPdnZH9Tr0eS3J3kz5K8cyv2e2CSJUn2mI46\n",
       "R/a7Mskl07CfN/XHe9QEfZ9N8ttb+5nSfNXyYxKklr1h5H3onrn0t8CSkfYfbOVnLOs/Z/VW7mfc\n",
       "O+geE7EjsDfw08ClSf4T8DNV9cRm7u9A4LeAPwEemsY6q3/NNu+IKm0hQ420DaqqW0eXk/wAuH+8\n",
       "fazPgn7bZyb8jPvpnng/3f62qqaeUv6/gc8k+QLwBeB8YEsfpzCvHtwn6YU8/SQ1qj+V8eEkUw+5\n",
       "+wHwE0l2TPKxJN9M8nCS7ye5MsmPjW3/gtNPU6dkkhyb5I7+FNJfJ/k3W1NrVf0ZcAVwSpKdRz7v\n",
       "vCR/k2RdkvuSXJvkJ0drBP6oX7xr5NTWK/v1pyW5OckDSR7q3x+9NbWO2lR9Y3ZP8qkkD/b9P5Pk\n",
       "hyf4jAP638+DSR5L8ldJDh3rc3CSq5Pc3/f5P/2DYaV5xVAjte0k4N8BZwBH0z3kbke6J4R/hO7U\n",
       "z68AOwE3J1m4if0VcBjd038/APw8sABYlmS3raz1S31t/2qkbS9gKfA24ERgLXBjkp/o1y8DPty/\n",
       "fwfd6bJGyvthAAAETElEQVTRU2b70IWedwLvAr7e1/pvt7LWSesbtRR4BjiW7r/d24A/3djOk7we\n",
       "uAnYne7p0m8HHgCu6deRZBfgy8BTfQ1vBT5I93uR5hVPP0ntW1xV4/NrfnnqTZLtgKvpgsAv0H35\n",
       "bkjoAtEBVbWu33418Nd0oenSrajz//Y/F001VNVonQuAq4DX9fWfXlX3J5k6lTV6Wmtq+zNHtt8O\n",
       "uA54NfCrdEFgq2yqvrHu36qqX+rfX5XkQbpTb0dV1Vc28BG/B6wEjqqqp/vP+TLwLeBc4D8A+9GF\n",
       "nvdV1bf67W4EPr2Vhydtcxypkdr2l+sJNCR5V5KvJXkIeBp4BNiF7gt/U26eCjS9qS/SH9nKWqfm\n",
       "xDw3UTbJm5Ncl+R+upGIJ/saJ6mTJAclWdYHr6nt3zLp9hPsf3Pq+/zY8p8Cz/L8Sd+j+94ZOJxu\n",
       "rhFJtk+yPd3f29f26wDuAv4R+GSSX0yytb8HaZtlqJHa9v3xhiQ/A3wOuJ1uZOZfAwcD99GdhtqY\n",
       "Ah58XsM/haZNbbspU1/G3+/rfD3wv4D/B5wM/GRf54pJPqv/cr+WbhTjNOCN/fZ/OQ21bkl9a0YX\n",
       "qupJuqu19trAR/ww3Smk36ILS6OvU+mOiz5gHgl8D/jvwD39fKljtuLwpG2Sp5+ktq3v8uBjgbuq\n",
       "6uSphiQ7AHvOWlXr99PA48DyfvntdF/gx4xesdVPrp3k0u23ArsC76qq741s/+Jpqndz61s0upDk\n",
       "RcAewL0b2P8/0o3kfILucvUNqqoVwDv6U2wHA2cBn09yQFXdPtnhSNs+R2qk+eeH6CasjjqBAf8+\n",
       "SPJ24GeAPxi5T80P0X2pj/Y7ihee5vrBSP9RU8tPj2z/amCrrtQa2/8k9U1519jyO+n+m9+8vs5V\n",
       "9SjdJe8HArdV1d+Mv9azzbNV9TW60Z3t6ObbSPOGIzVSGzbnHi1fAn42yQXAX9BdbXQa3cjApvYz\n",
       "HfeCeV2SlwEvAl4J/Hu6K5euohthGK3zN4BPJfkU3TyVc+hGNkbrmBqJODXJn9DNbVlBN/n5aeBP\n",
       "+mN9Od3NCe9hsgAXYO8k71jPups2o74p+yf5I+Cyvu/vANdV1XUbqeEMukm/X05yMd1k7pcCrwe2\n",
       "q6qzkvx74D/R3YBxJfBiunv9/D82EJikVhlqpDZszl1o/5BuNOFk4D3ArXSjJJevZz+bWt4cU9t+\n",
       "of/5BN0l0MuBn6+qLz6vc9VVSd5L98X+duCbdCNK547WUVXfSLKE7ov9FLpAsW9V/V2SX6S7vPkK\n",
       "4B+A99Nd4n7EhPUeSncJ+3j7O6vqzyapb2Sb3wB+lm4+0wLgSjZxo8Gqui3JwcBvA78P7EY392k5\n",
       "8Ad9t28Dj/Wf+3LgYbrf6VtGT7tJ80GqvCO3JEna9jmnRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhq\n",
       "JElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ14f8DJQQAkE+OKHsAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a8489d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Remove the plot frame lines. They are unnecessary chartjunk.  \n",
    "ax = plt.subplot(111)  \n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "\n",
    "# Ensure that the axis ticks only show up on the bottom and left of the plot.  \n",
    "# Ticks on the right and top of the plot are generally unnecessary chartjunk.  \n",
    "ax.get_xaxis().tick_bottom()  \n",
    "ax.get_yaxis().tick_left()  \n",
    "\n",
    "# Make sure your axis ticks are large enough to be easily read.  \n",
    "# You don't want your viewers squinting to read your plot.  \n",
    "plt.xticks(unique_train, fontsize=14)  \n",
    "plt.yticks(fontsize=14)  \n",
    "\n",
    "# Along the same vein, make sure your axis labels are large  \n",
    "# enough to be easily read as well. Make them slightly larger  \n",
    "# than your axis tick labels so they stand out.  \n",
    "plt.xlabel(\"Train Data Lables\", fontsize=16)  \n",
    "plt.ylabel(\"Count\", fontsize=16)\n",
    "\n",
    "ax.hist(labels[:4000], bins=range(10), cumulative=False, color=\"#3F5D7D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 114.,  172.,  101.,   95.,  127.,   85.,   54.,  141.,  111.]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " <a list of 9 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGKCAYAAAAbo9ubAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu4HXV97/H3h4BAuR9aE+ol4CnKwQuplkelQMRq2npq\n",
       "a61V6pETpMdaBQGRlopiE0FRTotYxLaeWlGqeKlFKQpFlEAVLYI2WASxhSABSQBp5CqXfM8fMxsX\n",
       "qzvJDll7rTUr79fzrGet+c1vZn2HHbI/+c1vZlJVSJIkddkWoy5AkiRpUxloJElS5xloJElS5xlo\n",
       "JElS5xloJElS5xloJElS5xloJElS5w010CQ5MMm5SVYmWZtkcd/6HZN8MMlNSe5Ncm2So/v6bJ3k\n",
       "9CS3Jbk7yeeTPGGYxyFJksbLsEdotgOuAo4C7gP67+p3GvCrwGuAvYB3Ae9J8pq+Pi8HDgYOAHYE\n",
       "zkviaJMkSZupjOpOwUnuAg6vqo/1tH0H+PuqWtrTtgy4qqqOTLITsBo4tKrObtc/EbgR+PWqunCY\n",
       "xyBJksbDuI1qnA/8ZhtSSLIfsAC4oF3/HGAr4JHgUlUrgWuA/YZbqiRJGhdbjrqAPscBHwN+kOSh\n",
       "tu2Iqvpi+3ke8HBV3dG33Spg7pBqlCRJY2bcAs2fAc8FXkpzGmkh8OdJbqyqfxppZZIkaWyNTaBJ\n",
       "sh3NZOHfrqovtM3/lmQBcCzwT8CtwJwku/aN0swDLp1mnwUs7WlaVlXLZqN+SZI0OmMTaIC0r7V9\n",
       "7WvbdoArgQeBRUDvpOC9gMum22lVLZmFWiVJ0hgZaqBpR2H2bBe3AOa3IzB3VNVNSb5Mc5n23cAP\n",
       "aE45HQL8EUBVrUnyYeCUJKuBHwGnAsuBi4Z5LJIkaXwM9bLtJC8AvtIuFj8deTmzqg5L8nPAyTT3\n",
       "otkVWAH8TVWd2rOPx9HMtXk1sC1NkHljVd08zfdVVaW/XZIkTZaR3YdmGAw0kiRtHsbtPjSSJEkb\n",
       "zUAjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6b5ye\n",
       "tq2NlGRyn1vR8tEVkqSZMNB03MJDThh1CbPmkrNOHHUJkqSO8JSTJEnqPAONJEnqPAONJEnqPAON\n",
       "JEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnq\n",
       "PAONJEnqvKEGmiQHJjk3ycoka5MsnqbPU5P8Q5I7k9yT5Moke/Ws3zrJ6UluS3J3ks8necIwj0OS\n",
       "JI2XYY/QbAdcBRwF3AdU78okewBfA/4DOAh4OvA24O6ebqcBLwcOBg4AdgTOS+JokyRJm6kth/ll\n",
       "VXU+cD5AkjOn6fIu4IKq+qOethVTH5LsBBwGHFpVX27bDgFuBF4EXDgrhUuSpLE2NqMa7QjLbwDX\n",
       "JLkgyeoklyd5ZU+35wBb0RNcqmolcA2w31ALliRJY2NsAg3weGB74HjgApoRl7OBjyd5SdtnHvBw\n",
       "Vd3Rt+0qYO6wCpUkSeNlqKecNmAqXH2uqk5rP1+V5JeAI4AvjqYsSZI07sYp0NwOPAR8t6/9WuBV\n",
       "7edbgTlJdu0bpZkHXDrdTpMs6VlcVlXLBlKtJEkaG2MTaKrqgSTfBPbqW/VUfjox+ErgQWARzeko\n",
       "kjyx3eaydex3ySyUK0mSxshQA02S7YA928UtgPlJFgB3VNVNwCnAp5P8M3AxzaXbrwJ+C6Cq1iT5\n",
       "MHBKktXAj4BTgeXARcM8FkmSND6GPSl4X+Bb7WsbYGn7eSlAVX0e+APgWJr71RwOHNJe7j3laOAc\n",
       "4FPAV4EfAy+tqkfd00aSJG0+hn0fmmVsIERV1UeBj65n/QPAke1LkiRprC7bliRJekwMNJIkqfMM\n",
       "NJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIk\n",
       "qfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMM\n",
       "NJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfOGGmiSHJjk3CQrk6xNsng9ff+67fOW\n",
       "vvatk5ye5LYkdyf5fJInzH71kiRpXA17hGY74CrgKOA+oKbrlOQVwL7ALdP0OQ14OXAwcACwI3Be\n",
       "EkebJEnaTG05zC+rqvOB8wGSnDldnyTzaULLrwAX9K3bCTgMOLSqvty2HQLcCLwIuHC2apckSeNr\n",
       "rEY1kmwJnA2cWFXfm6bLc4Ct6AkuVbUSuAbYbyhFSpKksTPUEZoZWAqsrqq/Xsf6ecDDVXVHX/sq\n",
       "YO6sViZJmghJpp3uMEmqKqOuYdjGJtAkeQGwGFjQv2oT97ukZ3FZVS3blP1Jkrpv4SEnjLqEWXPJ\n",
       "WSeOuoSRGJtAAywEdgN+mDySYeYA701yVFU9GbgVmJNk175RmnnApdPttKqWzF7JkiRpHIzTHJoP\n",
       "As8E9mlfC2iucjqVZoIwwJXAg8CiqY2SPBHYC7hsmMVKkqTxMdQRmiTbAXu2i1sA85MsAO6oqpuA\n",
       "2/r6PwjcWlXfB6iqNUk+DJySZDXwI5rAsxy4aEiHIUmSxsywR2j2Bb7VvrahmQT8rfZ9po4GzgE+\n",
       "BXwV+DHw0qqa+ElekiRpesO+D80yNiJEVdUe07Q9ABzZviRJksZqDo0kSdJjYqCRJEmdZ6CRJEmd\n",
       "Z6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CR\n",
       "JEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdt+WoC5A0eZLUqGuYbVWVUdcg\n",
       "6acMNJJmxcJDThh1CbPmkrNOHHUJkvp4ykmSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHXeUANN\n",
       "kgOTnJtkZZK1SRb3rNsyyXuTLE9yd5Jbknw8yZP69rF1ktOT3Nb2+3ySJwzzOCRJ0ngZ9gjNdsBV\n",
       "wFHAfUD1rftF4KT2/beAJwEXJJnT0+804OXAwcABwI7AeUkcbZIkaTM11PvQVNX5wPkASc7sW7cG\n",
       "WNTbluT1wNXAXsDVSXYCDgMOraovt30OAW4EXgRcOMuHIEmSxtC4j2rs1L7f2b4/B9iKnuBSVSuB\n",
       "a4D9hluaJEkaF2MbaJI8Dvhz4NyquqVtngc8XFV39HVfBcwdZn2SJGl8jOWjD5JsCfwdzfyY3xhx\n",
       "OZIkacyNXaBpw8zZwNOBF1TVnT2rbwXmJNm1b5RmHnDpOva3pGdxWVUtG2zFkiRp1MYq0CTZCvgk\n",
       "sDdNmFnd1+VK4EGaycNnt9s8kWbS8GXT7bOqlsxWvZIkaTwMNdAk2Q7Ys13cApifZAFwB3AL8Bng\n",
       "l4CXNt0zr+37n1V1f1WtSfJh4JQkq4EfAacCy4GLhngokiRpjAx7UvC+wLfa1zbA0vbzUuCJwG8C\n",
       "u9GMxNzS83plzz6OBs4BPgV8Ffgx8NKq6r2njSRJ2owM+z40y1h/iNpgwKqqB4Aj25ckSdL4XrYt\n",
       "SZI0UwYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeWN1Y73ZsNU2P3PFqGuQJEmza+IDzd4H/M5zRl3D\n",
       "bLj9B9dwy3VXjroMSZLGwsQHml1222PUJcyKe/6z/6kQkiRtvpxDI0mSOs9AI0mSOs9AI0mSOm/i\n",
       "59BIkrS5STKRD2yuqqxrnYFGkqQJs/CQE0ZdwtB5ykmSJHWegUaSJHWegUaSJHWegUaSJHWegUaS\n",
       "JHWegUaSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHXeUANNkgOT\n",
       "nJtkZZK1SRZP02dJkpuT3Jvk4iR7963fOsnpSW5LcneSzyd5wvCOQpIkjZthj9BsB1wFHAXcB1Tv\n",
       "yiTHAccARwD7AquBLyXZvqfbacDLgYOBA4AdgfOSONokSdJmakYhoB1Z2WEd67ZPcuBM9lNV51fV\n",
       "26vqs8Davv0EOBo4uarOqaqrgcXADsCr2z47AYcBx1bVl6vq28AhwLOAF82kBkmSNHlmOqqxDPgf\n",
       "61i3F3DxAGrZA5gLXDjVUFX3A5cC+7VNzwG26uuzErimp48kSdrMbDmAfWxN32jLYzSvfV/V174a\n",
       "+PmePg9X1R19fVbRhCFNmCS14V7dVVUZdQ2SNAnWGWiS7EEzajL1F+6+fXNZALYFfh/4weyU94iJ\n",
       "/qWmdVt4yAmjLmHWXHLWiaMuQZImxvpGaBYD7+hZPn0d/R6imcS7qW5t3+cCK3va5/asuxWYk2TX\n",
       "vlGaeTSnpv6LFcsveeTzznPns/O83QdQqiRJGifrCzRn0sydAfgKcDjNXJVePwGum+YU0GNxA01g\n",
       "WQRcCZBkG2B/4Ni2z5XAg22fs9s+T6SZx3PZdDvdfZ+FAyhNkiSNs3UGmqpaAawASPJC4MqqumtT\n",
       "vizJdsCe7eIWwPwkC4A7quqmJKcBxye5Fvg+8HbgLuATbU1rknwYOCXJauBHwKnAcuCiTalNkiR1\n",
       "14wmBVfVsgF93740oz3QzItZ2r7OBA6rqlOSbAucAewCfANYVFX39OzjaJrTXJ+imcNzEfCaqnKe\n",
       "jSRJm6kZBZokWwNvBX4PeDLNlU29qqrmbGg/bTBa76XiVTUVcta1/gHgyPYlSZI048u2T6GZQ3M+\n",
       "8A80c2d6OToiSZJGZqaB5hXAkqo6aTaLkSRJeixmeqfg7VnHVUSSJEmjNtNAcx4wo+c1SZIkDdtM\n",
       "Tzn9BXBWexv6L9BcLv0oVXX9IAuTNgeT/mgHSRqWmQaar7fvf9q++hWwwaucJD3apD7awcc6SBq2\n",
       "mQaaw2a1CkmSpE0w0xvrnTnLdUiSJD1mM50ULEmSNLZmeqfgj7Dum+eF5k7BnpaSJEkjMdM5NAfx\n",
       "6EAT4L/R3J9mDfCfA65LkiRpxmY6h2b36dqTHAj8FfCaAdYkSZK0UTZpDk1VXQq8j+Y+NZIkSSMx\n",
       "iEnBNwDPHsB+JEmSHpNNCjRJtgIWAysHU44kSdLGm+lVThfzX69y2hp4KrAr8IcDrkuSJGnGZnqV\n",
       "U/reAe4CPgt8sqqWDbIoSZKkjTHTq5xeMMt1SJIkPWbeKViSJHXejANNkmcl+WyS25M8nOS2JJ9J\n",
       "8szZLFCSJGlDZjopeF/gEuA+4FxgFTAPeCnwkiQLq+qKWatSkiRpPWY6Kfhk4N+AX6mqu6Yak+wA\n",
       "XNSuf/Hgy5MkSdqwmZ5yeh7wnt4wA9Auvxd4/qALkyRJmqmZjtCs60nbM10vSRMlyUT/vVdV2XAv\n",
       "aXzMNND8C/DWJBdV1Y+nGpNsDxwHfGM2ipOkcbXwkBNGXcKsueSsE0ddgrTRZhpojqeZFLwiyXnA\n",
       "D4HdgJcAPwO8YFaqkyRJmoEZzaGpqsuB5wJfAX4NOAb41Xb5ue36gUiyZZJ3J7k+yX3t+4lJ5vT1\n",
       "W5Lk5iT3Jrk4yd6DqkGSJHXLOkdokmwB/E9gRVV9p6quAl7R1+eZwO5J/q2qBnU++Xjg9cD/Br4D\n",
       "7AOcCfwEOKn93uNoQtVi4DrgHcCXkjytqu4eUB2SJKkj1jdC87+AT9I8s2ld7gbOBn5vgDXtC5xb\n",
       "VV+oqh9U1T8C59GMEJEkwNHAyVV1TlVdTRNsdgBePcA6JElSR6wv0BwCfKSqVqyrQ1XdAHyYZjRl\n",
       "UM4HXpjkaQDtqaSDgC+06/cA5gIX9tRxP3ApsN8A65AkSR2xvkDzbOCfZrCPL9OMqgxEVX0Q+Dhw\n",
       "TZIHaG7od2ZV/VXbZV77vqpv09U96yRJ0mZkfVc57QDcOYN93Nn2HYgkRwKvBQ4GrgZ+EXh/khVV\n",
       "9bcb2Hyi7wshSZKmt75AczswH/jqBvbxpLbvoLwNOKmqPt0uX51kPvBW4G+BW9v2ucDKnu3m9qx7\n",
       "xIrllzzyeee589l53u4DLFWSJI2D9QWar9FMtv34BvZxKBsOPRsjwNq+trVtO8ANNMFlEXAlQJJt\n",
       "gP2BY/t3tvs+CwdYmiRJGkfrCzTvA76a5DTgj6vqgd6VSR4HnAL8Ck2YGJTPAX+S5AbguzSnnN4M\n",
       "fBSgqqqt6fgk1wLfB95OczXWJwZYhyRJ6oh1Bpqq+nqStwCnAq9OciFwY7t6Ps0Iya7AMVX19QHW\n",
       "9Gbgx8AZNKeRfgh8CHhnT22nJNm27bMLzaMXFlXVPQOsQ5IkdcR6H31QVacl+RbN85peDmzTrroP\n",
       "WEbzBO5/HmRBbSg5lmlOH/X1WwosHeR3S5Kkbtrgs5yq6lLg0vbRAz/bNt9RVQ/NamWSJEkzNNOH\n",
       "U1JVD/Nf7/0iSZI0cjN6OKUkSdI4M9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTO\n",
       "M9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BI\n",
       "kqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOG8tAk2S3JB9NsjrJ\n",
       "fUmuTnJgX58lSW5Ocm+Si5PsPap6JUnSaI1doEmyM/A1oICXAHsBRwCre/ocBxzTtu/brvtSku2H\n",
       "XrAkSRq5LUddwDT+GLi5qg7tabtx6kOSAEcDJ1fVOW3bYppQ82rgQ8MrVZIkjYOxG6EBXgZcnuRT\n",
       "SVYl+XaSw3vW7wHMBS6caqiq+4FLgf2GW6okSRoH4xhongK8Efh3YBHwfuA9PaFmXvu+qm+71T3r\n",
       "JEnSZmQcTzltAVxeVW9rl5cn2RM4HDhjA9vWrFYmSZLG0jgGmluA7/a1XQs8uf18a/s+F1jZ02du\n",
       "z7pHrFh+ySOfd547n53n7T6oOiVJ0pgYx0DzNZorm3o9FVjRfr6BJrgsAq4ESLINsD9wbP/Odt9n\n",
       "4WzVKUmSxsQ4zqF5H/C8JMcn+YUkvwu8ifZ0U1UVcBpwXJLfTvIM4EzgLuATI6pZkiSN0NiN0FTV\n",
       "FUleBrwbOIHmku23V9Vf9vQ5Jcm2NCFnF+AbwKKqumcUNUuSpNEau0ADUFVfBL64gT5LgaXDqUiS\n",
       "JI2zcTzlJEmStFEMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfPG8rJtSdJoJfHZeOoUA40k\n",
       "6b9YeMgJoy5h1lxy1omjLkGzwFNOkiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0\n",
       "kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp\n",
       "8ww0kiSp8ww0kiSp8ww0kiSp88Y60CR5a5K1SU7va1+S5OYk9ya5OMneo6pRkiSN3tgGmiTPA14H\n",
       "XAVUT/txwDHAEcC+wGrgS0m2H0WdkiRp9MYy0CTZCfg74LXAnT3tAY4GTq6qc6rqamAxsAPw6lHU\n",
       "KkmSRm8sAw3wIeAzVXUJkJ72PYC5wIVTDVV1P3ApsN9QK5QkSWNjy1EX0C/J64Cn8NMRl+pZPa99\n",
       "X9W32Wrg52e5NEmSNKbGKtAkeRrwLmD/qnp4qplHj9KsS03XuGL5JY983nnufHaet/smVilJksbN\n",
       "WAUa4PnAzwJXN9NlAJgDHJDk9cAz2ra5wMqe7eYCt063w933WTg7lUqSpLExbnNozqEJLfu0rwXA\n",
       "FcDZ7efv0wSXRVMbJNkG2B+4bNjFSpKk8TBWIzRVtQZY09uW5F7gzqr6brt8GnB8kmtpAs7bgbuA\n",
       "Twy5XEmSNCbGKtCsQ9EzP6aqTkmyLXAGsAvwDWBRVd0zovokSdKIjX2gqaqDpmlbCiwdQTmSJGkM\n",
       "jdscGkmSpI1moJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1n\n",
       "oJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEk\n",
       "SZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ03doEmyVuTfDPJmiSr\n",
       "k5yb5OnT9FuS5OYk9ya5OMneo6hXkiSN3tgFGmAh8AHg+cALgYeAi5LsMtUhyXHAMcARwL7AauBL\n",
       "SbYffrmSJGnUthx1Af2q6td6l5McAqwB9gO+kCTA0cDJVXVO22cxTah5NfCh4VYsSZJGbRxHaPrt\n",
       "SFPnne3yHsBc4MKpDlV1P3ApTeiRJEmbmS4EmvcD3wa+3i7Pa99X9fVb3bNOkiRtRsbulFOvJKfS\n",
       "jLrsX1U1g01m0keSJE2YsQ00Sd4HvBI4qKpW9Ky6tX2fC6zsaZ/bs+4RK5Zf8sjnnefOZ+d5uw+6\n",
       "VEmSNGJjGWiSvB/4XZowc13f6htogssi4Mq2/zbA/sCx/fvafZ+Fs1usJEkaubELNEnOAF4DvAxY\n",
       "k2RqXsxdVXVPVVWS04Djk1wLfB94O3AX8ImRFC1JkkZq7AIN8AaauTBf7mtfArwToKpOSbItcAaw\n",
       "C/ANYFFV3TPEOiVJ0pgYu0BTVTO68qqqlgJLZ7kcSZLUAV24bFuSJGm9DDSSJKnzDDSSJKnzDDSS\n",
       "JKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnz\n",
       "DDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSS\n",
       "JKnzDDSSJKnzDDSSJKnzDDSSJKnzOhtokrwxyQ1J7ktyRZL9R12TJEkajU4GmiSvAk4DTgIWAJcB\n",
       "5yd50kgLkyRJI9HJQAMcA3ykqj5cVd+rqiOBHwJvGHFdkiRpBDoXaJI8Dng2cGHfqguB/YZfkSRJ\n",
       "GrXOBRrgZ4E5wKq+9tXAvOGXI0mSRm3LURcw25ZfeNaaUdcwG+6/Z83WwDajrkOSpHGQqhp1DRul\n",
       "PeV0D3BwVX22p/0MYO+qOqinrVsHJ0mS1quqMl1750ZoquqBJFcCi4DP9qx6MfCZvr7THrQkSZos\n",
       "nQs0rVOBs5JcTnPJ9h/SzJ/5q5FWJUmSRqKTgaaqPp1kV+DtwG7Ad4CXVNVNo61MkiSNQufm0EiS\n",
       "JPXr4mXbMzKpj0ZIcmCSc5OsTLI2yeJR1zRISd6a5JtJ1iRZ3R7r00dd1yAkOTzJ8vbY1iS5LMlL\n",
       "Rl3XbGl/lmuTnD7qWgYhyZL2eHpft4y6rkFKsluSj7b/792X5OokB466rkFIsmKan9/aJOeNurZN\n",
       "lWTLJO9Ocn37c7s+yYlJ5oy6tmGayEAz4Y9G2A64CjgKuA+YtCG2hcAHgOcDLwQeAi5KsstIqxqM\n",
       "m4A/Bn4ReA7wFeBzSfYZaVWzIMnzgNfR/FmdpD+j19LM15t6PXO05QxOkp2Br9H8vF4C7AUcQXOP\n",
       "r0nwHB79s3s2zbF+apRFDcjxwOuBNwFPo/n98EbgraMsatgm8pRTkn8B/rWqXt/Tdh3w91V1/Ogq\n",
       "G6wkdwGHV9XHRl3LbEmyHbAG+K2q+sKo6xm0JHcAf1JV/2/UtQxKkp2AK4HfB5YA32kfT9JpSZYA\n",
       "v1NVExNieiV5N3BAVR0w6lqGIcnbgLcAu1XVT0Zdz6ZI8o/A7VX12p62jwK7VNVvjq6y4Zq4ERof\n",
       "jTBxdqT5c3rnqAsZpCRzkhxMc3PES0ddz4B9CPhMVV0CTNqtE56S5OZ2SP/sJHuMuqABehlweZJP\n",
       "JVmV5NtJDh91UbMhSWgC9991Pcy0zgdemORpAEn2Bg4CvjjSqoask1c5bYCPRpgs7we+DXx91IUM\n",
       "QpJn0hzL1jSnDF9ZVd8bbVWDk+R1wFOAV7dNkzQE/A1gMc1pp7k0V1leluTpVfWjkVY2GE+hOU1x\n",
       "KvBumlOjpyehqs4YaWWD92Jgd2AiRkar6oNJnghck+Qhmt/tJ1XVZnUrk0kMNJoQSU6lGVXbvybn\n",
       "3Oi1wLOAnYDfBT6Z5KCqumK0ZW269l+H76L5eT081cyEjNJU1QU9i/+W5OvADTQh532jqWqgtgAu\n",
       "r6q3tcvLk+wJHA5MWqB5Hc2xfmfUhQxCkiOB1wIHA1fThNH3J1lRVX870uKGaBIDze3AwzT/guo1\n",
       "F/jh8MvRY5HkfcArgYOqasWIyxmYqnoQuL5d/HaSfWl+Ybx23Vt1xvNpRkivbkb0gWa09IAkrwe2\n",
       "a49/IlTVvUmuBn5h1LUMyC3Ad/vargWePIJaZk2SxwO/STMaNSneRjMi8+l2+eok82kmBW82gWbi\n",
       "5tBU1QM0ExIX9a16Mc3VThpzSd4PvAp4YVVdN+p6ZtkcJuf/w3OAZwD7tK8FwBXA2cCCSQozAEm2\n",
       "Af4Hk/MPpa/RXNnU66nAiuGXMqsOBe6n+XM5KQKs7Wtby4SMjs7UJI7QwAQ/GqG96mfPdnELYH6S\n",
       "BcAdk3Cn5PYho6+hmaC4JsnUvKe7quqe0VW26ZK8BzgPWAnsQDPPZCHwa6Osa1Cqag3NFWmPSHIv\n",
       "cGdV9f/Lv3OS/BlwLs3l948HTgC2BT46yroG6H00c4KOBz5Nc9riTUzQpb/tZOD/A3yyqu4ddT0D\n",
       "9DngT5LcQDPK9ovAm5mcP5szMpGXbQMkeQPNPT+mHo3w5qr66mir2nRJXkBz/xJoJlxOJfAzq+qw\n",
       "kRQ1QEnW8ujjmrKkqt45gpIGJslHaK48mEfzi3858H+r6ksjLWwWJbmYybls+2zgQJrTarfRTO4+\n",
       "oaquHWlhA9Te6PHdNPcyuRH4QFV9YLRVDU6Sg4CLgOdOwry1Ke0/dJcCv8NPp1ecDbyzPWuxWZjY\n",
       "QCNJkjYfk3LuXpIkbcYMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNFLHJVk7\n",
       "g9f1G97TBr9nQZIlSXaZYf9lPd//UJIfJfl2kr9Isvcm1HFokoE++yrJC9o6XziAfZ2ZZIN37W6P\n",
       "Y22SiXpWkjQqk/roA2lz8ryez6F5ptK/Akt62n8ygO9ZALwD+Bhw5wy3WQ68vv28I/BM4DDgD5Mc\n",
       "VVV/+Riysix2AAAF3UlEQVTqOJTmGVgfeQzbDot3LJWGzEAjdVxVXd67nOQnwO397QO0MQ+8u6uv\n",
       "jouSnE5zW/bTk3xzkm5B32OzeiigNA485SRtBpLskeTjSVYnub899fOyvj5PTXJOklVJ7ktyY5JP\n",
       "J5mT5FDgb9uu3+85lbTRp0uq6iHgjcBDwCPPeEryC0nOSnJ9knuT/EeSDybZuafPMprnKf1yTw1f\n",
       "adf9XJK/TvK9JPck+UF7zD+/sTVOZyb19fXfL8k32/+WNyQ5Yobf8wdJlrfb3Zbkb/pP8yU5Ksk1\n",
       "bR0/ar/nZevap7Q5cIRGmnBJngT8C3ArcDTNgxUPBj6b5GVV9Y9t1y8Ad9A8nf524InAr9P8w+c8\n",
       "4CTg7cAraJ4YTrvPjVZVtyW5Avjlnubd2v0e09bxFOB44IvAfm2fNwB/19Y0dSrrx+37LjSn1t4G\n",
       "rGr3dyzwtSR7VdWmnnabSX1TdgQ+CbwH+Hfg94C/SHJXVa3zCcjtE9mPAd4PvIXmZ3AS8Iwk+1XV\n",
       "2iT/C/gzmocR/jPNE7/3aY9f2mwZaKTJt4RmTsfCqpqa+/KlNui8E/jHJD8L/Heap9Kf17Pt2e37\n",
       "7T0Ti/+1qjZ5kjFwE/DsqYWq+meaX9AAJPk68B/ApUkWVNW/VtU1Se4Ctug/pVZV1/HoEZ85NE/E\n",
       "vpEmmH1uU4qdSX093XcAXldVn26XL0zyBJoQMm2gSbI7TQBbUlUn9bRfB3wVeCnweeD5wFW9fYAL\n",
       "NuXYpEngKSdp8v0azSjCj5NsOfUCLgT2SbI9zYjD9cB7k/yfJHsOoa4Aax9ZSB6X5Pgk1ya5F3gA\n",
       "uLRd/dQZ7TB5Q3u65i7gQZowM+PtN7DvjanvIeCzfW2fAp68nlNgL6b5O/kTfT+ny4G7gQPafpcD\n",
       "C9qrxV6U5Gc28dCkiWCgkSbf44HFNL/gH+h5nUIzcrNrVRXNL9QrgJOB77VzRP5wFut6EvDDnuWT\n",
       "gT+luYrqJcC+wMvbddtsaGdJ3gScQRPUfrvdfuoKsA1uPwMbU99/VtXDfW2r2vcnrGP/j2/f/51H\n",
       "/5weALYDdgWoqo/RnHp7Ls3IzB1JPptk/mM4JmlieMpJmny304wkvHcd638IUFU30AQfkuwDHAF8\n",
       "MMmKqhroKY0kjwd+CfhET/PBwEer6t09/XbciN0eDFxUVX/Us/0em1rrY6xvlyRz+kLN3Pb95nVs\n",
       "c0f7/mKmvyx+aj1V9SHgQ0l2An4V+HOaEaDnTbOdtFkw0EiT7wKaeRffrar7Z7JBVS1P8hbg94Gn\n",
       "t/uYmlS7Sac4kmwFfJBmhPgvelZtS3Oqptd0N9D7Ce1oRZ9tgTUz2P6xmml90Nwn5xU0IWPKwcCN\n",
       "VXXLOra5kOYU3Pyq+vJMCqqqNcCnkzwP+IOZbCNNKgONNHn674HyDpp5F5cm+QDNvJJdgGcAe1TV\n",
       "7yd5Fs2VNZ+kmeg6h+YGdg8CX2n38932/fAkH2vXLa+qB9dTy45JntvWtAPNjfVeC+wJvLGqvt3T\n",
       "9wJgcZLvtDW8nCaI9bsaeGOSV9LM+/lxOyH4AuC4JG8Fvgm8EPid9dQ2nQOT/Le+tger6vMbUR/A\n",
       "XcAp7WTrqaucfoV2BGw6VXV9kvcCH0jyNJpRtftpTs29CPibqlqW5EM0V3Z9A1hNM3/nNcA/beSx\n",
       "ShPFQCNNnkfdpbaqbkrySzRXO70b+Dma0xff4adX3PyQJugcQ3Op8P3AVcBvTIWOdtRmCc1IwOto\n",
       "QsoewA/WU8ezaK40Kppf8tfTBKRXVtU1ff3f1O7zXe3yF2iCQP8NAt8LPA34G2B7YBlNeHknsDPw\n",
       "Zpo5LctoTsfM5Iqsqf9m75hm3d00l2HPtL6iGSl6Fc0I1DNpLm8/sqrOWsf3NgtVb0tyDXB4+yqa\n",
       "q8EuAq5ru32VJhQeAuwE3AKcRTO/R9pspZkLKEmS1F1e5SRJkjrPQCNJkjrPQCNJkjrPQCNJkjrP\n",
       "QCNJkjrPQCNJkjrPQCNJkjrPQCNJkjrPQCNJkjrv/wNeTUGLCw9shQAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aeced90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Remove the plot frame lines. They are unnecessary chartjunk.  \n",
    "ax = plt.subplot(111)  \n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "\n",
    "# Ensure that the axis ticks only show up on the bottom and left of the plot.  \n",
    "# Ticks on the right and top of the plot are generally unnecessary chartjunk.  \n",
    "ax.get_xaxis().tick_bottom()  \n",
    "ax.get_yaxis().tick_left()  \n",
    "\n",
    "# Make sure your axis ticks are large enough to be easily read.  \n",
    "# You don't want your viewers squinting to read your plot.  \n",
    "plt.xticks(unique_test, fontsize=14)  \n",
    "plt.yticks(fontsize=14)  \n",
    "\n",
    "# Along the same vein, make sure your axis labels are large  \n",
    "# enough to be easily read as well. Make them slightly larger  \n",
    "# than your axis tick labels so they stand out.  \n",
    "plt.xlabel(\"Test Data Lables\", fontsize=16)  \n",
    "plt.ylabel(\"Count\", fontsize=16)\n",
    "\n",
    "ax.hist(labels[4000:5000], bins=range(10), cumulative=False, color=\"#3F5D7D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 103.,  130.,  132.,   94.,  134.,  109.,   57.,  148.,   93.]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " <a list of 9 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGKCAYAAAAbo9ubAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3X28ZWVd9/HPl0GBQB4km6HUAe9Q8iFIJZV4ENSpSNOs\n",
       "kFAE7fY2BRWROxKkBlFM7kIQsKRUEAPBDCUUQ9SBfEAUbVQEMWFIQBgcaEQe5GF+9x9rnWm7OWdm\n",
       "z7DP3nud+bxfr/3aZ13r2nv/1pwD53uu61prpaqQJEnqso3GXYAkSdLDZaCRJEmdZ6CRJEmdZ6CR\n",
       "JEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdN9JAk2TPJBckuTHJqiQHTdPniUn+JckdSe5KcmWSnXr2b5Lk\n",
       "lCS3Jflpkk8m+ZVRHockSZosox6h2Rz4FvAm4B7g567ql2QH4EvAD4C9gacARwM/7el2EvBSYH9g\n",
       "D2BL4MIkjjZJkrSByriuFJzkTuCQqvpwT9vZwINVdeAMr9kKWA4cXFXntG2PBW4AfreqLp79yiVJ\n",
       "0qSZmFGNdoTlhcDVST6TZHmSK5Ls19PtGcAjgNXBpapuBK4GdhtpwZIkaWJMTKABfgnYAjgK+Azw\n",
       "fOAc4J+S7Nv2WUAzgrOi77W3AvNHVagkSZosG4+7gB5T4eoTVXVS+/W3kjwTOBT49HjKkiRJk26S\n",
       "As2PgQeA7/a1XwO8rP36FmBekm37RmkWAJf1v2GSAo7taVpSVUuGVrEkSZoIExNoquq+JF8Ddurb\n",
       "9URgWfv1lcD9wCKa6aipRcE7AV+e4X0Xz0K5kiRpgow00CTZHNix3dwIWJhkF2BFVf0QOAE4L8m/\n",
       "A1+gOXX7ZcCLAapqZZIPACckWQ7cDpwILAUuGeWxSJKkyTHS07aTPBf4fLtZQNqvz6iqV7d9DqJZ\n",
       "GPw44FrgXVV1bs97PBL4G+AAYDOaIPP6qrppms+rqkp/uyRJmlvGdh2aUTDQSJK0YZik07YlSZLW\n",
       "i4FGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFG\n",
       "kiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1\n",
       "3sbjLkCSpFFKUuOuYbZVVcZdw6gZaCRJG5y9Djxm3CXMmkvPOm7cJYyFU06SJKnzDDSSJKnzDDSS\n",
       "JKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzRhpokuyZ5IIkNyZZleSgNfR9\n",
       "f9vnLX3tmyQ5JcltSX6a5JNJfmX2q5ckSZNq1CM0mwPfAt4E3ANMez+NJH8E7ArcPE2fk4CXAvsD\n",
       "ewBbAhcmcbRJkqQN1Ejv5VRVFwEXASQ5Y7o+SRbShJbnAZ/p27cV8Grg4Kr6XNt2IHAD8Hzg4tmq\n",
       "XZIkTa6JGtVIsjFwDnBcVX1vmi7PAB5BT3CpqhuBq4HdRlKkJEmaOBMVaIBjgeVV9f4Z9i8AHqyq\n",
       "FX3ttwLzZ7UySZI0sUY65bQmSZ4LHATs0r9r9NVIkqQumZhAA+wFbAf8KFmdYeYB707ypqp6PHAL\n",
       "MC/Jtn2jNAuAy6Z70ySLezaXVNWSYRcuSZLGa5ICzfuAj/VsB/g34GzgH9q2K4H7gUU0a21I8lhg\n",
       "J+DL071pVS2enXIlSdKkGGmgSbI5sGO7uRGwMMkuwIqq+iFwW1//+4Fbqur7AFW1MskHgBOSLAdu\n",
       "B04ElgKXjOgwJEnShBn1ouBdgW+0j01pFgF/o30e1GHA+cC5wBeBnwAvqqppr2kjSZLmvlFfh2YJ\n",
       "6xCiqmqHadruA97YPiRJkibutG1JkqR1ZqCRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CR\n",
       "JEmdN0m3PpA0RySZ8xe6rCpvnCtNEAONpFmx14HHjLuEWXPpWceNuwRJfZxykiRJnWegkSRJnWeg\n",
       "kSRJnecaGk0sF5ZKkgZloNFEc2GpJGkQTjlJkqTOM9BIkqTOc8qpwzaENSaSJA3CQNNxrjGRJMkp\n",
       "J0mSNAcYaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJ\n",
       "UucZaCRJUucZaCRJUucZaCRJUueNNNAk2TPJBUluTLIqyUE9+zZO8u4kS5P8NMnNSf4pyeP63mOT\n",
       "JKckua3t98kkvzLK45AkSZNl1CM0mwPfAt4E3ANU377fAN7RPr8YeBzwmSTzevqdBLwU2B/YA9gS\n",
       "uDCJo02SJG2gNh7lh1XVRcBFAEnO6Nu3EljU25bktcBVwE7AVUm2Al4NHFxVn2v7HAjcADwfuHiW\n",
       "D0GSJE2gSR/V2Kp9vqN9fgbwCHqCS1XdCFwN7Dba0iRJ0qSY2ECT5JHA3wIXVNXNbfMC4MGqWtHX\n",
       "/VZg/ijrkyRJk2OkU06DSrIx8BGa9TEvHHM5kiRpwk1coGnDzDnAU4DnVtUdPbtvAeYl2bZvlGYB\n",
       "cNkM77e4Z3NJVS0ZbsWSJGncJirQJHkE8FHgyTRhZnlflyuB+2kWD5/TvuaxNIuGvzzde1bV4tmq\n",
       "V5IkTYaRBpokmwM7tpsbAQuT7AKsAG4GPgY8E3hR0z0L2r7/XVX3VtXKJB8ATkiyHLgdOBFYClwy\n",
       "wkORJEkTZNSLgncFvtE+NgWObb8+Fngs8PvAdjQjMTf3PPbreY/DgPOBc4EvAj8BXlRVvde0kSRJ\n",
       "G5BRX4dmCWsOUWsNWFV1H/DG9iFJkjS5p21LkiQNykAjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0Aj\n",
       "SZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6\n",
       "z0AjSZI6z0AjSZI6z0AjSZI6b+NxFyBJXZSkxl3DbKqqjLsGaV0YaCRpPex14DHjLmHWXHrWceMu\n",
       "QVpnTjlJkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTO\n",
       "m/NXCk6y27hrkCRJs2vOB5rNt37Mp8ddw2y47967N7n/3rvGXYYkSRNhpIEmyZ7AEcDTgV8GXlVV\n",
       "Z/b1WQy8BtgG+CpwSFV9t2f/JsDfAPsDmwGfA15fVTdN95nPfNGfbTX8Ixm/G6/+Kj/4+sXjLkOS\n",
       "pIkw6jU0mwPfAt4E3AP83N1qkxwJHA4cCuwKLAc+m2SLnm4nAS+lCTR7AFsCFyZxPZAkSRuokYaA\n",
       "qrqoqt5WVR8HVvXuSxLgMOBdVXV+VV0FHAQ8Cjig7bMV8GrgiKr6XFV9EzgQ+HXg+SM8FEmSNEEm\n",
       "aVRjB2A+sHoeparuBS4Dphb2PgN4RF+fG4Gre/pIkqQNzCQFmgXt86197ct79i0AHqyqFX19bqUJ\n",
       "Q5IkaQM0SYFmTWrtXSRJ0oZqkk7bvqV9ng/c2NM+v2ffLcC8JNv2jdIsoJmaeohlSy9d/fXW8xey\n",
       "9YLth1WvJEmaEJMUaK6nCSyLgCsBkmwK7E5zqjdt+/1tn3PaPo8FdgK+PN2bbr/zXrNatCRJGr9R\n",
       "X4dmc2DHdnMjYGGSXYAVVfXDJCcBRyW5Bvg+8DbgTuBsgKpameQDwAlJlgO3AycCS4FLRnkskiRp\n",
       "cox6hGZX4PPt1wUc2z7OAF5dVSck2Qw4jebCepcDi6qq95K4hwEPAOfSXFjvEuAVVeU6G0mSNlAj\n",
       "DTRVtYS1LESuqqmQM9P++4A3tg9JkqTOnOUkSZI0IwONJEnqPAONJEnqPAONJEnqPAONJEnqPAON\n",
       "JEnqPAONJEnqvEm69YG0wUniBSElaQgMNNIY7XXgMeMuYVZcetZx4y5B0gbGQCNJ0hwzV0d/qyoz\n",
       "7TPQSJI0x8zV0d81cVGwJEnqPAONJEnqPAONJEnqvIECTZI9kzxqhn1bJNlzuGVJkiQNbtARmiXA\n",
       "r82wbyfgC0OpRpIkaT0MY8ppE2DVEN5HkiRpvcx42naSHYAdgKlzvndNskVft82APwX+a3bKkyRJ\n",
       "Wrs1XYfmIOAve7ZPmaHfA8ChQ6tIkiRpHa0p0JxBs3YG4PPAIcDVfX1+BlxbVSuGXpkkSdKAZgw0\n",
       "VbUMWAaQZB/gyqq6czRlSZIkDW6gWx9U1ZJZrkOSJGm9DXodmk2SLE7yvST3JFnV93hwtguVJEma\n",
       "yaA3pzyBZg3NRcC/0Kyd6TUn7+opSZK6YdBA80fA4qp6x2wWI0mStD4GvbDeFsCXZ7MQSZKk9TVo\n",
       "oLkQ8H5NkiRpIg065fRe4KwkBXwKuL2/Q1VdN8zCJEmSBjVooPlK+/xX7aNfAfOGUpEkSdI6GjTQ\n",
       "vHpWq5AkSXoYBr2w3hmzXIckSdJ6G3RR8Mgk2TjJ8Umuay/id12S45LM6+u3OMlNSe5O8oUkTx5X\n",
       "zZIkabwGGqFJ8iFmvnhegKqqYU1LHQW8Fngl8G1gZ5obZf4MeEdbz5HA4TR3BL+W5q7gn03ypKr6\n",
       "6ZDqkCRJHTHoGpq9+flAE+DRNNenWQn89xBr2hW4oKo+1W7/V5ILgWcBJAlwGPCuqjq/bTsIWA4c\n",
       "AJw+xFokSVIHDDTlVFXbV9UOPY/tq2pL4LnAj4A/HGJNFwH7JHkSQDuVtDfN6eIAOwDzgYt76rsX\n",
       "uAzYbYh1SJKkjhh0hGZaVXVZkvfQXKdm92EUVFXvS/JY4OokD7Q1vqOq/r7tsqB9vrXvpcuBXx5G\n",
       "DZIkqVseVqBpXQ88fQjvA0CSNwKvAvYHrgJ+Azg5ybKq+uBaXv6QdT7Lll66+uut5y9k6wXbD6tU\n",
       "SZI0IR5WoEnyCJqFuTcOpxwAjqYZkTmv3b4qyULgrcAHgVva9vl9nzu/Z99q2++81xBLkyRJk2jQ\n",
       "s5y+wENHPzYBnghsC/zZEGsKsKqvbVXbDs2I0C3AIuDKtr5Naaa8jhhiHZIkqSMGHaFJ3zPAncDH\n",
       "gY9W1ZIh1vQJ4C+SXA98l2bK6c3AmdCcH57kJOCoJNcA3wfe1tZz9hDrkCRJHTHolYKfO8t19Hoz\n",
       "8BPgNJpppB/RnIr99p56TkiyWdtnG+ByYFFV3TXCOiVJ0oQYxqLgoWpDyRGsZfqoqo4Fjh1JUZIk\n",
       "aaINfOuDJL+e5ONJfpzkwSS3JflYkqfNZoGSJElrM+ii4F2BS4F7gAtorgGzAHgRsG+Svarq67NW\n",
       "pSRJ0hoMOuX0LuA7wPOq6s6pxiSPAi5p979g+OVJkiSt3aBTTs8G/ro3zAC02+8GnjPswiRJkgY1\n",
       "aKCZ6U7bg+6XJEmaNYMGmq8Cb02yZW9jki2AI2lOm5YkSRqLQdfQHEWzKHhZkgtprg2zHbAv8As0\n",
       "d92WJEkai0EvrHdFkmcBfwn8Ds3F7G4HPg8cV1Xfnr0SJUmS1mzGQJNkI+D3gGVV9e2q+hbwR319\n",
       "ngZsn+Q7VeU6GkmSNBZrWkPzcuCjNPdImslPgXOAPxlmUZIkSetiTYHmQOBDVbVspg5VdT3wAeCV\n",
       "Q65LkiRpYGsKNE8H/m2A9/gcsOtwypEkSVp3awo0jwLuGOA97mj7SpIkjcWaAs2PgYUDvMfj2r6S\n",
       "JEljsaZA8yXgoAHe42Dgi0OpRpIkaT2sKdC8B3hekpOSPLJ/Z5JHJjkJeF7bV5IkaSxmvA5NVX0l\n",
       "yVuAE4EDklwM3NDuXggsArYFDq+qr8x6pZIkSTNY45WCq+qkJN+guV/TS4FN2133AEto7sD977Na\n",
       "oSRJ0lqs9dYHVXUZcFmSecAvts0rquqBWa1MkiRpQIPenJKqehC4dRZrkSRJWi9rWhQsSZLUCQYa\n",
       "SZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeRMZaJJs\n",
       "l+TMJMuT3JPkqiR79vVZnOSmJHcn+UKSJ4+rXkmSNF4TF2iSbA18CShgX2An4FBgeU+fI4HD2/Zd\n",
       "232fTbLFyAuWJEljN/DNKUfoz4GbqurgnrYbpr5IEuAw4F1VdX7bdhBNqDkAOH10pUqSpEkwcSM0\n",
       "wEuAK5Kcm+TWJN9MckjP/h2A+cDFUw1VdS9wGbDbaEuVJEmTYBIDzROA1wP/CSwCTgb+uifULGif\n",
       "b+173fKefZIkaQMyiVNOGwFXVNXR7fbSJDsChwCnreW1NauVSZKkiTSJgeZm4Lt9bdcAj2+/vqV9\n",
       "ng/c2NNnfs++1ZYtvXT111vPX8jWC7YfVp2SJGlCTGKg+RLNmU29nggsa7++nia4LAKuBEiyKbA7\n",
       "cET/m22/816zVackSZoQk7iG5j3As5McleRXk/wx8Aba6aaqKuAk4Mgkf5DkqcAZwJ3A2WOqWZIk\n",
       "jdHEjdBU1deTvAQ4HjiG5pTtt1XV3/X0OSHJZjQhZxvgcmBRVd01jpolSdJ4TVygAaiqTwOfXkuf\n",
       "Y4FjR1ORJEmaZJM45SRJkrRODDSSJKnzJnLKSZI0Xkm8rpc6xUAjSXqIvQ48ZtwlzJpLzzpu3CVo\n",
       "FjjlJEmSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9A\n",
       "I0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mS\n",
       "Os9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOm+iA02StyZZ\n",
       "leSUvvbFSW5KcneSLyR58rhqlCRJ4zexgSbJs4HXAN8Cqqf9SOBw4FBgV2A58NkkW4yjTkmSNH4T\n",
       "GWiSbAV8BHgVcEdPe4DDgHdV1flVdRVwEPAo4IBx1CpJksZvIgMNcDrwsaq6FEhP+w7AfODiqYaq\n",
       "uhe4DNhtpBVKkqSJsfG4C+iX5DXAE/ifEZfq2b2gfb6172XLgV+e5dIkSdKEmqhAk+RJwDuB3avq\n",
       "walmfn6UZia19i6SJGkumqhAAzwH+EXgqma5DADzgD2SvBZ4ats2H7ix53XzgVume8NlSy9d/fXW\n",
       "8xey9YLth1uxJEkau0kLNOcDV/RsB/gQcC1wPPB9muCyCLgSIMmmwO7AEdO94fY77zWL5UqSpEkw\n",
       "UYGmqlYCK3vbktwN3FFV3223TwKOSnINTcB5G3AncPaIy5UkSRNiogLNDIqe9TFVdUKSzYDTgG2A\n",
       "y4FFVXXXmOqTJEljNvGBpqr2nqbtWODYMZQjSZIm0KReh0aSJGlgBhpJktR5BhpJktR5BhpJktR5\n",
       "BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJ\n",
       "ktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5\n",
       "BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5Exdokrw1ydeS\n",
       "rEyyPMkFSZ4yTb/FSW5KcneSLyR58jjqlSRJ4zdxgQbYCzgVeA6wD/AAcEmSbaY6JDkSOBw4FNgV\n",
       "WA58NskWoy9XkiSN28bjLqBfVf1O73aSA4GVwG7Ap5IEOAx4V1Wd3/Y5iCbUHACcPtqKJUnSuE3i\n",
       "CE2/LWnqvKPd3gGYD1w81aGq7gUuowk9kiRpA9OFQHMy8E3gK+32gvb51r5+y3v2SZKkDcjETTn1\n",
       "SnIizajL7lVVA7xkkD6SJGmOmdhAk+Q9wH7A3lW1rGfXLe3zfODGnvb5PftWW7b00tVfbz1/IVsv\n",
       "2H7YpUqSpDGbyECT5GTgj2nCzLV9u6+nCS6LgCvb/psCuwNH9L/X9jvvNbvFSpKksZu4QJPkNOAV\n",
       "wEuAlUmm1sXcWVV3VVUlOQk4Ksk1wPeBtwF3AmePpWhJkjRWExdogNfRrIX5XF/7YuDtAFV1QpLN\n",
       "gNOAbYDLgUVVddcI65QkSRNi4gJNVQ105lVVHQscO8vlSJKkDujCaduSJElrZKCRJEmdZ6CRJEmd\n",
       "Z6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CR\n",
       "JEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmd\n",
       "Z6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmd19lA\n",
       "k+T1Sa5Pck+SryfZfdw1SZKk8ehkoEnyMuAk4B3ALsCXgYuSPG6shUmSpLHoZKABDgc+VFUfqKrv\n",
       "VdUbgR8BrxtzXZIkaQw6F2iSPBJ4OnBx366Lgd1GX5EkSRq3zgUa4BeBecCtfe3LgQWjL0eSJI3b\n",
       "xuMuYLYtvfisleOuYTbce9fKTYBNx12HJEmTIFU17hrWSTvldBewf1V9vKf9NODJVbV3T1u3Dk6S\n",
       "JK1RVWW69s6N0FTVfUmuBBYBH+/Z9QLgY319pz1oSZI0t3Qu0LROBM5KcgXNKdt/RrN+5u/HWpUk\n",
       "SRqLTgaaqjovybbA24DtgG8D+1bVD8dbmSRJGofOraGRJEnq18XTtgcyV2+NkGTPJBckuTHJqiQH\n",
       "jbumYUry1iRfS7IyyfL2WJ8y7rqGIckhSZa2x7YyyZeT7DvuumZL+71cleSUcdcyDEkWt8fT+7h5\n",
       "3HUNU5LtkpzZ/rd3T5Krkuw57rqGIcmyab5/q5JcOO7aHq4kGyc5Psl17fftuiTHJZk37tpGaU4G\n",
       "mjl+a4TNgW8BbwLuAebaENtewKnAc4B9gAeAS5JsM9aqhuOHwJ8DvwE8A/g88IkkO4+1qlmQ5NnA\n",
       "a2h+VufSz+g1NOv1ph5PG285w5Nka+BLNN+vfYGdgENprvE1FzyDn//ePZ3mWM8dZ1FDchTwWuAN\n",
       "wJNofj+8HnjrOIsatTk55ZTkq8B/VNVre9quBf65qo4aX2XDleRO4JCq+vC4a5ktSTYHVgIvrqpP\n",
       "jbueYUuyAviLqvqHcdcyLEm2Aq4E/hRYDHy7vT1JpyVZDPxhVc2ZENMryfHAHlW1x7hrGYUkRwNv\n",
       "Abarqp+Nu56HI8m/Aj+uqlf1tJ0JbFNVvz++ykZrzo3QeGuEOWdLmp/TO8ZdyDAlmZdkf5qLI142\n",
       "7nqG7HTgY1V1KTDXLp3whCQ3tUP65yTZYdwFDdFLgCuSnJvk1iTfTHLIuIuaDUlCE7g/0vUw07oI\n",
       "2CfJkwCSPBnYG/j0WKsasU6e5bQW3hphbjkZ+CbwlXEXMgxJnkZzLJvQTBnuV1XfG29Vw5PkNcAT\n",
       "gAPaprk0BHw5cBDNtNN8mrMsv5zkKVV1+1grG44n0ExTnAgcTzM1ekoSquq0sVY2fC8AtgfmxMho\n",
       "Vb0vyWOBq5M8QPO7/R1VtUFdymQuBhrNEUlOpBlV273mztzoNcCvA1sBfwx8NMneVfX18Zb18LV/\n",
       "Hb6T5vv14FQzc2SUpqo+07P5nSRfAa6nCTnvGU9VQ7URcEVVHd1uL02yI3AIMNcCzWtojvXb4y5k\n",
       "GJK8EXgVsD9wFU0YPTnJsqr64FiLG6G5GGh+DDxI8xdUr/nAj0ZfjtZHkvcA+wF7V9WyMZczNFV1\n",
       "P3Bdu/nNJLvS/MJ41cyv6ozn0IyQXtWM6APNaOkeSV4LbN4e/5xQVXcnuQr41XHXMiQ3A9/ta7sG\n",
       "ePwYapk1SX4J+H2a0ai54miaEZnz2u2rkiykWRS8wQSaObeGpqruo1mQuKhv1wtoznbShEtyMvAy\n",
       "YJ+qunbc9cyyecyd/w7PB54K7Nw+dgG+DpwD7DKXwgxAkk2BX2Pu/KH0JZozm3o9EVg2+lJm1cHA\n",
       "vTQ/l3NFgFV9bauYI6Ojg5qLIzQwh2+N0J71s2O7uRGwMMkuwIq5cKXk9iajr6BZoLgyydS6pzur\n",
       "6q7xVfbwJflr4ELgRuBRNOtM9gJ+Z5x1DUtVraQ5I221JHcDd1RV/1/+nZPkb4ALaE6//yXgGGAz\n",
       "4Mxx1jVE76FZE3QUcB7NtMUbmEOn/raLgf838NGqunvc9QzRJ4C/SHI9zSjbbwBvZu78bA5kTp62\n",
       "DZDkdTTX/Ji6NcKbq+qL463q4UvyXJrrl0Cz4HIqgZ9RVa8eS1FDlGQVP39cUxZX1dvHUNLQJPkQ\n",
       "zZkHC2h+8S8F/l9VfXashc2iJF9g7py2fQ6wJ8202m00i7uPqaprxlrYELUXejye5lomNwCnVtWp\n",
       "461qeJLsDVwCPGsurFub0v6heyzwh/zP8opzgLe3sxYbhDkbaCRJ0oZjrszdS5KkDZiBRpIkdZ6B\n",
       "RpIkdZ6BRpIkdZ6BRpIkdZ6BRpIkdZ6BRpIkdZ6BRpplST6R5PYkj5xh/6OS3JVk4HuuJFnWXqhv\n",
       "avvgJKuSrPG+O0m2b/sdNPgRrH7tYUn+YJr2xe0FEUcqyZL2WFYleaD9N/5mkvcmefLDeN+Dkwz1\n",
       "3lpJntvWuc8Q3uuMJGu9KvigPxPSXGGgkWbfGcDWwAtn2P9HrPsl9Kt9TLkQeDZwyzq8fl0dBjwk\n",
       "0AD/0H72OCxtP3s3mpuZfpjmasz/0V4tfH0cDEz6Vbe9IqrUZ67ey0maJJ8CVgCvBP5lmv2vBG6o\n",
       "qkvX9wOq6sc0d5qfbQ+52V1V3QTcNILPns6dVXVFz/YlSU6huez7KUm+Npcucd9jg7rpoDQIR2ik\n",
       "WdbeZfoc4HeTPLp3XzsdsCdwVru9KMmnk9zcTkN9O8nhSdb43+p00wtJfiHJ+5KsSHJnkk8Cj53m\n",
       "tbsm+eckP0xyd5JrkryzvZv0VJ9lwOOBl/dM83yw3feQKackWyY5tT2Oe9v3PKyvz9Q0zIvavre1\n",
       "j7OSbDXIv+10quoB4PXAA8Dqe0gl+dX2va9rj/MH7b/P1j19ltB8P36r5zg/3+57TJL3J/le+735\n",
       "ryT/lOSX17fWXoPU19d/tyRfS3JPkuuTHDrg5/yfJEvb192W5B+TbNPX501Jrm7ruL39nJcM4zil\n",
       "2eIIjTQaZwKHAvsD7+tpfwXNX9sfbrd3oLn56KnAXcCuwGLgMaz7XY/fTzMNsxj4GrAIOHuafo+n\n",
       "mbo5E/h3lAdRAAAGNUlEQVRv4KnAXwJPAP6k7fMS4NPAf7TvB80NGqesngJpw9enaO74ewzNzWFf\n",
       "CJyY5DFVdXTf558M/Gv7WTsBJwAP0kz9rJequi3J14Hf6mnejuZO54fTjJg9ATiqPa7d2j6vAz5C\n",
       "88fea9u2n7TP2wA/A44Gbm3f7wjgS0l2qqqfrW+961DflC2BjwJ/Dfwnzb/de5PcWVUzTl2mueP7\n",
       "4TT/5m+hCbjvAJ6aZLeqWpXk5cDf0Nzs8N9ppkN3bo9fmlxV5cOHjxE8gO8Al/e1XQ18aYb+ofmj\n",
       "42jg9r591wMf7Nk+GFgFPL7dfhLNCMWf973ufW2/V67lM19BEyq26fvMD0/zmsXAqp7tF073GTRr\n",
       "be4Ftm23n9v2+1Bfv1OAewb491wCXLaG/ecAd69h/8bA7m0Nuwz6vj395gGPa1//krX0nTrWfdbh\n",
       "52Wm+s5o2/br638xsGwNPxPbtz8Tb+t73W5tvxe326cCV47zvxUfPtbn4ZSTNDpnAr+ZZEeAJL9J\n",
       "EzxW/0WdZLt2WuMGmtGA+4DjgK2S/NI6fNazaEYZzutr/2h/x3Z66N1JfkATOO6jGTEK8MR1+Mwp\n",
       "e9L8guwfDfon4JE8dAHxp/q2vwNsso7HO520dTQbySOTHNVOf91Nc5yXtbsHOs4kr2una+4E7gdu\n",
       "WJfXr+W916W+B4CP97WdCzx+DVNgL6D5mTg7ycZTD+AK4KfAHm2/K4Bd0pwt9vwkv/AwD00aCQON\n",
       "NDofoR25aLdfSRMgzoXVUzUXAPsCb6c5W+eZwDtpfjlvyuC2a59v7WtfPk3fD9FMr5wEPL/9zEPa\n",
       "fZusw2dOeTTNiNIDfe239OzvdXvf9tTUzboc73QeB/yoZ/tdwF/RhLV9aabzXjroZyV5A3AazUjI\n",
       "H7SvnwpnD7fWda3vv6vqwb62qe/1r8zw/lMB8T9pwlLvY3NgW4Cq+jDN1NuzgM8AK5J8PMnC9Tgm\n",
       "aWRcQyONSFX9KMlngVckeTvwMuBfq2pl2+V/Ac8AXlFVq0c3krx4PT5u6hf5fGBZT/v83k7twt/f\n",
       "B/6qqk7pad95PT5zyu3Ao5Ns3BdqFvTsn1Xt6M4z+flRov2BM6vq+J5+W67D2+4PXFJV/7fn9Ts8\n",
       "3FrXs75tkszrCzVT39uZzjhb0T6/ALhjDfupqtOB09vF2b8N/C1N8B7X6fnSWjlCI43WmcBCmsWc\n",
       "2/Lz156ZGtpfHQKSPAJ4Oet+3ZGv0owGvayvff++7U1o1oL0j6YcPM17/qynxjVZQvP/lv362l/e\n",
       "vsdXBniP9db+m72vreG9Pbs246HHOd0F9GY6zkFfv77W5f3n0Vy/qNf+NKf/3zzDay6m+ZlYWFXf\n",
       "mOZxQ/8LqmplVZ0HfIxmsbg0sRyhkUbrEzRnzRxGM0XwmZ5936VZk/HOJA/S/HJ7M02Y6b/uyBqv\n",
       "Q1JV30tyNvD2dirr6zRnOf1uX7+VSS4H3pLkRzR/pb8amG4dxneBPZL8Xlv7bdP9EgQuAr4I/H2S\n",
       "x7Sv2xf4U+D4qhrmCM2WSZ5F8+/xKOBpNCFgR+D1VfXNnr6fAQ5K8m3gBzTTOc+Z5j2vAl6fZD/g\n",
       "OuAnVXVt+/ojk7yV5qyxfYA/XMd690zfqfvA/VX1yXWoD+BO4IQkv8j/nOX0PGDGK0BX1XVJ3g2c\n",
       "muRJNOtz7qWZmns+8I9VtSTJ6TQ/o5fTTFE+kWaR+L+t47FKI2WgkUaoqu5Nch7NL/ezq2pVz777\n",
       "22t9nEqzjmIF8EHgh8Dp/W813dv3bb+WZrHnETSLcT8HHEATNnr9CfB3NOtD7qGZWvggzanUvd5K\n",
       "c6bSeTSjCWfwP1fUXf3ZVVVt6DkeOJJmJOp64M1VdfIAx7Gm9v4+v04z4lM0v+Svozntfb+qurqv\n",
       "/xtogs872+1P0Rz7FX393k2zWPsfgS1oRpz2oVnXtDVNyNy0bf/t9jMHqRWa0+H7/ZTmNOxB6ytg\n",
       "Jc3o23tpQtwtwBur6qwZPrfZqDo6ydU0a6QOaff/ELgEuLbt9kWaUHggsBVwM811kv5qgOOUxiZV\n",
       "XkFbkiR1m2toJElS5xloJElS5xloJElS5xloJElS5xloJElS5xloJElS5xloJElS5xloJElS5xlo\n",
       "JElS5/1/2MjJTwKILBoAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11251e810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Remove the plot frame lines. They are unnecessary chartjunk.  \n",
    "ax = plt.subplot(111)  \n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "\n",
    "# Ensure that the axis ticks only show up on the bottom and left of the plot.  \n",
    "# Ticks on the right and top of the plot are generally unnecessary chartjunk.  \n",
    "ax.get_xaxis().tick_bottom()  \n",
    "ax.get_yaxis().tick_left()  \n",
    "\n",
    "# Make sure your axis ticks are large enough to be easily read.  \n",
    "# You don't want your viewers squinting to read your plot.  \n",
    "plt.xticks(unique_valid, fontsize=14)  \n",
    "plt.yticks(fontsize=14)  \n",
    "\n",
    "# Along the same vein, make sure your axis labels are large  \n",
    "# enough to be easily read as well. Make them slightly larger  \n",
    "# than your axis tick labels so they stand out.  \n",
    "plt.xlabel(\"Validation Data Lables\", fontsize=16)  \n",
    "plt.ylabel(\"Count\", fontsize=16)\n",
    "\n",
    "ax.hist(labels[5000:], bins=range(10), cumulative=False, color=\"#3F5D7D\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
