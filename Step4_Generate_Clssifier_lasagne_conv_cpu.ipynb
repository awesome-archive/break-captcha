{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from __future__ import print_function\n",
    "import gzip\n",
    "import itertools\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = 600\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_iter_functions(dataset, output_layer,\n",
    "                          X_tensor_type=T.matrix,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          learning_rate=LEARNING_RATE, momentum=MOMENTUM):\n",
    "    \"\"\"Create functions for training, validation and testing to iterate one\n",
    "       epoch.\n",
    "    \"\"\"\n",
    "    batch_index = T.iscalar('batch_index')\n",
    "    X_batch = X_tensor_type('x')\n",
    "    y_batch = T.ivector('y')\n",
    "    batch_slice = slice(batch_index * batch_size,\n",
    "                        (batch_index + 1) * batch_size)\n",
    "\n",
    "    objective = lasagne.objectives.Objective(output_layer,\n",
    "        loss_function=lasagne.objectives.categorical_crossentropy)\n",
    "\n",
    "    loss_train = objective.get_loss(X_batch, target=y_batch)\n",
    "    loss_eval = objective.get_loss(X_batch, target=y_batch,\n",
    "                                   deterministic=True)\n",
    "\n",
    "    pred = T.argmax(\n",
    "        lasagne.layers.get_output(output_layer, X_batch, deterministic=True),\n",
    "        axis=1)\n",
    "    accuracy = T.mean(T.eq(pred, y_batch), dtype=theano.config.floatX)\n",
    "\n",
    "    all_params = lasagne.layers.get_all_params(output_layer)\n",
    "    updates = lasagne.updates.nesterov_momentum(\n",
    "        loss_train, all_params, learning_rate, momentum)\n",
    "\n",
    "    iter_train = theano.function(\n",
    "        [batch_index], loss_train,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            X_batch: dataset['X_train'][batch_slice],\n",
    "            y_batch: dataset['y_train'][batch_slice],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    iter_valid = theano.function(\n",
    "        [batch_index], [loss_eval, accuracy],\n",
    "        givens={\n",
    "            X_batch: dataset['X_valid'][batch_slice],\n",
    "            y_batch: dataset['y_valid'][batch_slice],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    iter_test = theano.function(\n",
    "        [batch_index], [loss_eval, accuracy],\n",
    "        givens={\n",
    "            X_batch: dataset['X_test'][batch_slice],\n",
    "            y_batch: dataset['y_test'][batch_slice],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        train=iter_train,\n",
    "        valid=iter_valid,\n",
    "        test=iter_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(iter_funcs, dataset, batch_size=BATCH_SIZE):\n",
    "    \"\"\"Train the model with `dataset` with mini-batch training. Each\n",
    "       mini-batch has `batch_size` recordings.\n",
    "    \"\"\"\n",
    "    num_batches_train = dataset['num_examples_train'] // batch_size\n",
    "    num_batches_valid = dataset['num_examples_valid'] // batch_size\n",
    "\n",
    "    for epoch in itertools.count(1):\n",
    "        batch_train_losses = []\n",
    "        for b in range(num_batches_train):\n",
    "            batch_train_loss = iter_funcs['train'](b)\n",
    "            batch_train_losses.append(batch_train_loss)\n",
    "\n",
    "        avg_train_loss = np.mean(batch_train_losses)\n",
    "\n",
    "        batch_valid_losses = []\n",
    "        batch_valid_accuracies = []\n",
    "        for b in range(num_batches_valid):\n",
    "            batch_valid_loss, batch_valid_accuracy = iter_funcs['valid'](b)\n",
    "            batch_valid_losses.append(batch_valid_loss)\n",
    "            batch_valid_accuracies.append(batch_valid_accuracy)\n",
    "\n",
    "        avg_valid_loss = np.mean(batch_valid_losses)\n",
    "        avg_valid_accuracy = np.mean(batch_valid_accuracies)\n",
    "\n",
    "        yield {\n",
    "            'number': epoch,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'valid_loss': avg_valid_loss,\n",
    "            'valid_accuracy': avg_valid_accuracy,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(features, labels):\n",
    "    \"\"\"Get data with labels, split into training, validation and test set.\"\"\"\n",
    "    X_train = features[:2000]\n",
    "    y_train = labels[:2000]\n",
    "    X_valid = features[2000:4000]\n",
    "    y_valid = labels[2000:4000]\n",
    "    X_test = features[4000:]\n",
    "    y_test = labels[4000:]\n",
    "\n",
    "    # reshape for convolutions\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1, 28, 28))\n",
    "    X_valid = X_valid.reshape((X_valid.shape[0], 1, 28, 28))\n",
    "    X_test = X_test.reshape((X_test.shape[0], 1, 28, 28))\n",
    "\n",
    "    return dict(\n",
    "        X_train=theano.shared(lasagne.utils.floatX(X_train)),\n",
    "        y_train=T.cast(theano.shared(y_train), 'int32'),\n",
    "        X_valid=theano.shared(lasagne.utils.floatX(X_valid)),\n",
    "        y_valid=T.cast(theano.shared(y_valid), 'int32'),\n",
    "        X_test=theano.shared(lasagne.utils.floatX(X_test)),\n",
    "        y_test=T.cast(theano.shared(y_test), 'int32'),\n",
    "        num_examples_train=X_train.shape[0],\n",
    "        num_examples_valid=X_valid.shape[0],\n",
    "        num_examples_test=X_test.shape[0],\n",
    "        input_height=X_train.shape[2],\n",
    "        input_width=X_train.shape[3],\n",
    "        output_dim=9,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale(X, eps = 0.001):\n",
    "    # scale the data points s.t the columns of the feature space\n",
    "    # (i.e the predictors) are within the range [0, 1]\n",
    "    return (X - np.min(X, axis = 0)) / (np.max(X, axis = 0) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_width, input_height, output_dim,\n",
    "                batch_size=BATCH_SIZE):\n",
    "    l_in = lasagne.layers.InputLayer(\n",
    "        shape=(batch_size, 1, input_width, input_height),\n",
    "        )\n",
    "\n",
    "    l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "        l_in,\n",
    "        num_filters=32,\n",
    "        filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform(),\n",
    "        )\n",
    "    l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))\n",
    "\n",
    "    l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "        l_pool1,\n",
    "        num_filters=32,\n",
    "        filter_size=(5, 5),\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform(),\n",
    "        )\n",
    "    l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(2, 2))\n",
    "\n",
    "    l_hidden1 = lasagne.layers.DenseLayer(\n",
    "        l_pool2,\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        W=lasagne.init.GlorotUniform(),\n",
    "        )\n",
    "\n",
    "    l_hidden1_dropout = lasagne.layers.DropoutLayer(l_hidden1, p=0.5)\n",
    "\n",
    "    l_hidden2 = lasagne.layers.DenseLayer(\n",
    "        l_hidden1_dropout,\n",
    "        num_units=256,\n",
    "        nonlinearity=lasagne.nonlinearities.rectify,\n",
    "        )\n",
    "    l_hidden2_dropout = lasagne.layers.DropoutLayer(l_hidden2, p=0.5)\n",
    "\n",
    "    l_out = lasagne.layers.DenseLayer(\n",
    "        l_hidden1_dropout,\n",
    "        num_units=output_dim,\n",
    "        nonlinearity=lasagne.nonlinearities.softmax,\n",
    "        W=lasagne.init.GlorotUniform(),\n",
    "        )\n",
    "\n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and compiling functions...\n",
      "Starting training...\n",
      "Epoch 1 of 500 took 8.799s\n",
      "  training loss:\t\t2.185890\n",
      "  validation loss:\t\t2.131395\n",
      "  validation accuracy:\t\t15.22 %%\n",
      "Epoch 2 of 500 took 9.032s\n",
      "  training loss:\t\t2.111097\n",
      "  validation loss:\t\t2.064566\n",
      "  validation accuracy:\t\t18.00 %%\n",
      "Epoch 3 of 500 took 8.677s\n",
      "  training loss:\t\t2.036950\n",
      "  validation loss:\t\t1.952891\n",
      "  validation accuracy:\t\t28.89 %%\n",
      "Epoch 4 of 500 took 8.563s\n",
      "  training loss:\t\t1.905106\n",
      "  validation loss:\t\t1.745619\n",
      "  validation accuracy:\t\t50.89 %%\n",
      "Epoch 5 of 500 took 9.917s\n",
      "  training loss:\t\t1.684985\n",
      "  validation loss:\t\t1.445677\n",
      "  validation accuracy:\t\t61.94 %%\n",
      "Epoch 6 of 500 took 10.181s\n",
      "  training loss:\t\t1.361547\n",
      "  validation loss:\t\t1.070829\n",
      "  validation accuracy:\t\t76.22 %%\n",
      "Epoch 7 of 500 took 8.588s\n",
      "  training loss:\t\t1.015604\n",
      "  validation loss:\t\t0.759416\n",
      "  validation accuracy:\t\t81.67 %%\n",
      "Epoch 8 of 500 took 8.557s\n",
      "  training loss:\t\t0.758473\n",
      "  validation loss:\t\t0.597538\n",
      "  validation accuracy:\t\t88.22 %%\n",
      "Epoch 9 of 500 took 8.691s\n",
      "  training loss:\t\t0.571047\n",
      "  validation loss:\t\t0.545116\n",
      "  validation accuracy:\t\t88.67 %%\n",
      "Epoch 10 of 500 took 8.575s\n",
      "  training loss:\t\t0.481191\n",
      "  validation loss:\t\t0.545716\n",
      "  validation accuracy:\t\t88.78 %%\n",
      "Epoch 11 of 500 took 8.835s\n",
      "  training loss:\t\t0.435352\n",
      "  validation loss:\t\t0.544588\n",
      "  validation accuracy:\t\t89.06 %%\n",
      "Epoch 12 of 500 took 8.556s\n",
      "  training loss:\t\t0.401459\n",
      "  validation loss:\t\t0.542201\n",
      "  validation accuracy:\t\t88.94 %%\n",
      "Epoch 13 of 500 took 8.535s\n",
      "  training loss:\t\t0.395062\n",
      "  validation loss:\t\t0.535597\n",
      "  validation accuracy:\t\t89.06 %%\n",
      "Epoch 14 of 500 took 8.534s\n",
      "  training loss:\t\t0.381224\n",
      "  validation loss:\t\t0.523608\n",
      "  validation accuracy:\t\t89.00 %%\n",
      "Epoch 15 of 500 took 8.507s\n",
      "  training loss:\t\t0.374885\n",
      "  validation loss:\t\t0.507297\n",
      "  validation accuracy:\t\t89.06 %%\n",
      "Epoch 16 of 500 took 8.530s\n",
      "  training loss:\t\t0.345114\n",
      "  validation loss:\t\t0.502936\n",
      "  validation accuracy:\t\t88.89 %%\n",
      "Epoch 17 of 500 took 8.477s\n",
      "  training loss:\t\t0.338807\n",
      "  validation loss:\t\t0.493339\n",
      "  validation accuracy:\t\t89.06 %%\n",
      "Epoch 18 of 500 took 8.542s\n",
      "  training loss:\t\t0.319985\n",
      "  validation loss:\t\t0.487364\n",
      "  validation accuracy:\t\t89.00 %%\n",
      "Epoch 19 of 500 took 8.525s\n",
      "  training loss:\t\t0.307406\n",
      "  validation loss:\t\t0.479952\n",
      "  validation accuracy:\t\t89.06 %%\n",
      "Epoch 20 of 500 took 8.539s\n",
      "  training loss:\t\t0.319192\n",
      "  validation loss:\t\t0.469032\n",
      "  validation accuracy:\t\t89.22 %%\n",
      "Epoch 21 of 500 took 8.496s\n",
      "  training loss:\t\t0.306729\n",
      "  validation loss:\t\t0.458240\n",
      "  validation accuracy:\t\t89.06 %%\n",
      "Epoch 22 of 500 took 8.616s\n",
      "  training loss:\t\t0.285279\n",
      "  validation loss:\t\t0.455675\n",
      "  validation accuracy:\t\t89.33 %%\n",
      "Epoch 23 of 500 took 8.531s\n",
      "  training loss:\t\t0.284471\n",
      "  validation loss:\t\t0.455171\n",
      "  validation accuracy:\t\t89.22 %%\n",
      "Epoch 24 of 500 took 8.532s\n",
      "  training loss:\t\t0.283606\n",
      "  validation loss:\t\t0.452639\n",
      "  validation accuracy:\t\t89.56 %%\n",
      "Epoch 25 of 500 took 8.491s\n",
      "  training loss:\t\t0.281333\n",
      "  validation loss:\t\t0.447609\n",
      "  validation accuracy:\t\t89.33 %%\n",
      "Epoch 26 of 500 took 8.529s\n",
      "  training loss:\t\t0.278713\n",
      "  validation loss:\t\t0.443311\n",
      "  validation accuracy:\t\t89.33 %%\n",
      "Epoch 27 of 500 took 8.661s\n",
      "  training loss:\t\t0.264904\n",
      "  validation loss:\t\t0.439549\n",
      "  validation accuracy:\t\t89.44 %%\n",
      "Epoch 28 of 500 took 8.509s\n",
      "  training loss:\t\t0.269232\n",
      "  validation loss:\t\t0.436999\n",
      "  validation accuracy:\t\t89.67 %%\n",
      "Epoch 29 of 500 took 8.520s\n",
      "  training loss:\t\t0.268419\n",
      "  validation loss:\t\t0.433999\n",
      "  validation accuracy:\t\t89.67 %%\n",
      "Epoch 30 of 500 took 8.522s\n",
      "  training loss:\t\t0.266748\n",
      "  validation loss:\t\t0.431864\n",
      "  validation accuracy:\t\t89.61 %%\n",
      "Epoch 31 of 500 took 8.497s\n",
      "  training loss:\t\t0.249312\n",
      "  validation loss:\t\t0.428088\n",
      "  validation accuracy:\t\t89.78 %%\n",
      "Epoch 32 of 500 took 8.511s\n",
      "  training loss:\t\t0.251880\n",
      "  validation loss:\t\t0.425959\n",
      "  validation accuracy:\t\t89.94 %%\n",
      "Epoch 33 of 500 took 8.532s\n",
      "  training loss:\t\t0.257929\n",
      "  validation loss:\t\t0.422941\n",
      "  validation accuracy:\t\t90.06 %%\n",
      "Epoch 34 of 500 took 8.518s\n",
      "  training loss:\t\t0.249264\n",
      "  validation loss:\t\t0.421856\n",
      "  validation accuracy:\t\t89.89 %%\n",
      "Epoch 35 of 500 took 8.497s\n",
      "  training loss:\t\t0.235980\n",
      "  validation loss:\t\t0.421983\n",
      "  validation accuracy:\t\t89.94 %%\n",
      "Epoch 36 of 500 took 8.484s\n",
      "  training loss:\t\t0.239121\n",
      "  validation loss:\t\t0.415134\n",
      "  validation accuracy:\t\t90.00 %%\n",
      "Epoch 37 of 500 took 8.496s\n",
      "  training loss:\t\t0.235892\n",
      "  validation loss:\t\t0.416327\n",
      "  validation accuracy:\t\t90.11 %%\n",
      "Epoch 38 of 500 took 8.468s\n",
      "  training loss:\t\t0.216142\n",
      "  validation loss:\t\t0.417037\n",
      "  validation accuracy:\t\t90.11 %%\n",
      "Epoch 39 of 500 took 8.508s\n",
      "  training loss:\t\t0.222829\n",
      "  validation loss:\t\t0.416684\n",
      "  validation accuracy:\t\t90.17 %%\n",
      "Epoch 40 of 500 took 8.502s\n",
      "  training loss:\t\t0.222000\n",
      "  validation loss:\t\t0.417930\n",
      "  validation accuracy:\t\t90.11 %%\n",
      "Epoch 41 of 500 took 8.526s\n",
      "  training loss:\t\t0.221827\n",
      "  validation loss:\t\t0.413969\n",
      "  validation accuracy:\t\t90.11 %%\n",
      "Epoch 42 of 500 took 8.535s\n",
      "  training loss:\t\t0.216954\n",
      "  validation loss:\t\t0.411549\n",
      "  validation accuracy:\t\t90.11 %%\n",
      "Epoch 43 of 500 took 8.510s\n",
      "  training loss:\t\t0.214484\n",
      "  validation loss:\t\t0.408419\n",
      "  validation accuracy:\t\t90.11 %%\n",
      "Epoch 44 of 500 took 8.501s\n",
      "  training loss:\t\t0.213572\n",
      "  validation loss:\t\t0.410456\n",
      "  validation accuracy:\t\t90.17 %%\n",
      "Epoch 45 of 500 took 8.512s\n",
      "  training loss:\t\t0.218179\n",
      "  validation loss:\t\t0.412322\n",
      "  validation accuracy:\t\t90.17 %%\n",
      "Epoch 46 of 500 took 8.215s\n",
      "  training loss:\t\t0.223825\n",
      "  validation loss:\t\t0.409180\n",
      "  validation accuracy:\t\t90.39 %%\n",
      "Epoch 47 of 500 took 7.974s\n",
      "  training loss:\t\t0.207743\n",
      "  validation loss:\t\t0.410504\n",
      "  validation accuracy:\t\t90.44 %%\n",
      "Epoch 48 of 500 took 8.122s\n",
      "  training loss:\t\t0.207024\n",
      "  validation loss:\t\t0.405869\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 49 of 500 took 7.992s\n",
      "  training loss:\t\t0.210005\n",
      "  validation loss:\t\t0.404567\n",
      "  validation accuracy:\t\t90.39 %%\n",
      "Epoch 50 of 500 took 7.987s\n",
      "  training loss:\t\t0.200948\n",
      "  validation loss:\t\t0.404183\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 51 of 500 took 8.033s\n",
      "  training loss:\t\t0.199427\n",
      "  validation loss:\t\t0.401741\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 52 of 500 took 8.050s\n",
      "  training loss:\t\t0.197115\n",
      "  validation loss:\t\t0.405271\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 53 of 500 took 7.962s\n",
      "  training loss:\t\t0.202139\n",
      "  validation loss:\t\t0.408798\n",
      "  validation accuracy:\t\t90.28 %%\n",
      "Epoch 54 of 500 took 7.928s\n",
      "  training loss:\t\t0.203772\n",
      "  validation loss:\t\t0.403734\n",
      "  validation accuracy:\t\t90.33 %%\n",
      "Epoch 55 of 500 took 7.954s\n",
      "  training loss:\t\t0.183956\n",
      "  validation loss:\t\t0.403840\n",
      "  validation accuracy:\t\t90.44 %%\n",
      "Epoch 56 of 500 took 8.018s\n",
      "  training loss:\t\t0.194885\n",
      "  validation loss:\t\t0.407875\n",
      "  validation accuracy:\t\t90.44 %%\n",
      "Epoch 57 of 500 took 7.965s\n",
      "  training loss:\t\t0.186463\n",
      "  validation loss:\t\t0.404632\n",
      "  validation accuracy:\t\t90.56 %%\n",
      "Epoch 58 of 500 took 8.036s\n",
      "  training loss:\t\t0.191867\n",
      "  validation loss:\t\t0.402826\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 59 of 500 took 7.954s\n",
      "  training loss:\t\t0.178161\n",
      "  validation loss:\t\t0.406165\n",
      "  validation accuracy:\t\t90.56 %%\n",
      "Epoch 60 of 500 took 7.875s\n",
      "  training loss:\t\t0.180712\n",
      "  validation loss:\t\t0.405745\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 61 of 500 took 7.938s\n",
      "  training loss:\t\t0.178983\n",
      "  validation loss:\t\t0.406347\n",
      "  validation accuracy:\t\t90.44 %%\n",
      "Epoch 62 of 500 took 7.948s\n",
      "  training loss:\t\t0.179224\n",
      "  validation loss:\t\t0.404470\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 63 of 500 took 8.082s\n",
      "  training loss:\t\t0.184309\n",
      "  validation loss:\t\t0.405005\n",
      "  validation accuracy:\t\t90.39 %%\n",
      "Epoch 64 of 500 took 7.940s\n",
      "  training loss:\t\t0.186810\n",
      "  validation loss:\t\t0.405192\n",
      "  validation accuracy:\t\t90.39 %%\n",
      "Epoch 65 of 500 took 8.043s\n",
      "  training loss:\t\t0.184355\n",
      "  validation loss:\t\t0.405442\n",
      "  validation accuracy:\t\t90.56 %%\n",
      "Epoch 66 of 500 took 7.968s\n",
      "  training loss:\t\t0.173402\n",
      "  validation loss:\t\t0.407338\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 67 of 500 took 7.954s\n",
      "  training loss:\t\t0.172557\n",
      "  validation loss:\t\t0.407900\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 68 of 500 took 7.911s\n",
      "  training loss:\t\t0.171145\n",
      "  validation loss:\t\t0.405818\n",
      "  validation accuracy:\t\t90.56 %%\n",
      "Epoch 69 of 500 took 7.936s\n",
      "  training loss:\t\t0.169555\n",
      "  validation loss:\t\t0.405690\n",
      "  validation accuracy:\t\t90.61 %%\n",
      "Epoch 70 of 500 took 7.941s\n",
      "  training loss:\t\t0.172141\n",
      "  validation loss:\t\t0.407944\n",
      "  validation accuracy:\t\t90.78 %%\n",
      "Epoch 71 of 500 took 8.004s\n",
      "  training loss:\t\t0.173064\n",
      "  validation loss:\t\t0.406747\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 72 of 500 took 7.999s\n",
      "  training loss:\t\t0.156240\n",
      "  validation loss:\t\t0.405491\n",
      "  validation accuracy:\t\t90.61 %%\n",
      "Epoch 73 of 500 took 7.950s\n",
      "  training loss:\t\t0.170096\n",
      "  validation loss:\t\t0.405483\n",
      "  validation accuracy:\t\t90.67 %%\n",
      "Epoch 74 of 500 took 8.019s\n",
      "  training loss:\t\t0.154316\n",
      "  validation loss:\t\t0.407800\n",
      "  validation accuracy:\t\t90.50 %%\n",
      "Epoch 75 of 500 took 8.065s\n",
      "  training loss:\t\t0.164953\n",
      "  validation loss:\t\t0.408738\n",
      "  validation accuracy:\t\t90.61 %%\n",
      "Epoch 76 of 500 took 8.005s\n",
      "  training loss:\t\t0.150828\n",
      "  validation loss:\t\t0.412044\n",
      "  validation accuracy:\t\t90.56 %%\n",
      "Epoch 77 of 500 took 7.903s\n",
      "  training loss:\t\t0.151899\n",
      "  validation loss:\t\t0.410511\n",
      "  validation accuracy:\t\t90.78 %%\n",
      "Epoch 78 of 500 took 8.270s\n",
      "  training loss:\t\t0.149720\n",
      "  validation loss:\t\t0.404963\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 79 of 500 took 7.964s\n",
      "  training loss:\t\t0.158078\n",
      "  validation loss:\t\t0.408990\n",
      "  validation accuracy:\t\t90.78 %%\n",
      "Epoch 80 of 500 took 7.957s\n",
      "  training loss:\t\t0.162156\n",
      "  validation loss:\t\t0.410753\n",
      "  validation accuracy:\t\t90.61 %%\n",
      "Epoch 81 of 500 took 7.945s\n",
      "  training loss:\t\t0.160853\n",
      "  validation loss:\t\t0.407423\n",
      "  validation accuracy:\t\t90.89 %%\n",
      "Epoch 82 of 500 took 7.910s\n",
      "  training loss:\t\t0.158300\n",
      "  validation loss:\t\t0.409919\n",
      "  validation accuracy:\t\t90.94 %%\n",
      "Epoch 83 of 500 took 7.967s\n",
      "  training loss:\t\t0.150786\n",
      "  validation loss:\t\t0.411576\n",
      "  validation accuracy:\t\t90.78 %%\n",
      "Epoch 84 of 500 took 7.963s\n",
      "  training loss:\t\t0.148084\n",
      "  validation loss:\t\t0.412658\n",
      "  validation accuracy:\t\t90.78 %%\n",
      "Epoch 85 of 500 took 8.046s\n",
      "  training loss:\t\t0.150962\n",
      "  validation loss:\t\t0.411891\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 86 of 500 took 7.988s\n",
      "  training loss:\t\t0.153827\n",
      "  validation loss:\t\t0.413110\n",
      "  validation accuracy:\t\t91.06 %%\n",
      "Epoch 87 of 500 took 7.958s\n",
      "  training loss:\t\t0.146994\n",
      "  validation loss:\t\t0.413096\n",
      "  validation accuracy:\t\t90.94 %%\n",
      "Epoch 88 of 500 took 8.024s\n",
      "  training loss:\t\t0.160648\n",
      "  validation loss:\t\t0.411079\n",
      "  validation accuracy:\t\t91.06 %%\n",
      "Epoch 89 of 500 took 7.957s\n",
      "  training loss:\t\t0.158611\n",
      "  validation loss:\t\t0.405771\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 90 of 500 took 7.940s\n",
      "  training loss:\t\t0.150564\n",
      "  validation loss:\t\t0.406259\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 91 of 500 took 7.974s\n",
      "  training loss:\t\t0.143319\n",
      "  validation loss:\t\t0.412095\n",
      "  validation accuracy:\t\t90.78 %%\n",
      "Epoch 92 of 500 took 8.013s\n",
      "  training loss:\t\t0.137088\n",
      "  validation loss:\t\t0.415574\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 93 of 500 took 7.983s\n",
      "  training loss:\t\t0.143953\n",
      "  validation loss:\t\t0.413863\n",
      "  validation accuracy:\t\t90.83 %%\n",
      "Epoch 94 of 500 took 7.937s\n",
      "  training loss:\t\t0.156639\n",
      "  validation loss:\t\t0.413557\n",
      "  validation accuracy:\t\t91.06 %%\n",
      "Epoch 95 of 500 took 7.942s\n",
      "  training loss:\t\t0.142457\n",
      "  validation loss:\t\t0.410489\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 96 of 500 took 7.921s\n",
      "  training loss:\t\t0.145829\n",
      "  validation loss:\t\t0.409617\n",
      "  validation accuracy:\t\t90.94 %%\n",
      "Epoch 97 of 500 took 8.055s\n",
      "  training loss:\t\t0.143776\n",
      "  validation loss:\t\t0.410871\n",
      "  validation accuracy:\t\t90.89 %%\n",
      "Epoch 98 of 500 took 7.992s\n",
      "  training loss:\t\t0.149005\n",
      "  validation loss:\t\t0.414046\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 99 of 500 took 7.974s\n",
      "  training loss:\t\t0.145984\n",
      "  validation loss:\t\t0.411866\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 100 of 500 took 7.948s\n",
      "  training loss:\t\t0.139431\n",
      "  validation loss:\t\t0.414468\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 101 of 500 took 7.888s\n",
      "  training loss:\t\t0.138709\n",
      "  validation loss:\t\t0.413888\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 102 of 500 took 7.955s\n",
      "  training loss:\t\t0.135285\n",
      "  validation loss:\t\t0.411384\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 103 of 500 took 7.991s\n",
      "  training loss:\t\t0.133188\n",
      "  validation loss:\t\t0.415403\n",
      "  validation accuracy:\t\t91.06 %%\n",
      "Epoch 104 of 500 took 7.968s\n",
      "  training loss:\t\t0.128251\n",
      "  validation loss:\t\t0.419824\n",
      "  validation accuracy:\t\t90.94 %%\n",
      "Epoch 105 of 500 took 8.316s\n",
      "  training loss:\t\t0.134083\n",
      "  validation loss:\t\t0.422200\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 106 of 500 took 9.347s\n",
      "  training loss:\t\t0.146336\n",
      "  validation loss:\t\t0.418266\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 107 of 500 took 7.971s\n",
      "  training loss:\t\t0.139466\n",
      "  validation loss:\t\t0.415243\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 108 of 500 took 7.974s\n",
      "  training loss:\t\t0.130788\n",
      "  validation loss:\t\t0.422608\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 109 of 500 took 9.005s\n",
      "  training loss:\t\t0.139296\n",
      "  validation loss:\t\t0.421065\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 110 of 500 took 9.499s\n",
      "  training loss:\t\t0.128093\n",
      "  validation loss:\t\t0.423163\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 111 of 500 took 9.902s\n",
      "  training loss:\t\t0.127903\n",
      "  validation loss:\t\t0.421744\n",
      "  validation accuracy:\t\t91.06 %%\n",
      "Epoch 112 of 500 took 9.544s\n",
      "  training loss:\t\t0.128152\n",
      "  validation loss:\t\t0.423651\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 113 of 500 took 8.879s\n",
      "  training loss:\t\t0.127109\n",
      "  validation loss:\t\t0.427665\n",
      "  validation accuracy:\t\t91.06 %%\n",
      "Epoch 114 of 500 took 8.567s\n",
      "  training loss:\t\t0.124575\n",
      "  validation loss:\t\t0.428461\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 115 of 500 took 8.954s\n",
      "  training loss:\t\t0.124415\n",
      "  validation loss:\t\t0.426191\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 116 of 500 took 8.557s\n",
      "  training loss:\t\t0.129957\n",
      "  validation loss:\t\t0.424438\n",
      "  validation accuracy:\t\t91.28 %%\n",
      "Epoch 117 of 500 took 8.929s\n",
      "  training loss:\t\t0.113912\n",
      "  validation loss:\t\t0.428345\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 118 of 500 took 8.569s\n",
      "  training loss:\t\t0.119833\n",
      "  validation loss:\t\t0.431530\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 119 of 500 took 8.975s\n",
      "  training loss:\t\t0.121123\n",
      "  validation loss:\t\t0.432290\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 120 of 500 took 8.827s\n",
      "  training loss:\t\t0.124653\n",
      "  validation loss:\t\t0.432380\n",
      "  validation accuracy:\t\t91.00 %%\n",
      "Epoch 121 of 500 took 8.671s\n",
      "  training loss:\t\t0.119517\n",
      "  validation loss:\t\t0.437111\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 122 of 500 took 8.926s\n",
      "  training loss:\t\t0.116148\n",
      "  validation loss:\t\t0.434508\n",
      "  validation accuracy:\t\t91.28 %%\n",
      "Epoch 123 of 500 took 8.561s\n",
      "  training loss:\t\t0.129374\n",
      "  validation loss:\t\t0.432921\n",
      "  validation accuracy:\t\t91.06 %%\n",
      "Epoch 124 of 500 took 11.078s\n",
      "  training loss:\t\t0.123394\n",
      "  validation loss:\t\t0.431850\n",
      "  validation accuracy:\t\t91.06 %%\n",
      "Epoch 125 of 500 took 10.974s\n",
      "  training loss:\t\t0.118481\n",
      "  validation loss:\t\t0.433356\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 126 of 500 took 9.724s\n",
      "  training loss:\t\t0.121894\n",
      "  validation loss:\t\t0.434638\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 127 of 500 took 11.833s\n",
      "  training loss:\t\t0.120629\n",
      "  validation loss:\t\t0.435201\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 128 of 500 took 8.811s\n",
      "  training loss:\t\t0.115191\n",
      "  validation loss:\t\t0.437571\n",
      "  validation accuracy:\t\t91.28 %%\n",
      "Epoch 129 of 500 took 9.522s\n",
      "  training loss:\t\t0.118236\n",
      "  validation loss:\t\t0.438956\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 130 of 500 took 9.417s\n",
      "  training loss:\t\t0.118870\n",
      "  validation loss:\t\t0.442456\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 131 of 500 took 9.904s\n",
      "  training loss:\t\t0.112361\n",
      "  validation loss:\t\t0.436877\n",
      "  validation accuracy:\t\t91.28 %%\n",
      "Epoch 132 of 500 took 10.127s\n",
      "  training loss:\t\t0.115929\n",
      "  validation loss:\t\t0.443665\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 133 of 500 took 9.497s\n",
      "  training loss:\t\t0.111260\n",
      "  validation loss:\t\t0.444560\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 134 of 500 took 8.818s\n",
      "  training loss:\t\t0.107417\n",
      "  validation loss:\t\t0.444750\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 135 of 500 took 10.301s\n",
      "  training loss:\t\t0.110176\n",
      "  validation loss:\t\t0.446248\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 136 of 500 took 9.580s\n",
      "  training loss:\t\t0.102925\n",
      "  validation loss:\t\t0.442954\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 137 of 500 took 9.242s\n",
      "  training loss:\t\t0.110787\n",
      "  validation loss:\t\t0.442214\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 138 of 500 took 9.226s\n",
      "  training loss:\t\t0.107221\n",
      "  validation loss:\t\t0.446141\n",
      "  validation accuracy:\t\t91.17 %%\n",
      "Epoch 139 of 500 took 9.624s\n",
      "  training loss:\t\t0.100348\n",
      "  validation loss:\t\t0.449859\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 140 of 500 took 10.104s\n",
      "  training loss:\t\t0.107340\n",
      "  validation loss:\t\t0.451111\n",
      "  validation accuracy:\t\t91.11 %%\n",
      "Epoch 141 of 500 took 9.826s\n",
      "  training loss:\t\t0.113063\n",
      "  validation loss:\t\t0.452840\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 142 of 500 took 9.548s\n",
      "  training loss:\t\t0.106276\n",
      "  validation loss:\t\t0.451808\n",
      "  validation accuracy:\t\t91.28 %%\n",
      "Epoch 143 of 500 took 8.586s\n",
      "  training loss:\t\t0.103864\n",
      "  validation loss:\t\t0.448557\n",
      "  validation accuracy:\t\t91.28 %%\n",
      "Epoch 144 of 500 took 8.599s\n",
      "  training loss:\t\t0.107334\n",
      "  validation loss:\t\t0.451094\n",
      "  validation accuracy:\t\t91.28 %%\n",
      "Epoch 145 of 500 took 8.533s\n",
      "  training loss:\t\t0.095690\n",
      "  validation loss:\t\t0.450737\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 146 of 500 took 8.551s\n",
      "  training loss:\t\t0.103888\n",
      "  validation loss:\t\t0.451257\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 147 of 500 took 8.537s\n",
      "  training loss:\t\t0.111658\n",
      "  validation loss:\t\t0.451590\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 148 of 500 took 8.541s\n",
      "  training loss:\t\t0.106884\n",
      "  validation loss:\t\t0.453805\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 149 of 500 took 8.535s\n",
      "  training loss:\t\t0.111502\n",
      "  validation loss:\t\t0.457260\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 150 of 500 took 8.516s\n",
      "  training loss:\t\t0.098176\n",
      "  validation loss:\t\t0.460420\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 151 of 500 took 8.511s\n",
      "  training loss:\t\t0.095021\n",
      "  validation loss:\t\t0.455580\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 152 of 500 took 8.492s\n",
      "  training loss:\t\t0.104033\n",
      "  validation loss:\t\t0.458108\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 153 of 500 took 8.034s\n",
      "  training loss:\t\t0.103727\n",
      "  validation loss:\t\t0.464436\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 154 of 500 took 7.970s\n",
      "  training loss:\t\t0.099506\n",
      "  validation loss:\t\t0.463966\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 155 of 500 took 8.036s\n",
      "  training loss:\t\t0.094107\n",
      "  validation loss:\t\t0.464031\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 156 of 500 took 7.956s\n",
      "  training loss:\t\t0.093590\n",
      "  validation loss:\t\t0.462950\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 157 of 500 took 8.021s\n",
      "  training loss:\t\t0.107374\n",
      "  validation loss:\t\t0.456418\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 158 of 500 took 8.003s\n",
      "  training loss:\t\t0.099276\n",
      "  validation loss:\t\t0.460077\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 159 of 500 took 7.991s\n",
      "  training loss:\t\t0.098636\n",
      "  validation loss:\t\t0.465908\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 160 of 500 took 7.988s\n",
      "  training loss:\t\t0.088627\n",
      "  validation loss:\t\t0.462667\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 161 of 500 took 8.050s\n",
      "  training loss:\t\t0.101880\n",
      "  validation loss:\t\t0.464398\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 162 of 500 took 8.058s\n",
      "  training loss:\t\t0.092482\n",
      "  validation loss:\t\t0.470343\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 163 of 500 took 8.192s\n",
      "  training loss:\t\t0.104952\n",
      "  validation loss:\t\t0.476017\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 164 of 500 took 8.084s\n",
      "  training loss:\t\t0.095591\n",
      "  validation loss:\t\t0.477896\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 165 of 500 took 7.980s\n",
      "  training loss:\t\t0.098843\n",
      "  validation loss:\t\t0.476822\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 166 of 500 took 7.984s\n",
      "  training loss:\t\t0.105883\n",
      "  validation loss:\t\t0.475435\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 167 of 500 took 8.053s\n",
      "  training loss:\t\t0.098671\n",
      "  validation loss:\t\t0.472556\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 168 of 500 took 8.386s\n",
      "  training loss:\t\t0.091363\n",
      "  validation loss:\t\t0.473445\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 169 of 500 took 8.476s\n",
      "  training loss:\t\t0.097085\n",
      "  validation loss:\t\t0.477489\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 170 of 500 took 9.547s\n",
      "  training loss:\t\t0.091770\n",
      "  validation loss:\t\t0.472175\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 171 of 500 took 8.938s\n",
      "  training loss:\t\t0.098773\n",
      "  validation loss:\t\t0.471045\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 172 of 500 took 9.241s\n",
      "  training loss:\t\t0.097793\n",
      "  validation loss:\t\t0.475658\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 173 of 500 took 8.436s\n",
      "  training loss:\t\t0.098021\n",
      "  validation loss:\t\t0.475641\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 174 of 500 took 8.595s\n",
      "  training loss:\t\t0.092167\n",
      "  validation loss:\t\t0.473906\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 175 of 500 took 8.478s\n",
      "  training loss:\t\t0.091071\n",
      "  validation loss:\t\t0.473783\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 176 of 500 took 8.490s\n",
      "  training loss:\t\t0.090030\n",
      "  validation loss:\t\t0.480054\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 177 of 500 took 8.474s\n",
      "  training loss:\t\t0.090472\n",
      "  validation loss:\t\t0.478987\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 178 of 500 took 8.481s\n",
      "  training loss:\t\t0.088295\n",
      "  validation loss:\t\t0.481867\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 179 of 500 took 8.903s\n",
      "  training loss:\t\t0.096711\n",
      "  validation loss:\t\t0.481449\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 180 of 500 took 8.911s\n",
      "  training loss:\t\t0.092764\n",
      "  validation loss:\t\t0.485360\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 181 of 500 took 8.652s\n",
      "  training loss:\t\t0.096445\n",
      "  validation loss:\t\t0.485001\n",
      "  validation accuracy:\t\t91.22 %%\n",
      "Epoch 182 of 500 took 8.514s\n",
      "  training loss:\t\t0.100977\n",
      "  validation loss:\t\t0.484158\n",
      "  validation accuracy:\t\t91.28 %%\n",
      "Epoch 183 of 500 took 8.500s\n",
      "  training loss:\t\t0.089913\n",
      "  validation loss:\t\t0.488033\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 184 of 500 took 8.470s\n",
      "  training loss:\t\t0.087563\n",
      "  validation loss:\t\t0.491181\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 185 of 500 took 8.481s\n",
      "  training loss:\t\t0.096556\n",
      "  validation loss:\t\t0.488369\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 186 of 500 took 8.463s\n",
      "  training loss:\t\t0.085824\n",
      "  validation loss:\t\t0.480832\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 187 of 500 took 8.445s\n",
      "  training loss:\t\t0.087211\n",
      "  validation loss:\t\t0.486922\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 188 of 500 took 8.482s\n",
      "  training loss:\t\t0.087644\n",
      "  validation loss:\t\t0.487803\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 189 of 500 took 8.480s\n",
      "  training loss:\t\t0.092248\n",
      "  validation loss:\t\t0.486838\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 190 of 500 took 8.460s\n",
      "  training loss:\t\t0.088470\n",
      "  validation loss:\t\t0.487678\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 191 of 500 took 8.466s\n",
      "  training loss:\t\t0.097542\n",
      "  validation loss:\t\t0.482568\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 192 of 500 took 8.517s\n",
      "  training loss:\t\t0.085259\n",
      "  validation loss:\t\t0.494866\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 193 of 500 took 8.521s\n",
      "  training loss:\t\t0.092105\n",
      "  validation loss:\t\t0.494066\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 194 of 500 took 8.475s\n",
      "  training loss:\t\t0.085059\n",
      "  validation loss:\t\t0.493920\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 195 of 500 took 8.468s\n",
      "  training loss:\t\t0.088598\n",
      "  validation loss:\t\t0.493921\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 196 of 500 took 8.475s\n",
      "  training loss:\t\t0.087655\n",
      "  validation loss:\t\t0.493885\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 197 of 500 took 8.455s\n",
      "  training loss:\t\t0.089492\n",
      "  validation loss:\t\t0.493614\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 198 of 500 took 8.465s\n",
      "  training loss:\t\t0.080580\n",
      "  validation loss:\t\t0.499738\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 199 of 500 took 8.485s\n",
      "  training loss:\t\t0.087802\n",
      "  validation loss:\t\t0.502117\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 200 of 500 took 8.496s\n",
      "  training loss:\t\t0.087725\n",
      "  validation loss:\t\t0.504064\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 201 of 500 took 8.477s\n",
      "  training loss:\t\t0.077645\n",
      "  validation loss:\t\t0.501431\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 202 of 500 took 8.436s\n",
      "  training loss:\t\t0.081893\n",
      "  validation loss:\t\t0.503042\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 203 of 500 took 8.472s\n",
      "  training loss:\t\t0.084534\n",
      "  validation loss:\t\t0.505677\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 204 of 500 took 8.461s\n",
      "  training loss:\t\t0.077591\n",
      "  validation loss:\t\t0.504796\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 205 of 500 took 8.448s\n",
      "  training loss:\t\t0.085190\n",
      "  validation loss:\t\t0.505308\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 206 of 500 took 8.448s\n",
      "  training loss:\t\t0.089540\n",
      "  validation loss:\t\t0.505212\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 207 of 500 took 8.523s\n",
      "  training loss:\t\t0.087222\n",
      "  validation loss:\t\t0.504943\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 208 of 500 took 8.516s\n",
      "  training loss:\t\t0.089238\n",
      "  validation loss:\t\t0.506638\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 209 of 500 took 8.456s\n",
      "  training loss:\t\t0.078744\n",
      "  validation loss:\t\t0.507394\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 210 of 500 took 8.508s\n",
      "  training loss:\t\t0.077575\n",
      "  validation loss:\t\t0.508735\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 211 of 500 took 8.459s\n",
      "  training loss:\t\t0.080974\n",
      "  validation loss:\t\t0.511195\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 212 of 500 took 8.470s\n",
      "  training loss:\t\t0.085433\n",
      "  validation loss:\t\t0.510484\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 213 of 500 took 8.446s\n",
      "  training loss:\t\t0.082934\n",
      "  validation loss:\t\t0.504051\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 214 of 500 took 8.455s\n",
      "  training loss:\t\t0.079386\n",
      "  validation loss:\t\t0.513981\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 215 of 500 took 8.461s\n",
      "  training loss:\t\t0.080978\n",
      "  validation loss:\t\t0.516821\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 216 of 500 took 8.422s\n",
      "  training loss:\t\t0.076422\n",
      "  validation loss:\t\t0.516157\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 217 of 500 took 8.538s\n",
      "  training loss:\t\t0.081376\n",
      "  validation loss:\t\t0.516479\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 218 of 500 took 8.445s\n",
      "  training loss:\t\t0.091514\n",
      "  validation loss:\t\t0.518004\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 219 of 500 took 8.444s\n",
      "  training loss:\t\t0.075760\n",
      "  validation loss:\t\t0.513670\n",
      "  validation accuracy:\t\t91.28 %%\n",
      "Epoch 220 of 500 took 8.469s\n",
      "  training loss:\t\t0.078271\n",
      "  validation loss:\t\t0.520163\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 221 of 500 took 8.491s\n",
      "  training loss:\t\t0.076323\n",
      "  validation loss:\t\t0.517244\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 222 of 500 took 9.161s\n",
      "  training loss:\t\t0.072046\n",
      "  validation loss:\t\t0.519454\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 223 of 500 took 10.138s\n",
      "  training loss:\t\t0.077908\n",
      "  validation loss:\t\t0.526828\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 224 of 500 took 9.772s\n",
      "  training loss:\t\t0.076777\n",
      "  validation loss:\t\t0.526905\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 225 of 500 took 9.847s\n",
      "  training loss:\t\t0.079119\n",
      "  validation loss:\t\t0.521161\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 226 of 500 took 8.969s\n",
      "  training loss:\t\t0.074314\n",
      "  validation loss:\t\t0.524121\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 227 of 500 took 8.966s\n",
      "  training loss:\t\t0.073994\n",
      "  validation loss:\t\t0.527849\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 228 of 500 took 8.073s\n",
      "  training loss:\t\t0.076533\n",
      "  validation loss:\t\t0.544782\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 229 of 500 took 7.991s\n",
      "  training loss:\t\t0.082929\n",
      "  validation loss:\t\t0.532855\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 230 of 500 took 8.343s\n",
      "  training loss:\t\t0.078705\n",
      "  validation loss:\t\t0.531564\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 231 of 500 took 9.264s\n",
      "  training loss:\t\t0.082064\n",
      "  validation loss:\t\t0.529370\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 232 of 500 took 9.602s\n",
      "  training loss:\t\t0.080055\n",
      "  validation loss:\t\t0.528040\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 233 of 500 took 8.671s\n",
      "  training loss:\t\t0.077697\n",
      "  validation loss:\t\t0.529061\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 234 of 500 took 10.498s\n",
      "  training loss:\t\t0.073556\n",
      "  validation loss:\t\t0.536451\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 235 of 500 took 8.658s\n",
      "  training loss:\t\t0.081230\n",
      "  validation loss:\t\t0.532984\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 236 of 500 took 8.381s\n",
      "  training loss:\t\t0.073736\n",
      "  validation loss:\t\t0.527453\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 237 of 500 took 8.838s\n",
      "  training loss:\t\t0.073192\n",
      "  validation loss:\t\t0.527120\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 238 of 500 took 10.301s\n",
      "  training loss:\t\t0.077983\n",
      "  validation loss:\t\t0.527094\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 239 of 500 took 9.345s\n",
      "  training loss:\t\t0.079672\n",
      "  validation loss:\t\t0.541390\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 240 of 500 took 9.250s\n",
      "  training loss:\t\t0.075665\n",
      "  validation loss:\t\t0.544127\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 241 of 500 took 8.634s\n",
      "  training loss:\t\t0.084864\n",
      "  validation loss:\t\t0.534699\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 242 of 500 took 8.715s\n",
      "  training loss:\t\t0.069602\n",
      "  validation loss:\t\t0.536780\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 243 of 500 took 9.243s\n",
      "  training loss:\t\t0.072162\n",
      "  validation loss:\t\t0.537704\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 244 of 500 took 9.576s\n",
      "  training loss:\t\t0.069550\n",
      "  validation loss:\t\t0.543009\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 245 of 500 took 9.099s\n",
      "  training loss:\t\t0.075214\n",
      "  validation loss:\t\t0.536443\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 246 of 500 took 9.038s\n",
      "  training loss:\t\t0.072269\n",
      "  validation loss:\t\t0.537285\n",
      "  validation accuracy:\t\t91.33 %%\n",
      "Epoch 247 of 500 took 9.830s\n",
      "  training loss:\t\t0.076817\n",
      "  validation loss:\t\t0.544299\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 248 of 500 took 9.780s\n",
      "  training loss:\t\t0.082049\n",
      "  validation loss:\t\t0.540228\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 249 of 500 took 8.355s\n",
      "  training loss:\t\t0.074364\n",
      "  validation loss:\t\t0.541123\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 250 of 500 took 8.128s\n",
      "  training loss:\t\t0.072832\n",
      "  validation loss:\t\t0.544050\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 251 of 500 took 8.152s\n",
      "  training loss:\t\t0.066944\n",
      "  validation loss:\t\t0.538899\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 252 of 500 took 8.140s\n",
      "  training loss:\t\t0.073176\n",
      "  validation loss:\t\t0.542714\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 253 of 500 took 7.986s\n",
      "  training loss:\t\t0.075761\n",
      "  validation loss:\t\t0.549486\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 254 of 500 took 7.734s\n",
      "  training loss:\t\t0.071130\n",
      "  validation loss:\t\t0.546711\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 255 of 500 took 7.719s\n",
      "  training loss:\t\t0.073437\n",
      "  validation loss:\t\t0.546747\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 256 of 500 took 7.776s\n",
      "  training loss:\t\t0.068962\n",
      "  validation loss:\t\t0.542904\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 257 of 500 took 7.704s\n",
      "  training loss:\t\t0.069504\n",
      "  validation loss:\t\t0.540985\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 258 of 500 took 7.729s\n",
      "  training loss:\t\t0.071965\n",
      "  validation loss:\t\t0.551396\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 259 of 500 took 7.710s\n",
      "  training loss:\t\t0.069358\n",
      "  validation loss:\t\t0.557708\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 260 of 500 took 7.718s\n",
      "  training loss:\t\t0.065204\n",
      "  validation loss:\t\t0.555929\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 261 of 500 took 7.752s\n",
      "  training loss:\t\t0.070527\n",
      "  validation loss:\t\t0.554080\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 262 of 500 took 7.712s\n",
      "  training loss:\t\t0.061877\n",
      "  validation loss:\t\t0.560608\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 263 of 500 took 7.724s\n",
      "  training loss:\t\t0.067391\n",
      "  validation loss:\t\t0.564498\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 264 of 500 took 7.698s\n",
      "  training loss:\t\t0.070225\n",
      "  validation loss:\t\t0.567610\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 265 of 500 took 7.835s\n",
      "  training loss:\t\t0.070686\n",
      "  validation loss:\t\t0.561661\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 266 of 500 took 8.603s\n",
      "  training loss:\t\t0.073988\n",
      "  validation loss:\t\t0.558843\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 267 of 500 took 8.526s\n",
      "  training loss:\t\t0.066463\n",
      "  validation loss:\t\t0.560357\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 268 of 500 took 8.327s\n",
      "  training loss:\t\t0.069873\n",
      "  validation loss:\t\t0.563110\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 269 of 500 took 8.214s\n",
      "  training loss:\t\t0.065835\n",
      "  validation loss:\t\t0.568087\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 270 of 500 took 8.065s\n",
      "  training loss:\t\t0.062029\n",
      "  validation loss:\t\t0.567161\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 271 of 500 took 8.591s\n",
      "  training loss:\t\t0.070486\n",
      "  validation loss:\t\t0.565259\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 272 of 500 took 8.740s\n",
      "  training loss:\t\t0.070800\n",
      "  validation loss:\t\t0.563995\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 273 of 500 took 8.476s\n",
      "  training loss:\t\t0.065995\n",
      "  validation loss:\t\t0.561606\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 274 of 500 took 8.278s\n",
      "  training loss:\t\t0.069388\n",
      "  validation loss:\t\t0.565908\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 275 of 500 took 8.259s\n",
      "  training loss:\t\t0.065163\n",
      "  validation loss:\t\t0.564576\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 276 of 500 took 8.181s\n",
      "  training loss:\t\t0.065311\n",
      "  validation loss:\t\t0.569043\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 277 of 500 took 8.138s\n",
      "  training loss:\t\t0.071489\n",
      "  validation loss:\t\t0.563419\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 278 of 500 took 8.178s\n",
      "  training loss:\t\t0.073568\n",
      "  validation loss:\t\t0.560485\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 279 of 500 took 7.769s\n",
      "  training loss:\t\t0.065205\n",
      "  validation loss:\t\t0.565798\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 280 of 500 took 7.957s\n",
      "  training loss:\t\t0.068708\n",
      "  validation loss:\t\t0.571214\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 281 of 500 took 8.006s\n",
      "  training loss:\t\t0.063439\n",
      "  validation loss:\t\t0.570264\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 282 of 500 took 8.962s\n",
      "  training loss:\t\t0.070227\n",
      "  validation loss:\t\t0.582706\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 283 of 500 took 8.236s\n",
      "  training loss:\t\t0.066541\n",
      "  validation loss:\t\t0.573570\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 284 of 500 took 9.288s\n",
      "  training loss:\t\t0.067381\n",
      "  validation loss:\t\t0.582194\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 285 of 500 took 8.078s\n",
      "  training loss:\t\t0.069467\n",
      "  validation loss:\t\t0.587890\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 286 of 500 took 8.096s\n",
      "  training loss:\t\t0.066977\n",
      "  validation loss:\t\t0.584100\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 287 of 500 took 7.938s\n",
      "  training loss:\t\t0.066451\n",
      "  validation loss:\t\t0.579850\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 288 of 500 took 7.732s\n",
      "  training loss:\t\t0.063691\n",
      "  validation loss:\t\t0.578605\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 289 of 500 took 7.715s\n",
      "  training loss:\t\t0.065236\n",
      "  validation loss:\t\t0.578926\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 290 of 500 took 7.778s\n",
      "  training loss:\t\t0.068859\n",
      "  validation loss:\t\t0.576360\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 291 of 500 took 8.108s\n",
      "  training loss:\t\t0.064727\n",
      "  validation loss:\t\t0.575970\n",
      "  validation accuracy:\t\t91.83 %%\n",
      "Epoch 292 of 500 took 8.009s\n",
      "  training loss:\t\t0.065235\n",
      "  validation loss:\t\t0.580058\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 293 of 500 took 7.889s\n",
      "  training loss:\t\t0.064073\n",
      "  validation loss:\t\t0.583186\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 294 of 500 took 8.727s\n",
      "  training loss:\t\t0.071443\n",
      "  validation loss:\t\t0.581620\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 295 of 500 took 9.116s\n",
      "  training loss:\t\t0.064363\n",
      "  validation loss:\t\t0.584378\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 296 of 500 took 8.359s\n",
      "  training loss:\t\t0.062659\n",
      "  validation loss:\t\t0.581364\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 297 of 500 took 8.064s\n",
      "  training loss:\t\t0.070014\n",
      "  validation loss:\t\t0.581224\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 298 of 500 took 8.218s\n",
      "  training loss:\t\t0.065816\n",
      "  validation loss:\t\t0.576072\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 299 of 500 took 8.177s\n",
      "  training loss:\t\t0.060842\n",
      "  validation loss:\t\t0.580124\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 300 of 500 took 8.130s\n",
      "  training loss:\t\t0.067451\n",
      "  validation loss:\t\t0.591951\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 301 of 500 took 8.128s\n",
      "  training loss:\t\t0.065699\n",
      "  validation loss:\t\t0.591240\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 302 of 500 took 7.919s\n",
      "  training loss:\t\t0.068550\n",
      "  validation loss:\t\t0.585103\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 303 of 500 took 7.768s\n",
      "  training loss:\t\t0.067019\n",
      "  validation loss:\t\t0.584599\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 304 of 500 took 7.765s\n",
      "  training loss:\t\t0.060909\n",
      "  validation loss:\t\t0.577327\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 305 of 500 took 7.716s\n",
      "  training loss:\t\t0.063034\n",
      "  validation loss:\t\t0.583302\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 306 of 500 took 8.008s\n",
      "  training loss:\t\t0.057822\n",
      "  validation loss:\t\t0.588508\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 307 of 500 took 7.958s\n",
      "  training loss:\t\t0.064810\n",
      "  validation loss:\t\t0.589272\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 308 of 500 took 9.002s\n",
      "  training loss:\t\t0.060459\n",
      "  validation loss:\t\t0.589208\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 309 of 500 took 9.613s\n",
      "  training loss:\t\t0.061852\n",
      "  validation loss:\t\t0.589931\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 310 of 500 took 12.188s\n",
      "  training loss:\t\t0.059315\n",
      "  validation loss:\t\t0.591108\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 311 of 500 took 9.891s\n",
      "  training loss:\t\t0.059287\n",
      "  validation loss:\t\t0.593585\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 312 of 500 took 10.920s\n",
      "  training loss:\t\t0.063341\n",
      "  validation loss:\t\t0.590781\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 313 of 500 took 11.416s\n",
      "  training loss:\t\t0.062674\n",
      "  validation loss:\t\t0.596088\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 314 of 500 took 10.485s\n",
      "  training loss:\t\t0.060944\n",
      "  validation loss:\t\t0.596639\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 315 of 500 took 10.185s\n",
      "  training loss:\t\t0.057207\n",
      "  validation loss:\t\t0.606816\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 316 of 500 took 10.334s\n",
      "  training loss:\t\t0.058679\n",
      "  validation loss:\t\t0.613511\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 317 of 500 took 11.053s\n",
      "  training loss:\t\t0.067878\n",
      "  validation loss:\t\t0.608059\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 318 of 500 took 10.211s\n",
      "  training loss:\t\t0.065689\n",
      "  validation loss:\t\t0.595174\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 319 of 500 took 10.045s\n",
      "  training loss:\t\t0.062668\n",
      "  validation loss:\t\t0.608245\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 320 of 500 took 10.109s\n",
      "  training loss:\t\t0.061417\n",
      "  validation loss:\t\t0.607465\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 321 of 500 took 9.782s\n",
      "  training loss:\t\t0.058104\n",
      "  validation loss:\t\t0.612473\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 322 of 500 took 9.763s\n",
      "  training loss:\t\t0.058257\n",
      "  validation loss:\t\t0.612049\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 323 of 500 took 10.078s\n",
      "  training loss:\t\t0.061984\n",
      "  validation loss:\t\t0.614791\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 324 of 500 took 10.113s\n",
      "  training loss:\t\t0.061444\n",
      "  validation loss:\t\t0.609906\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 325 of 500 took 9.875s\n",
      "  training loss:\t\t0.056909\n",
      "  validation loss:\t\t0.609743\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 326 of 500 took 10.121s\n",
      "  training loss:\t\t0.059162\n",
      "  validation loss:\t\t0.610331\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 327 of 500 took 10.657s\n",
      "  training loss:\t\t0.059588\n",
      "  validation loss:\t\t0.612038\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 328 of 500 took 11.084s\n",
      "  training loss:\t\t0.057227\n",
      "  validation loss:\t\t0.608105\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 329 of 500 took 10.618s\n",
      "  training loss:\t\t0.058863\n",
      "  validation loss:\t\t0.617286\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 330 of 500 took 10.051s\n",
      "  training loss:\t\t0.058075\n",
      "  validation loss:\t\t0.616115\n",
      "  validation accuracy:\t\t91.89 %%\n",
      "Epoch 331 of 500 took 10.014s\n",
      "  training loss:\t\t0.055830\n",
      "  validation loss:\t\t0.617402\n",
      "  validation accuracy:\t\t92.00 %%\n",
      "Epoch 332 of 500 took 9.911s\n",
      "  training loss:\t\t0.060789\n",
      "  validation loss:\t\t0.608375\n",
      "  validation accuracy:\t\t91.83 %%\n",
      "Epoch 333 of 500 took 10.102s\n",
      "  training loss:\t\t0.056604\n",
      "  validation loss:\t\t0.606503\n",
      "  validation accuracy:\t\t91.83 %%\n",
      "Epoch 334 of 500 took 10.161s\n",
      "  training loss:\t\t0.054199\n",
      "  validation loss:\t\t0.618866\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 335 of 500 took 10.089s\n",
      "  training loss:\t\t0.058255\n",
      "  validation loss:\t\t0.626786\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 336 of 500 took 8.625s\n",
      "  training loss:\t\t0.061685\n",
      "  validation loss:\t\t0.626172\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 337 of 500 took 8.516s\n",
      "  training loss:\t\t0.060982\n",
      "  validation loss:\t\t0.629723\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 338 of 500 took 9.332s\n",
      "  training loss:\t\t0.057052\n",
      "  validation loss:\t\t0.636907\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 339 of 500 took 9.208s\n",
      "  training loss:\t\t0.059177\n",
      "  validation loss:\t\t0.634128\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 340 of 500 took 9.281s\n",
      "  training loss:\t\t0.058930\n",
      "  validation loss:\t\t0.629609\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 341 of 500 took 8.505s\n",
      "  training loss:\t\t0.062237\n",
      "  validation loss:\t\t0.628153\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 342 of 500 took 8.225s\n",
      "  training loss:\t\t0.059541\n",
      "  validation loss:\t\t0.630584\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 343 of 500 took 8.223s\n",
      "  training loss:\t\t0.058052\n",
      "  validation loss:\t\t0.627914\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 344 of 500 took 8.168s\n",
      "  training loss:\t\t0.056979\n",
      "  validation loss:\t\t0.629148\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 345 of 500 took 8.863s\n",
      "  training loss:\t\t0.053981\n",
      "  validation loss:\t\t0.625762\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 346 of 500 took 8.679s\n",
      "  training loss:\t\t0.055207\n",
      "  validation loss:\t\t0.626059\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 347 of 500 took 8.765s\n",
      "  training loss:\t\t0.059341\n",
      "  validation loss:\t\t0.629674\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 348 of 500 took 7.946s\n",
      "  training loss:\t\t0.057693\n",
      "  validation loss:\t\t0.629653\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 349 of 500 took 7.997s\n",
      "  training loss:\t\t0.058866\n",
      "  validation loss:\t\t0.628990\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 350 of 500 took 7.826s\n",
      "  training loss:\t\t0.061568\n",
      "  validation loss:\t\t0.631221\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 351 of 500 took 8.573s\n",
      "  training loss:\t\t0.056813\n",
      "  validation loss:\t\t0.628519\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 352 of 500 took 8.077s\n",
      "  training loss:\t\t0.057131\n",
      "  validation loss:\t\t0.633806\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 353 of 500 took 7.768s\n",
      "  training loss:\t\t0.057952\n",
      "  validation loss:\t\t0.631379\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 354 of 500 took 8.518s\n",
      "  training loss:\t\t0.055260\n",
      "  validation loss:\t\t0.636736\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 355 of 500 took 7.804s\n",
      "  training loss:\t\t0.061668\n",
      "  validation loss:\t\t0.638516\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 356 of 500 took 7.934s\n",
      "  training loss:\t\t0.059401\n",
      "  validation loss:\t\t0.640418\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 357 of 500 took 7.808s\n",
      "  training loss:\t\t0.054215\n",
      "  validation loss:\t\t0.641774\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 358 of 500 took 8.488s\n",
      "  training loss:\t\t0.057132\n",
      "  validation loss:\t\t0.636320\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 359 of 500 took 8.738s\n",
      "  training loss:\t\t0.058177\n",
      "  validation loss:\t\t0.630712\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 360 of 500 took 8.284s\n",
      "  training loss:\t\t0.057250\n",
      "  validation loss:\t\t0.636712\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 361 of 500 took 8.241s\n",
      "  training loss:\t\t0.059114\n",
      "  validation loss:\t\t0.642611\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 362 of 500 took 8.521s\n",
      "  training loss:\t\t0.054331\n",
      "  validation loss:\t\t0.655219\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 363 of 500 took 9.345s\n",
      "  training loss:\t\t0.059996\n",
      "  validation loss:\t\t0.648401\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 364 of 500 took 8.900s\n",
      "  training loss:\t\t0.056525\n",
      "  validation loss:\t\t0.652247\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 365 of 500 took 8.162s\n",
      "  training loss:\t\t0.056131\n",
      "  validation loss:\t\t0.642085\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 366 of 500 took 8.713s\n",
      "  training loss:\t\t0.055034\n",
      "  validation loss:\t\t0.635638\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 367 of 500 took 8.610s\n",
      "  training loss:\t\t0.054809\n",
      "  validation loss:\t\t0.637193\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 368 of 500 took 8.985s\n",
      "  training loss:\t\t0.054491\n",
      "  validation loss:\t\t0.650785\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 369 of 500 took 9.040s\n",
      "  training loss:\t\t0.056154\n",
      "  validation loss:\t\t0.645339\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 370 of 500 took 9.441s\n",
      "  training loss:\t\t0.053508\n",
      "  validation loss:\t\t0.639937\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 371 of 500 took 8.591s\n",
      "  training loss:\t\t0.059881\n",
      "  validation loss:\t\t0.637677\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 372 of 500 took 9.027s\n",
      "  training loss:\t\t0.049557\n",
      "  validation loss:\t\t0.643868\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 373 of 500 took 8.384s\n",
      "  training loss:\t\t0.058366\n",
      "  validation loss:\t\t0.646642\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 374 of 500 took 8.332s\n",
      "  training loss:\t\t0.052769\n",
      "  validation loss:\t\t0.644484\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 375 of 500 took 8.273s\n",
      "  training loss:\t\t0.051173\n",
      "  validation loss:\t\t0.646937\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 376 of 500 took 7.893s\n",
      "  training loss:\t\t0.050534\n",
      "  validation loss:\t\t0.656790\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 377 of 500 took 8.077s\n",
      "  training loss:\t\t0.051329\n",
      "  validation loss:\t\t0.659608\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 378 of 500 took 8.385s\n",
      "  training loss:\t\t0.052536\n",
      "  validation loss:\t\t0.657273\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 379 of 500 took 9.499s\n",
      "  training loss:\t\t0.052792\n",
      "  validation loss:\t\t0.659251\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 380 of 500 took 8.336s\n",
      "  training loss:\t\t0.052999\n",
      "  validation loss:\t\t0.667507\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 381 of 500 took 8.286s\n",
      "  training loss:\t\t0.051646\n",
      "  validation loss:\t\t0.659843\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 382 of 500 took 8.387s\n",
      "  training loss:\t\t0.054904\n",
      "  validation loss:\t\t0.659721\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 383 of 500 took 7.884s\n",
      "  training loss:\t\t0.052964\n",
      "  validation loss:\t\t0.657719\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 384 of 500 took 8.068s\n",
      "  training loss:\t\t0.054301\n",
      "  validation loss:\t\t0.659502\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 385 of 500 took 8.038s\n",
      "  training loss:\t\t0.052653\n",
      "  validation loss:\t\t0.663138\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 386 of 500 took 8.488s\n",
      "  training loss:\t\t0.052984\n",
      "  validation loss:\t\t0.668524\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 387 of 500 took 7.875s\n",
      "  training loss:\t\t0.060153\n",
      "  validation loss:\t\t0.665628\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 388 of 500 took 8.243s\n",
      "  training loss:\t\t0.053894\n",
      "  validation loss:\t\t0.655839\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 389 of 500 took 7.991s\n",
      "  training loss:\t\t0.053950\n",
      "  validation loss:\t\t0.662946\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 390 of 500 took 8.739s\n",
      "  training loss:\t\t0.057009\n",
      "  validation loss:\t\t0.671535\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 391 of 500 took 8.928s\n",
      "  training loss:\t\t0.055961\n",
      "  validation loss:\t\t0.681450\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 392 of 500 took 8.166s\n",
      "  training loss:\t\t0.057683\n",
      "  validation loss:\t\t0.675246\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 393 of 500 took 8.391s\n",
      "  training loss:\t\t0.049047\n",
      "  validation loss:\t\t0.674706\n",
      "  validation accuracy:\t\t91.83 %%\n",
      "Epoch 394 of 500 took 8.138s\n",
      "  training loss:\t\t0.053826\n",
      "  validation loss:\t\t0.674673\n",
      "  validation accuracy:\t\t91.94 %%\n",
      "Epoch 395 of 500 took 7.908s\n",
      "  training loss:\t\t0.048252\n",
      "  validation loss:\t\t0.680639\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 396 of 500 took 8.732s\n",
      "  training loss:\t\t0.053613\n",
      "  validation loss:\t\t0.682438\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 397 of 500 took 8.775s\n",
      "  training loss:\t\t0.051767\n",
      "  validation loss:\t\t0.676715\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 398 of 500 took 8.888s\n",
      "  training loss:\t\t0.049285\n",
      "  validation loss:\t\t0.674510\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 399 of 500 took 8.464s\n",
      "  training loss:\t\t0.055691\n",
      "  validation loss:\t\t0.671178\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 400 of 500 took 8.977s\n",
      "  training loss:\t\t0.054048\n",
      "  validation loss:\t\t0.671859\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 401 of 500 took 7.934s\n",
      "  training loss:\t\t0.047576\n",
      "  validation loss:\t\t0.674482\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 402 of 500 took 7.782s\n",
      "  training loss:\t\t0.059550\n",
      "  validation loss:\t\t0.673505\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 403 of 500 took 7.750s\n",
      "  training loss:\t\t0.056039\n",
      "  validation loss:\t\t0.677782\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 404 of 500 took 7.717s\n",
      "  training loss:\t\t0.048353\n",
      "  validation loss:\t\t0.669602\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 405 of 500 took 7.721s\n",
      "  training loss:\t\t0.049227\n",
      "  validation loss:\t\t0.675581\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 406 of 500 took 8.192s\n",
      "  training loss:\t\t0.057521\n",
      "  validation loss:\t\t0.674451\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 407 of 500 took 7.719s\n",
      "  training loss:\t\t0.048936\n",
      "  validation loss:\t\t0.682859\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 408 of 500 took 8.188s\n",
      "  training loss:\t\t0.050401\n",
      "  validation loss:\t\t0.680370\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 409 of 500 took 7.967s\n",
      "  training loss:\t\t0.050197\n",
      "  validation loss:\t\t0.679696\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 410 of 500 took 8.516s\n",
      "  training loss:\t\t0.051313\n",
      "  validation loss:\t\t0.687702\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 411 of 500 took 8.247s\n",
      "  training loss:\t\t0.056572\n",
      "  validation loss:\t\t0.681294\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 412 of 500 took 8.831s\n",
      "  training loss:\t\t0.049178\n",
      "  validation loss:\t\t0.677349\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 413 of 500 took 8.217s\n",
      "  training loss:\t\t0.051110\n",
      "  validation loss:\t\t0.677458\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 414 of 500 took 9.294s\n",
      "  training loss:\t\t0.047864\n",
      "  validation loss:\t\t0.684920\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 415 of 500 took 9.925s\n",
      "  training loss:\t\t0.050745\n",
      "  validation loss:\t\t0.689181\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 416 of 500 took 8.869s\n",
      "  training loss:\t\t0.055240\n",
      "  validation loss:\t\t0.689608\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 417 of 500 took 8.069s\n",
      "  training loss:\t\t0.049590\n",
      "  validation loss:\t\t0.684161\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 418 of 500 took 9.002s\n",
      "  training loss:\t\t0.052610\n",
      "  validation loss:\t\t0.678260\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 419 of 500 took 8.832s\n",
      "  training loss:\t\t0.050377\n",
      "  validation loss:\t\t0.678977\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 420 of 500 took 8.813s\n",
      "  training loss:\t\t0.049823\n",
      "  validation loss:\t\t0.684736\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 421 of 500 took 8.276s\n",
      "  training loss:\t\t0.048162\n",
      "  validation loss:\t\t0.687514\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 422 of 500 took 8.342s\n",
      "  training loss:\t\t0.052653\n",
      "  validation loss:\t\t0.691420\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 423 of 500 took 8.442s\n",
      "  training loss:\t\t0.051882\n",
      "  validation loss:\t\t0.691230\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 424 of 500 took 8.918s\n",
      "  training loss:\t\t0.055889\n",
      "  validation loss:\t\t0.689918\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 425 of 500 took 8.964s\n",
      "  training loss:\t\t0.052106\n",
      "  validation loss:\t\t0.692540\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 426 of 500 took 8.633s\n",
      "  training loss:\t\t0.052250\n",
      "  validation loss:\t\t0.687681\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 427 of 500 took 8.061s\n",
      "  training loss:\t\t0.049013\n",
      "  validation loss:\t\t0.688845\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 428 of 500 took 8.251s\n",
      "  training loss:\t\t0.048669\n",
      "  validation loss:\t\t0.701803\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 429 of 500 took 8.571s\n",
      "  training loss:\t\t0.050265\n",
      "  validation loss:\t\t0.700178\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 430 of 500 took 8.275s\n",
      "  training loss:\t\t0.052374\n",
      "  validation loss:\t\t0.692517\n",
      "  validation accuracy:\t\t91.83 %%\n",
      "Epoch 431 of 500 took 8.286s\n",
      "  training loss:\t\t0.046141\n",
      "  validation loss:\t\t0.689549\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 432 of 500 took 8.188s\n",
      "  training loss:\t\t0.050649\n",
      "  validation loss:\t\t0.685274\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 433 of 500 took 8.282s\n",
      "  training loss:\t\t0.048686\n",
      "  validation loss:\t\t0.691581\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 434 of 500 took 8.611s\n",
      "  training loss:\t\t0.054127\n",
      "  validation loss:\t\t0.700463\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 435 of 500 took 8.623s\n",
      "  training loss:\t\t0.050287\n",
      "  validation loss:\t\t0.699031\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 436 of 500 took 8.233s\n",
      "  training loss:\t\t0.045860\n",
      "  validation loss:\t\t0.703443\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 437 of 500 took 8.397s\n",
      "  training loss:\t\t0.048942\n",
      "  validation loss:\t\t0.711065\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 438 of 500 took 8.368s\n",
      "  training loss:\t\t0.054221\n",
      "  validation loss:\t\t0.710868\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 439 of 500 took 8.427s\n",
      "  training loss:\t\t0.051811\n",
      "  validation loss:\t\t0.712424\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 440 of 500 took 8.165s\n",
      "  training loss:\t\t0.050964\n",
      "  validation loss:\t\t0.721268\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 441 of 500 took 8.431s\n",
      "  training loss:\t\t0.054101\n",
      "  validation loss:\t\t0.711240\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 442 of 500 took 8.590s\n",
      "  training loss:\t\t0.047722\n",
      "  validation loss:\t\t0.708111\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 443 of 500 took 8.171s\n",
      "  training loss:\t\t0.050449\n",
      "  validation loss:\t\t0.708979\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 444 of 500 took 7.673s\n",
      "  training loss:\t\t0.053391\n",
      "  validation loss:\t\t0.707363\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 445 of 500 took 8.194s\n",
      "  training loss:\t\t0.045950\n",
      "  validation loss:\t\t0.715141\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 446 of 500 took 8.795s\n",
      "  training loss:\t\t0.051014\n",
      "  validation loss:\t\t0.717892\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 447 of 500 took 9.043s\n",
      "  training loss:\t\t0.046329\n",
      "  validation loss:\t\t0.717856\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 448 of 500 took 9.695s\n",
      "  training loss:\t\t0.052917\n",
      "  validation loss:\t\t0.718168\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 449 of 500 took 8.888s\n",
      "  training loss:\t\t0.047658\n",
      "  validation loss:\t\t0.707557\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 450 of 500 took 8.479s\n",
      "  training loss:\t\t0.053127\n",
      "  validation loss:\t\t0.714930\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 451 of 500 took 8.756s\n",
      "  training loss:\t\t0.050103\n",
      "  validation loss:\t\t0.722252\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 452 of 500 took 8.842s\n",
      "  training loss:\t\t0.052252\n",
      "  validation loss:\t\t0.721087\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 453 of 500 took 8.112s\n",
      "  training loss:\t\t0.049054\n",
      "  validation loss:\t\t0.724030\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 454 of 500 took 8.160s\n",
      "  training loss:\t\t0.047802\n",
      "  validation loss:\t\t0.727765\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 455 of 500 took 8.083s\n",
      "  training loss:\t\t0.052666\n",
      "  validation loss:\t\t0.720879\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 456 of 500 took 8.027s\n",
      "  training loss:\t\t0.046147\n",
      "  validation loss:\t\t0.720249\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 457 of 500 took 8.303s\n",
      "  training loss:\t\t0.048139\n",
      "  validation loss:\t\t0.721613\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 458 of 500 took 8.321s\n",
      "  training loss:\t\t0.049888\n",
      "  validation loss:\t\t0.725650\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 459 of 500 took 8.507s\n",
      "  training loss:\t\t0.053001\n",
      "  validation loss:\t\t0.726647\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 460 of 500 took 8.704s\n",
      "  training loss:\t\t0.046399\n",
      "  validation loss:\t\t0.730757\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 461 of 500 took 8.038s\n",
      "  training loss:\t\t0.049380\n",
      "  validation loss:\t\t0.737268\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 462 of 500 took 8.355s\n",
      "  training loss:\t\t0.044239\n",
      "  validation loss:\t\t0.738011\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 463 of 500 took 8.459s\n",
      "  training loss:\t\t0.042156\n",
      "  validation loss:\t\t0.739713\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 464 of 500 took 8.895s\n",
      "  training loss:\t\t0.046243\n",
      "  validation loss:\t\t0.743051\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 465 of 500 took 8.136s\n",
      "  training loss:\t\t0.043479\n",
      "  validation loss:\t\t0.736363\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 466 of 500 took 8.766s\n",
      "  training loss:\t\t0.045703\n",
      "  validation loss:\t\t0.736259\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 467 of 500 took 8.047s\n",
      "  training loss:\t\t0.046540\n",
      "  validation loss:\t\t0.739406\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 468 of 500 took 8.215s\n",
      "  training loss:\t\t0.044899\n",
      "  validation loss:\t\t0.748555\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 469 of 500 took 7.864s\n",
      "  training loss:\t\t0.046528\n",
      "  validation loss:\t\t0.748023\n",
      "  validation accuracy:\t\t91.72 %%\n",
      "Epoch 470 of 500 took 7.947s\n",
      "  training loss:\t\t0.054135\n",
      "  validation loss:\t\t0.735195\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 471 of 500 took 8.301s\n",
      "  training loss:\t\t0.051078\n",
      "  validation loss:\t\t0.732389\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 472 of 500 took 8.774s\n",
      "  training loss:\t\t0.052797\n",
      "  validation loss:\t\t0.729547\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 473 of 500 took 9.257s\n",
      "  training loss:\t\t0.049869\n",
      "  validation loss:\t\t0.728259\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 474 of 500 took 8.677s\n",
      "  training loss:\t\t0.047889\n",
      "  validation loss:\t\t0.726912\n",
      "  validation accuracy:\t\t91.44 %%\n",
      "Epoch 475 of 500 took 8.407s\n",
      "  training loss:\t\t0.048164\n",
      "  validation loss:\t\t0.728782\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 476 of 500 took 8.629s\n",
      "  training loss:\t\t0.044943\n",
      "  validation loss:\t\t0.731428\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 477 of 500 took 8.637s\n",
      "  training loss:\t\t0.050211\n",
      "  validation loss:\t\t0.733520\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 478 of 500 took 8.497s\n",
      "  training loss:\t\t0.049596\n",
      "  validation loss:\t\t0.733222\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 479 of 500 took 8.804s\n",
      "  training loss:\t\t0.045717\n",
      "  validation loss:\t\t0.725851\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 480 of 500 took 8.863s\n",
      "  training loss:\t\t0.052235\n",
      "  validation loss:\t\t0.736619\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 481 of 500 took 8.717s\n",
      "  training loss:\t\t0.052828\n",
      "  validation loss:\t\t0.744000\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 482 of 500 took 8.543s\n",
      "  training loss:\t\t0.047218\n",
      "  validation loss:\t\t0.743563\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 483 of 500 took 8.422s\n",
      "  training loss:\t\t0.046681\n",
      "  validation loss:\t\t0.731883\n",
      "  validation accuracy:\t\t91.39 %%\n",
      "Epoch 484 of 500 took 8.348s\n",
      "  training loss:\t\t0.048674\n",
      "  validation loss:\t\t0.733259\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 485 of 500 took 8.003s\n",
      "  training loss:\t\t0.046544\n",
      "  validation loss:\t\t0.739202\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 486 of 500 took 8.279s\n",
      "  training loss:\t\t0.044495\n",
      "  validation loss:\t\t0.747717\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 487 of 500 took 9.059s\n",
      "  training loss:\t\t0.048001\n",
      "  validation loss:\t\t0.748622\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 488 of 500 took 8.136s\n",
      "  training loss:\t\t0.044960\n",
      "  validation loss:\t\t0.745414\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 489 of 500 took 7.915s\n",
      "  training loss:\t\t0.051101\n",
      "  validation loss:\t\t0.740284\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 490 of 500 took 8.013s\n",
      "  training loss:\t\t0.045666\n",
      "  validation loss:\t\t0.746112\n",
      "  validation accuracy:\t\t91.78 %%\n",
      "Epoch 491 of 500 took 8.203s\n",
      "  training loss:\t\t0.046060\n",
      "  validation loss:\t\t0.743386\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 492 of 500 took 8.579s\n",
      "  training loss:\t\t0.045854\n",
      "  validation loss:\t\t0.739381\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 493 of 500 took 8.680s\n",
      "  training loss:\t\t0.043923\n",
      "  validation loss:\t\t0.740046\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 494 of 500 took 7.996s\n",
      "  training loss:\t\t0.045049\n",
      "  validation loss:\t\t0.744791\n",
      "  validation accuracy:\t\t91.50 %%\n",
      "Epoch 495 of 500 took 8.474s\n",
      "  training loss:\t\t0.047743\n",
      "  validation loss:\t\t0.743735\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 496 of 500 took 8.564s\n",
      "  training loss:\t\t0.051283\n",
      "  validation loss:\t\t0.746024\n",
      "  validation accuracy:\t\t91.67 %%\n",
      "Epoch 497 of 500 took 8.060s\n",
      "  training loss:\t\t0.048341\n",
      "  validation loss:\t\t0.747822\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 498 of 500 took 7.968s\n",
      "  training loss:\t\t0.046824\n",
      "  validation loss:\t\t0.742437\n",
      "  validation accuracy:\t\t91.56 %%\n",
      "Epoch 499 of 500 took 7.722s\n",
      "  training loss:\t\t0.040792\n",
      "  validation loss:\t\t0.743491\n",
      "  validation accuracy:\t\t91.61 %%\n",
      "Epoch 500 of 500 took 7.803s\n",
      "  training loss:\t\t0.047672\n",
      "  validation loss:\t\t0.745802\n",
      "  validation accuracy:\t\t91.67 %%\n"
     ]
    }
   ],
   "source": [
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "dataset = load_data(features, labels)\n",
    "\n",
    "print(\"Building model and compiling functions...\")\n",
    "output_layer = build_model(\n",
    "    input_height=dataset['input_height'], # 28\n",
    "    input_width=dataset['input_width'], # 28\n",
    "    output_dim=dataset['output_dim'], # 9\n",
    "    )\n",
    "\n",
    "iter_funcs = create_iter_functions(\n",
    "    dataset,\n",
    "    output_layer,\n",
    "    X_tensor_type=T.tensor4,\n",
    "    )\n",
    "\n",
    "num_epochs = NUM_EPOCHS\n",
    "\n",
    "print(\"Starting training...\")\n",
    "now = time.time()\n",
    "try:\n",
    "    for epoch in train(iter_funcs, dataset):\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch['number'], num_epochs, time.time() - now))\n",
    "        now = time.time()\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(epoch['train_loss']))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(epoch['valid_loss']))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %%\".format(\n",
    "            epoch['valid_accuracy'] * 100))\n",
    "\n",
    "        if epoch['number'] >= num_epochs:\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set\n",
      "[[  0 423]\n",
      " [  1 619]\n",
      " [  2 383]\n",
      " [  3 404]\n",
      " [  4 478]\n",
      " [  5 425]\n",
      " [  6 259]\n",
      " [  7 551]\n",
      " [  8 458]]\n",
      "test set\n",
      "[[  0 114]\n",
      " [  1 172]\n",
      " [  2 101]\n",
      " [  3  95]\n",
      " [  4 127]\n",
      " [  5  85]\n",
      " [  6  54]\n",
      " [  7 141]\n",
      " [  8 111]]\n",
      "validation set\n",
      "[[  0 103]\n",
      " [  1 130]\n",
      " [  2 132]\n",
      " [  3  94]\n",
      " [  4 134]\n",
      " [  5 109]\n",
      " [  6  57]\n",
      " [  7 148]\n",
      " [  8  93]]\n"
     ]
    }
   ],
   "source": [
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "unique_train, counts_train = np.unique(labels[:4000], return_counts=True)\n",
    "unique_valid, counts_valid = np.unique(labels[4000:5000], return_counts=True)\n",
    "unique_test, counts_test = np.unique(labels[5000:], return_counts=True)\n",
    "\n",
    "print (\"train set\")\n",
    "print (\"{}\".format(np.asarray((unique_train, counts_train)).T))\n",
    "print (\"test set\")\n",
    "print (\"{}\".format(np.asarray((unique_valid, counts_valid)).T))\n",
    "print (\"validation set\")\n",
    "print (\"{}\".format(np.asarray((unique_test, counts_test)).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 423.,  619.,  383.,  404.,  478.,  425.,  259.,  551.,  458.]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " <a list of 9 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGKCAYAAAD0YbClAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu0ZnV93/H3hwGBiFyCyxmLEbCNoSQKSmmUchGiU0sa\n",
       "k+IlhEBBEmoSiKGEpQUhGdRoSrpwDNJmmUWiwSWiMQQ6qZGLXBoBiRMyKoFIKkMddGa4ZcpVbt/+\n",
       "sfchDw9zeWbmnLPP/M77tdazzrN/+7f3892cYZ7P/PZv752qQpIkaVu33dAFSJIkTQdDjSRJaoKh\n",
       "RpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSE2Y91CRZmeTZ9byW9euTZEmSe5M8luS6JPuP7WPH\n",
       "JBcmuS/JI0muSLLXbB+LJEmaO4YYqTkIWDTyej1QwGX9+vcBZwCnAQcDa4Grk+wyso+lwDHAscBh\n",
       "wK7AsiSOPEmSNE9l6DsKJ/kA8JvAy4Enge8Bv19VH+3X70QXbM6sqk8m2a1fPqmqLu37vAK4B/h3\n",
       "VXXVAIchSZIGNujIRpIAvwR8pqp+AOwLLASeCyZV9QRwI3BI33QQsMNYn1XAHSN9JEnSPDP06Zq3\n",
       "APsAf9gvL+p/rhnrt3Zk3SLgmap6YKzPGrpAJEmS5qGhQ80pwK1V9c0J+vrkTUmStEHbD/XBSV4G\n",
       "vA34tZHm1f3PhcCqkfaFI+tWAwuS7Dk2WrOI7jTV+OcUcN5I0/VVdf3WVS9JkuaawUINcBLwBHDp\n",
       "SNvddKFlMbAcnpsofChwZt9nOfBU32d0ovB+wE3r+6CqWjLdxUuSpLllkFDTTxD+ZeBzVfXYVHtV\n",
       "VZKlwNlJ7gTuAs4BHgY+2/dZl+Ri4Pwka4EHgQuAFcA1s3skkiRprhhqpOZNwD8HjhtfUVXnJ9kZ\n",
       "uAjYA7gFWFxVj450Ox14mu7eNjvThZnja+jr0yVJ0mAGv0/NTEtSVZWh65AkSTNr6KufJEmSpoWh\n",
       "RpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKa\n",
       "YKiRJElNMNRIkqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiS\n",
       "pCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1\n",
       "kiSpCYYaSZLUBEONJElqgqFGkiQ1YfuhC9DWSVJD1zDTqipD1yBJmvsMNQ044oRzhy5hxtxwyYeG\n",
       "LkGStI3w9JMkSWrCIKEmycuTfDrJ2iSPJ7k9yeFjfZYkuTfJY0muS7L/2Podk1yY5L4kjyS5Isle\n",
       "s3skkiRprpj1UJNkd+CrQAFHA/sBpwFrR/q8Hzijbz+4X3d1kl1GdrUUOAY4FjgM2BVYlsTRJ0mS\n",
       "5qEh5tS8D7i3qk4aabtn6k2SAKcDH62qy/u2E+mCzXHAJ5PsBpwMnFRV1/Z9Tuj382bgqlk4DkmS\n",
       "NIcMMarxc8CtSS5LsibJbUlOHVm/L7CQkWBSVU8ANwKH9E0HATuM9VkF3DHSR5IkzSNDhJpXAb8G\n",
       "/AOwGPg48LsjwWZR/3PN2HZrR9YtAp6pqgfG+qyhC0SSJGmeGeL003bArVX1gX55RZIfBU4FLtrE\n",
       "ts3fk0WSJG2ZIULN94C/G2u7E3hl/351/3MhsGqkz8KRdauBBUn2HButWUR3mup5kiwZWby+qq7f\n",
       "osolSdKcNUSo+SrdFU+jXg2s7N/fTRdaFgPLAZLsBBwKnNn3WQ481fe5tO/zin6/N41/YFUtmcb6\n",
       "JUnSHDREqPkYcFOSs4HPA68Dfh04C6CqKslS4OwkdwJ3AecADwOf7fusS3IxcH6StcCDwAXACuCa\n",
       "WT4eSZI0B8x6qKmqryf5OeAjwLl0l2GfU1X/Y6TP+Ul2pptjswdwC7C4qh4d2dXpwNPAZcDOdGHm\n",
       "+Kpy3o0kSfNQWs8ASarlByImqdaf/dTy70+SNH28+64kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiS\n",
       "pCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1\n",
       "kiSpCYYaSZLUBEONJElqgqFGkiQ1YfuhC5AkabYlqaFrmGlVlaFrmG2GGknSvHTECecOXcKMueGS\n",
       "Dw1dwiA8/SRJkppgqJEkSU0w1EiSpCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mS\n",
       "mmCokSRJTTDUSJKkJhhqJElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKaMOuhJsmSJM+O\n",
       "vb63nj73JnksyXVJ9h9bv2OSC5Pcl+SRJFck2Wt2j0SSJM0lQ43U3AksGnm9ZmpFkvcDZwCnAQcD\n",
       "a4Grk+wysv1S4BjgWOAwYFdgWRJHniRJmqe2H+hzn6mqteONSQKcDny0qi7v206kCzbHAZ9Mshtw\n",
       "MnBSVV3b9zkBuAd4M3DV7ByCJEmaS4Ya2XhVf3rpO0kuTbJv374vsJCRYFJVTwA3Aof0TQcBO4z1\n",
       "WQXcMdJHkiTNM0OEmluAE4F/C5xCd/rppiQ/3L8HWDO2zdqRdYvoRnoeGOuzhi4QSZKkeWjWTz9V\n",
       "1V+OLH4ryc3A3XRB52sb23RGC5MkSdu0oebUPKeqHktyO/AvgD/vmxcCq0a6LQRW9+9XAwuS7Dk2\n",
       "WrOI7jTVCyRZMrJ4fVVdPw2lS5KkOWTwUJNkJ+BfAl+pqruTrAYWA8tH1h8KnNlvshx4qu9zad/n\n",
       "FcB+wE3r+4yqWjKDhyBJkuaAWQ81Sf4bcCXwXeBlwLnAzsCn+y5LgbOT3AncBZwDPAx8FqCq1iW5\n",
       "GDg/yVrgQeACYAVwzSweiiRJmkOGGKnZi26E5aXAfcDNwBuq6rsAVXV+kp2Bi4A96CYWL66qR0f2\n",
       "cTrwNHAZXSC6Bji+qpx3I0nSPDXEROFfmKDPecB5G1n/JPDe/iVJkuSznyRJUhsMNZIkqQmGGkmS\n",
       "1ARDjSRJaoKhRpIkNWHwm+9JalOS5m+xUFUZugZJ/8RQI2nGHHHCuUOXMGNuuORDQ5cgaYynnyRJ\n",
       "UhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJnjzPUmSGtTqXb03didv\n",
       "Q40kSQ1q+Y7eG+LpJ0mS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1kiSp\n",
       "CYYaSZLUBEONJElqgqFGkiQ1wVAjSZKaYKiRJElNmBdP6U4yL45TkqT5bJ582efJoSuYGZWhK5Dm\n",
       "syQ1dA0zqcq/Y7RtmReh5ogTzmnyf8yVK27gnm/cOHQZ0rx1xAnnDl3CjLnhkg8NXYK02ZxTI0mS\n",
       "mmCokSRJTTDUSJKkJhhqJElSEwYNNUnOSvJskgvH2pckuTfJY0muS7L/2Podk1yY5L4kjyS5Isle\n",
       "s1u9JEmaSwYLNUneAJwCfAOokfb3A2cApwEHA2uBq5PsMrL5UuAY4FjgMGBXYFkSR54kSZqnBgkB\n",
       "SXYDPgO8G3hopD3A6cBHq+ryqrodOBF4CXDcyLYnA2dW1bVVdRtwAvBa4M2zeiCSJGnOGGpk45PA\n",
       "F6rqBmD0HjL7AguBq6YaquoJ4EbgkL7pIGCHsT6rgDtG+kiSpHlm1m++l+QU4FX0Iy+MnHoCFvU/\n",
       "14xtthb4ZyN9nqmqB8b6rKELRNI2o/U70krSbJrVUJPkx4DfAQ6tqmemmnn+aM2GbPFf/itX3PDc\n",
       "+90X7s3ui/bZ0l1J067Vu9J6R1pJs222R2reCLwUuL2bPgPAAuCwJO8BfqJvWwisGtluIbC6f78a\n",
       "WJBkz7HRmkV0p6leYJ8Djpie6iVJ0pw10ZyaJIcneckG1u2S5PAJP+9yuuByQP86EPg6cGn//i66\n",
       "0LJ4ZP87AYcCN/VNy4Gnxvq8AthvpI8kSZpnJh2puR54A3DretbtB1xHN+KyUVW1Dlg32pbkMeCh\n",
       "qvq7fnkpcHaSO+lCzjnAw8Bnp/aR5GLg/CRrgQeBC4AVwDUTHo8kSWrMdJx+2hF4diu2L0bmy1TV\n",
       "+Ul2Bi4C9gBuARZX1aMj25wOPA1cBuxMF2aOryonXUqSNE9tMNQk2ZfuEuupyS8Hj90AD7pA8UvA\n",
       "/93SAqrqyPW0nQect5FtngTe278kSZI2OlJzIvBbI8sXbqDf03R3/5UkSRrMxkLNp+jm0gB8BTiV\n",
       "7gZ3o34AfHs994yRJEmaVRsMNVW1ElgJkOQoYHlVPTw7ZUmSJG2eiSYKV9X1M1yHtEHedVeSNImJ\n",
       "Qk2SHYGzgF8AXkl3xdOoqqpNXtItbYlW77gL3nVXkqbTpJd0n083p+ZLwJ/RzaUZ5b+kJUnSoCYN\n",
       "Ne8AllTVh2eyGEmSpC010WMSgF3wEQSSJGkOmzTULAMmfb6TJEnSrJv09NPvA5f0V6H8Bd3zlp6n\n",
       "qr4znYVJkiRtjklDzc39z9/uX+OKCR5oKUmSNFMmDTUnz2gVkiRJW2nSm+99aobrkCRJ2iqTThSW\n",
       "JEma0ya9o/Afs+Eb7IXujsKeopIkSYOZdE7NkTw/1AT4Ybr716wD/nGa65IkSdosk86p2Wd97UkO\n",
       "B/4AOH4aa5IkSdpsWzWnpqpuBD5Gdx8bSZKkwUzHROG7gddPw34kSZK22FaFmiQ7ACcCq6anHEmS\n",
       "pC0z6dVP1/HCq592BF4N7An8yjTXJUmStFkmvfopYz8BHga+CHyuqq6fzqIkSZI216RXP71phuuQ\n",
       "JEnaKt5RWJIkNWHiUJPktUm+mOT+JM8kuS/JF5K8ZiYLlCRJmsSkE4UPBm4AHgeuBNYAi4CfAY5O\n",
       "ckRVfX3GqpQkSdqESScKfxT4FvBTVfXwVGOSlwDX9OvfMv3lSZIkTWbS009vAH53NNAA9Mv/FXjj\n",
       "dBcmSZK0OSYNNRt6Qvek6yVJkmbUpKHma8BZSXYdbUyyC/B+4JbpLkySJGlzTDqn5my6icIrkywD\n",
       "vg+8HDga+CHgTTNSnSRJ0oQmvfnerUl+Evgt4K3AHsCDwFeAD1XVN2euREmSpE3bYKhJsh3w08DK\n",
       "qvpmVX0DeMdYn9cA+yT5VlU5r0aSJA1mY3NqfhH4HN0znjbkEeBS4BemsyhJkqTNtbFQcwLwx1W1\n",
       "ckMdqupu4GLgP05zXZIkSZtlY6Hm9cCXJ9jHtcDB01OOJEnSltlYqHkJ8NAE+3io7ytJkjSYjYWa\n",
       "+4G9J9jHj/R9J5Lk1CQrkqzrXzclOXqsz5Ik9yZ5LMl1SfYfW79jkgv7h2o+kuSKJHtNWoMkSWrP\n",
       "xkLNV4ETJ9jHScBfbcZnfhd4H/A64CC6y8L/PMkBAEneD5wBnEZ3WmstcHV/o78pS4FjgGOBw4Bd\n",
       "gWX9FVuSJGke2lgI+BjwU0mWJnnR+MokL0qyFPipvu9EqurKqvpyVX2nqv6hqs6hu8LqXycJcDrw\n",
       "0aq6vKpupwtWLwGO6z93N+Bk4MyquraqbqOb1Pxa4M2T1iFJktqywfvUVNXNSX4TuAA4LslVwD39\n",
       "6r2BxcCewBlVdfOWfHiSBcA7gZ2AG4F9gYXAVSN1PJHkRuAQ4JN0ozs7jPVZleSOvs9z7ZIkaf7Y\n",
       "6B2Fq2ppkr+he77TMXThA+Bx4Hq6J3f/78390P6mfTcDO/b7eldV/X2SQ/oua8Y2WQv8s/79IuCZ\n",
       "qnpgrM8aukAkSZLmoU0+JqGqbgRu7EdVXto3P1BVT2/F595Jd7poN7qRms8lOXJTpWzph61cccNz\n",
       "73dfuDe7L9pnS3clSZLmqEkfaElVPcMLR1C2SFU9BXynX7wtycHAqcAH+7aFwKqRTRYCq/v3q4EF\n",
       "SfYcG61ZRHcK6wX2OeCI6ShbkiTNYXPlaqEFwHb9HYpX083XASDJTsChwE1903LgqbE+rwD2G+kj\n",
       "SZLmmYlHaqZLkt8FltGNxExd1XQE3dO/obtc++wkdwJ3AVNXR30WoKrWJbkYOD/JWrqnhV8ArACu\n",
       "mcVDkSRJc8ishxq6U0mfoTtdtI4ujLy1qq4GqKrzk+wMXATsAdwCLK6qR0f2cTrwNHAZsDNdmDne\n",
       "J4VLkjR/zXqoqap3T9DnPOC8jax/Enhv/5IkSZozc2okSZK2iqFGkiQ1wVAjSZKaYKiRJElNMNRI\n",
       "kqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiSpCYYaiRJUhO2\n",
       "H7oASdLclKSGrkHaHIYaSdJ6HXHCuUOXMGNuuORDQ5egGeDpJ0mS1ARDjSRJaoKhRpIkNcFQI0mS\n",
       "mmCokSRJTTDUSJKkJhhqJElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKaYKiRJElNMNRI\n",
       "kqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkpow66EmyVlJ/jrJuiRrk1yZ5MfX\n",
       "029JknuTPJbkuiT7j63fMcmFSe5L8kiSK5LsNXtHIkmS5pIhRmqOAD4BvBE4CngauCbJHlMdkrwf\n",
       "OAM4DTgYWAtcnWSXkf0sBY4BjgUOA3YFliVx9EmSpHlo+9n+wKp66+hykhOAdcAhwF8kCXA68NGq\n",
       "urzvcyJdsDkO+GSS3YCTgZOq6tqR/dwDvBm4apYOR5IkzRFzYVRjV7o6HuqX9wUWMhJMquoJ4Ea6\n",
       "4ANwELDDWJ9VwB0jfSRJ0jwyF0LNx4HbgJv75UX9zzVj/daOrFsEPFNVD4z1WUMXiCRJ0jwz66ef\n",
       "RiW5gG5k5dCqqgk2maSPJEmahwYLNUk+BrwLOLKqVo6sWt3/XAisGmlfOLJuNbAgyZ5jozWL6E5T\n",
       "Pc/KFTc89373hXuz+6J9trZ8SZI0xwwSapJ8HHgnXaD59tjqu+lCy2Jged9/J+BQ4My+z3Lgqb7P\n",
       "pX2fVwD7ATeNf94+Bxwx/QchSZLmlFkPNUkuAo4Hfg5Yl2RqnszDVfVoVVWSpcDZSe4E7gLOAR4G\n",
       "PgtQVeuSXAycn2Qt8CBwAbACuGZ2j0iSJM0FQ4zU/Crd3Jhrx9qXAB8EqKrzk+wMXATsAdwCLK6q\n",
       "R0f6n053j5vLgJ3pwszxE87NkSRJjRniPjUTXXFVVecB521k/ZPAe/uXJEma5+bCJd2SJElbzVAj\n",
       "SZKaYKiRJElNMNRIkqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w\n",
       "1EiSpCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElS\n",
       "Eww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKaYKiRJElNMNRIkqQmGGokSVITDDWSJKkJhhpJ\n",
       "ktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiSpCYYaiRJUhNmPdQkOTzJlUlWJXk2yYnr6bMk\n",
       "yb1JHktyXZL9x9bvmOTCJPcleSTJFUn2mr2jkCRJc80QIzUvBr4B/AbwOFCjK5O8HzgDOA04GFgL\n",
       "XJ1kl5FuS4FjgGOBw4BdgWVJHHmSJGmemvUQUFVfqqpzquqLwLOj65IEOB34aFVdXlW3AycCLwGO\n",
       "6/vsBpwMnFlV11bVbcAJwGuBN8/ioUiSpDlkro1s7AssBK6aaqiqJ4AbgUP6poOAHcb6rALuGOkj\n",
       "SZLmmbkWahb1P9eMta8dWbcIeKaqHhjrs4YuEEmSpHloroWajalNd5EkSfPV9kMXMGZ1/3MhsGqk\n",
       "feHIutXAgiR7jo3WLKI7TfUCK1fc8Nz73Rfuze6L9pmueiVJ0hwx10LN3XShZTGwHCDJTsChwJl9\n",
       "n+XAU32fS/s+rwD2A25a3073OeCIGS1akiQNb9ZDTZIXAz/aL24H7J3kQOCBqvpukqXA2UnuBO4C\n",
       "zgEeBj4LUFXrklwMnJ9kLfAgcAGwArhmdo9GkiTNFUOM1BwMfKV/X8B5/etTwMlVdX6SnYGLgD2A\n",
       "W4DFVfXoyD5OB54GLgN2pgszx1eV824kSZqnZj3UVNX1bGKCclVNBZ0NrX8SeG//kiRJ2qaufpIk\n",
       "SdogQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiSpCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKh\n",
       "RpIkNcFQI0mSmmCokSRJTTDUSJKkJhhqJElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ1wVAjSZKa\n",
       "YKiRJElNMNRIkqQmGGokSVITDDWSJKkJhhpJktQEQ40kSWqCoUaSJDXBUCNJkppgqJEkSU0w1EiS\n",
       "pCYYaiRJUhMMNZIkqQmGGkmS1ARDjSRJaoKhRpIkNcFQI0mSmmCokSRJTdimQ02SX0tyd5LHk3w9\n",
       "yaFD1yRJkoaxzYaaJD8PLAU+DBwI3AR8KcmPDFqYJEkaxDYbaoAzgD+uqour6u+r6r3A94FfHbgu\n",
       "SZI0gG0y1CR5EfB64KqxVVcBh8x+RZIkaWjbZKgBXgosANaMta8FFs1+OZIkaWjbD13AbFhx1SXr\n",
       "hq5hJjz+yEM7ATsOXYckSXNBqmroGjZbf/rpUeDYqvriSPtFwP5VdeRI27Z3gJIkaYOqKutr3yZH\n",
       "aqrqySTLgcXAF0dWvQX4wljf9R64JElqyzYZanoXAJckuZXucu5foZtP8weDViVJkgaxzYaaqvp8\n",
       "kj2Bc4CXA98Ejq6q7w5bmSRJGsI2OadGkiRp3LZ6SfdEWn2MQpLDk1yZZFWSZ5OcOHRN0ynJWUn+\n",
       "Osm6JGv7Y/3xoeuaDklOTbKiP7Z1SW5KcvTQdc2U/nf5bJILh65lOiRZ0h/P6Ot7Q9c1nZK8PMmn\n",
       "+//3Hk9ye5LDh65rayVZuZ7f3bNJlg1d23RIsn2SjyT5Tv97+06SDyVZMHRts6nZUNP4YxReDHwD\n",
       "+A3gcaC14bYjgE8AbwSOAp4Grkmyx6BVTY/vAu8DXgccBHwF+PMkBwxa1QxI8gbgFLo/qy39Gb2T\n",
       "bv7e1Os1w5YzfZLsDnyV7vd1NLAfcBrdPcC2dQfx/N/b6+mO87Ihi5pGZwPvAX4d+DG674dfA84a\n",
       "sqjZ1uzppyRfA/62qt4z0vZt4E+r6uzhKpteSR4GTq2qPxm6lpmS5MXAOuBnq+ovhq5nuiV5APgv\n",
       "VfWHQ9cyXZLsBiwHfglYAnyzf5TJNi3JEuDtVdVMkBmV5CPAYVV12NC1zLQkHwB+E3h5Vf1g6Hq2\n",
       "VpL/CdxfVe8eafs0sEdVvW24ymZXkyM1PkahObvS/Vl9aOhCplOSBUmOBXYCbhy6nmn2SeALVXUD\n",
       "0NptFV6V5N5+eP/SJPsOXdA0+jng1iSXJVmT5LYkpw5d1HRLErrA/ZkWAk3vS8BRSX4MIMn+wJHA\n",
       "/xq0qlm2zV79tAk+RqEtHwduA24eupDpkOQ1dMeyI93pw3dV1d8PW9X0SXIK8CrguL6ppeHgW4AT\n",
       "6U5BLaS7+vKmJD9eVQ8OWtn0eBXdKYsLgI/QnSa9MAlVddGglU2vtwD7AM2MjlbVf0/yCuCOJE/T\n",
       "fb9/uKrm1W1OWg01akSSC+hG1w6tds6V3gm8FtgNeCfwuSRHVtXXhy1r6/X/Svwdut/XM1PNNDJa\n",
       "U1V/ObL4rSQ3A3fTBZ2PDVPVtNoOuLWqPtAvr0jyo8CpQEuh5hS64/zm0IVMlyTvBd4NHAvcThdI\n",
       "P55kZVX90aDFzaJWQ839wDN0/5IatRD4/uyXoy2R5GPAu4Ajq2rlwOVMm6p6CvhOv3hbkoPpvjTe\n",
       "veGtthlvpBspvb0b4Qe6UdPDkrwHeHF//E2oqseS3A78i6FrmSbfA/5urO1O4JUD1DIjkrwMeBvd\n",
       "iFRLPkA3MvP5fvn2JHvTTRSeN6GmyTk1VfUk3STFxWOr3kJ3FZTmuCQfB34eOKqqvj10PTNsAe38\n",
       "v3g58BPAAf3rQODrwKXAgS0FGoAkOwH/knb+sfRVuiueRr0aWDn7pcyYk4An6P5MtiTAs2Ntz9LI\n",
       "KOmkWh2pgYYfo9BfDfSj/eJ2wN5JDgQeaOGOyv2DSY+nm7S4LsnUPKiHq+rR4Srbekl+F1gGrAJe\n",
       "Qjfv5AjgrUPWNV2qah3dlWrPSfIY8FBVjY8AbHOS/DfgSrpL818GnAvsDHx6yLqm0cfo5gidDXye\n",
       "7hTGr9PIZcH9BOFfBj5XVY8NXc80+3PgvyS5m2607XXAf6adP5sTafaSboAkv0p3T5Cpxyj856r6\n",
       "q2Gr2npJ3kR3fxPoJmFOJfFPVdXJgxQ1jZI8y/OPa8qSqvrgACVNmyR/THdFwiK6L/8VwO9V1dWD\n",
       "FjaDklxHO5d0XwocTneK7T66Cd/nVtWdgxY2jfqbQX6E7l4n9wCfqKpPDFvV9EhyJHAN8JMtzGEb\n",
       "1f9j9zzg7fzTVItLgQ/2Zy/mhaZDjSRJmj9aOY8vSZLmOUONJElqgqFGkiQ1wVAjSZKaYKiRJElN\n",
       "MNRIkqQmGGokSVITDDXSNijJsxO87t7Kzzip38+0PPdnZH9Tr0eS3J3kz5K8cyv2e2CSJUn2mI46\n",
       "R/a7Mskl07CfN/XHe9QEfZ9N8ttb+5nSfNXyYxKklr1h5H3onrn0t8CSkfYfbOVnLOs/Z/VW7mfc\n",
       "O+geE7EjsDfw08ClSf4T8DNV9cRm7u9A4LeAPwEemsY6q3/NNu+IKm0hQ420DaqqW0eXk/wAuH+8\n",
       "fazPgn7bZyb8jPvpnng/3f62qqaeUv6/gc8k+QLwBeB8YEsfpzCvHtwn6YU8/SQ1qj+V8eEkUw+5\n",
       "+wHwE0l2TPKxJN9M8nCS7ye5MsmPjW3/gtNPU6dkkhyb5I7+FNJfJ/k3W1NrVf0ZcAVwSpKdRz7v\n",
       "vCR/k2RdkvuSXJvkJ0drBP6oX7xr5NTWK/v1pyW5OckDSR7q3x+9NbWO2lR9Y3ZP8qkkD/b9P5Pk\n",
       "hyf4jAP638+DSR5L8ldJDh3rc3CSq5Pc3/f5P/2DYaV5xVAjte0k4N8BZwBH0z3kbke6J4R/hO7U\n",
       "z68AOwE3J1m4if0VcBjd038/APw8sABYlmS3raz1S31t/2qkbS9gKfA24ERgLXBjkp/o1y8DPty/\n",
       "fwfd6bJGyvthAAAETElEQVTRU2b70IWedwLvAr7e1/pvt7LWSesbtRR4BjiW7r/d24A/3djOk7we\n",
       "uAnYne7p0m8HHgCu6deRZBfgy8BTfQ1vBT5I93uR5hVPP0ntW1xV4/NrfnnqTZLtgKvpgsAv0H35\n",
       "bkjoAtEBVbWu33418Nd0oenSrajz//Y/F001VNVonQuAq4DX9fWfXlX3J5k6lTV6Wmtq+zNHtt8O\n",
       "uA54NfCrdEFgq2yqvrHu36qqX+rfX5XkQbpTb0dV1Vc28BG/B6wEjqqqp/vP+TLwLeBc4D8A+9GF\n",
       "nvdV1bf67W4EPr2Vhydtcxypkdr2l+sJNCR5V5KvJXkIeBp4BNiF7gt/U26eCjS9qS/SH9nKWqfm\n",
       "xDw3UTbJm5Ncl+R+upGIJ/saJ6mTJAclWdYHr6nt3zLp9hPsf3Pq+/zY8p8Cz/L8Sd+j+94ZOJxu\n",
       "rhFJtk+yPd3f29f26wDuAv4R+GSSX0yytb8HaZtlqJHa9v3xhiQ/A3wOuJ1uZOZfAwcD99GdhtqY\n",
       "Ah58XsM/haZNbbspU1/G3+/rfD3wv4D/B5wM/GRf54pJPqv/cr+WbhTjNOCN/fZ/OQ21bkl9a0YX\n",
       "qupJuqu19trAR/ww3Smk36ILS6OvU+mOiz5gHgl8D/jvwD39fKljtuLwpG2Sp5+ktq3v8uBjgbuq\n",
       "6uSphiQ7AHvOWlXr99PA48DyfvntdF/gx4xesdVPrp3k0u23ArsC76qq741s/+Jpqndz61s0upDk\n",
       "RcAewL0b2P8/0o3kfILucvUNqqoVwDv6U2wHA2cBn09yQFXdPtnhSNs+R2qk+eeH6CasjjqBAf8+\n",
       "SPJ24GeAPxi5T80P0X2pj/Y7ihee5vrBSP9RU8tPj2z/amCrrtQa2/8k9U1519jyO+n+m9+8vs5V\n",
       "9SjdJe8HArdV1d+Mv9azzbNV9TW60Z3t6ObbSPOGIzVSGzbnHi1fAn42yQXAX9BdbXQa3cjApvYz\n",
       "HfeCeV2SlwEvAl4J/Hu6K5euohthGK3zN4BPJfkU3TyVc+hGNkbrmBqJODXJn9DNbVlBN/n5aeBP\n",
       "+mN9Od3NCe9hsgAXYO8k71jPups2o74p+yf5I+Cyvu/vANdV1XUbqeEMukm/X05yMd1k7pcCrwe2\n",
       "q6qzkvx74D/R3YBxJfBiunv9/D82EJikVhlqpDZszl1o/5BuNOFk4D3ArXSjJJevZz+bWt4cU9t+\n",
       "of/5BN0l0MuBn6+qLz6vc9VVSd5L98X+duCbdCNK547WUVXfSLKE7ov9FLpAsW9V/V2SX6S7vPkK\n",
       "4B+A99Nd4n7EhPUeSncJ+3j7O6vqzyapb2Sb3wB+lm4+0wLgSjZxo8Gqui3JwcBvA78P7EY392k5\n",
       "8Ad9t28Dj/Wf+3LgYbrf6VtGT7tJ80GqvCO3JEna9jmnRpIkNcFQI0mSmmCokSRJTTDUSJKkJhhq\n",
       "JElSEww1kiSpCYYaSZLUBEONJElqgqFGkiQ14f8DJQQAkE+OKHsAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a8489d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Remove the plot frame lines. They are unnecessary chartjunk.  \n",
    "ax = plt.subplot(111)  \n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "\n",
    "# Ensure that the axis ticks only show up on the bottom and left of the plot.  \n",
    "# Ticks on the right and top of the plot are generally unnecessary chartjunk.  \n",
    "ax.get_xaxis().tick_bottom()  \n",
    "ax.get_yaxis().tick_left()  \n",
    "\n",
    "# Make sure your axis ticks are large enough to be easily read.  \n",
    "# You don't want your viewers squinting to read your plot.  \n",
    "plt.xticks(unique_train, fontsize=14)  \n",
    "plt.yticks(fontsize=14)  \n",
    "\n",
    "# Along the same vein, make sure your axis labels are large  \n",
    "# enough to be easily read as well. Make them slightly larger  \n",
    "# than your axis tick labels so they stand out.  \n",
    "plt.xlabel(\"Train Data Lables\", fontsize=16)  \n",
    "plt.ylabel(\"Count\", fontsize=16)\n",
    "\n",
    "ax.hist(labels[:4000], bins=range(10), cumulative=False, color=\"#3F5D7D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 114.,  172.,  101.,   95.,  127.,   85.,   54.,  141.,  111.]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " <a list of 9 Patch objects>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGKCAYAAAAbo9ubAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu4HXV97/H3h4BAuR9aE+ol4CnKwQuplkelQMRq2npq\n",
       "a61V6pETpMdaBQGRlopiE0FRTotYxLaeWlGqeKlFKQpFlEAVLYI2WASxhSABSQBp5CqXfM8fMxsX\n",
       "qzvJDll7rTUr79fzrGet+c1vZn2HHbI/+c1vZlJVSJIkddkWoy5AkiRpUxloJElS5xloJElS5xlo\n",
       "JElS5xloJElS5xloJElS5xloJElS5w010CQ5MMm5SVYmWZtkcd/6HZN8MMlNSe5Ncm2So/v6bJ3k\n",
       "9CS3Jbk7yeeTPGGYxyFJksbLsEdotgOuAo4C7gP67+p3GvCrwGuAvYB3Ae9J8pq+Pi8HDgYOAHYE\n",
       "zkviaJMkSZupjOpOwUnuAg6vqo/1tH0H+PuqWtrTtgy4qqqOTLITsBo4tKrObtc/EbgR+PWqunCY\n",
       "xyBJksbDuI1qnA/8ZhtSSLIfsAC4oF3/HGAr4JHgUlUrgWuA/YZbqiRJGhdbjrqAPscBHwN+kOSh\n",
       "tu2Iqvpi+3ke8HBV3dG33Spg7pBqlCRJY2bcAs2fAc8FXkpzGmkh8OdJbqyqfxppZZIkaWyNTaBJ\n",
       "sh3NZOHfrqovtM3/lmQBcCzwT8CtwJwku/aN0swDLp1mnwUs7WlaVlXLZqN+SZI0OmMTaIC0r7V9\n",
       "7WvbdoArgQeBRUDvpOC9gMum22lVLZmFWiVJ0hgZaqBpR2H2bBe3AOa3IzB3VNVNSb5Mc5n23cAP\n",
       "aE45HQL8EUBVrUnyYeCUJKuBHwGnAsuBi4Z5LJIkaXwM9bLtJC8AvtIuFj8deTmzqg5L8nPAyTT3\n",
       "otkVWAH8TVWd2rOPx9HMtXk1sC1NkHljVd08zfdVVaW/XZIkTZaR3YdmGAw0kiRtHsbtPjSSJEkb\n",
       "zUAjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6b5ye\n",
       "tq2NlGRyn1vR8tEVkqSZMNB03MJDThh1CbPmkrNOHHUJkqSO8JSTJEnqPAONJEnqPAONJEnqPAON\n",
       "JEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnqPAONJEnq\n",
       "PAONJEnqvKEGmiQHJjk3ycoka5MsnqbPU5P8Q5I7k9yT5Moke/Ws3zrJ6UluS3J3ks8necIwj0OS\n",
       "JI2XYY/QbAdcBRwF3AdU78okewBfA/4DOAh4OvA24O6ebqcBLwcOBg4AdgTOS+JokyRJm6kth/ll\n",
       "VXU+cD5AkjOn6fIu4IKq+qOethVTH5LsBBwGHFpVX27bDgFuBF4EXDgrhUuSpLE2NqMa7QjLbwDX\n",
       "JLkgyeoklyd5ZU+35wBb0RNcqmolcA2w31ALliRJY2NsAg3weGB74HjgApoRl7OBjyd5SdtnHvBw\n",
       "Vd3Rt+0qYO6wCpUkSeNlqKecNmAqXH2uqk5rP1+V5JeAI4AvjqYsSZI07sYp0NwOPAR8t6/9WuBV\n",
       "7edbgTlJdu0bpZkHXDrdTpMs6VlcVlXLBlKtJEkaG2MTaKrqgSTfBPbqW/VUfjox+ErgQWARzeko\n",
       "kjyx3eaydex3ySyUK0mSxshQA02S7YA928UtgPlJFgB3VNVNwCnAp5P8M3AxzaXbrwJ+C6Cq1iT5\n",
       "MHBKktXAj4BTgeXARcM8FkmSND6GPSl4X+Bb7WsbYGn7eSlAVX0e+APgWJr71RwOHNJe7j3laOAc\n",
       "4FPAV4EfAy+tqkfd00aSJG0+hn0fmmVsIERV1UeBj65n/QPAke1LkiRprC7bliRJekwMNJIkqfMM\n",
       "NJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIk\n",
       "qfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMM\n",
       "NJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfOGGmiSHJjk3CQrk6xNsng9ff+67fOW\n",
       "vvatk5ye5LYkdyf5fJInzH71kiRpXA17hGY74CrgKOA+oKbrlOQVwL7ALdP0OQ14OXAwcACwI3Be\n",
       "EkebJEnaTG05zC+rqvOB8wGSnDldnyTzaULLrwAX9K3bCTgMOLSqvty2HQLcCLwIuHC2apckSeNr\n",
       "rEY1kmwJnA2cWFXfm6bLc4Ct6AkuVbUSuAbYbyhFSpKksTPUEZoZWAqsrqq/Xsf6ecDDVXVHX/sq\n",
       "YO6sViZJmghJpp3uMEmqKqOuYdjGJtAkeQGwGFjQv2oT97ukZ3FZVS3blP1Jkrpv4SEnjLqEWXPJ\n",
       "WSeOuoSRGJtAAywEdgN+mDySYeYA701yVFU9GbgVmJNk175RmnnApdPttKqWzF7JkiRpHIzTHJoP\n",
       "As8E9mlfC2iucjqVZoIwwJXAg8CiqY2SPBHYC7hsmMVKkqTxMdQRmiTbAXu2i1sA85MsAO6oqpuA\n",
       "2/r6PwjcWlXfB6iqNUk+DJySZDXwI5rAsxy4aEiHIUmSxsywR2j2Bb7VvrahmQT8rfZ9po4GzgE+\n",
       "BXwV+DHw0qqa+ElekiRpesO+D80yNiJEVdUe07Q9ABzZviRJksZqDo0kSdJjYqCRJEmdZ6CRJEmd\n",
       "Z6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CR\n",
       "JEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdt+WoC5A0eZLUqGuYbVWVUdcg\n",
       "6acMNJJmxcJDThh1CbPmkrNOHHUJkvp4ykmSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHXeUANN\n",
       "kgOTnJtkZZK1SRb3rNsyyXuTLE9yd5Jbknw8yZP69rF1ktOT3Nb2+3ySJwzzOCRJ0ngZ9gjNdsBV\n",
       "wFHAfUD1rftF4KT2/beAJwEXJJnT0+804OXAwcABwI7AeUkcbZIkaTM11PvQVNX5wPkASc7sW7cG\n",
       "WNTbluT1wNXAXsDVSXYCDgMOraovt30OAW4EXgRcOMuHIEmSxtC4j2rs1L7f2b4/B9iKnuBSVSuB\n",
       "a4D9hluaJEkaF2MbaJI8Dvhz4NyquqVtngc8XFV39HVfBcwdZn2SJGl8jOWjD5JsCfwdzfyY3xhx\n",
       "OZIkacyNXaBpw8zZwNOBF1TVnT2rbwXmJNm1b5RmHnDpOva3pGdxWVUtG2zFkiRp1MYq0CTZCvgk\n",
       "sDdNmFnd1+VK4EGaycNnt9s8kWbS8GXT7bOqlsxWvZIkaTwMNdAk2Q7Ys13cApifZAFwB3AL8Bng\n",
       "l4CXNt0zr+37n1V1f1WtSfJh4JQkq4EfAacCy4GLhngokiRpjAx7UvC+wLfa1zbA0vbzUuCJwG8C\n",
       "u9GMxNzS83plzz6OBs4BPgV8Ffgx8NKq6r2njSRJ2owM+z40y1h/iNpgwKqqB4Aj25ckSdL4XrYt\n",
       "SZI0UwYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeWN1Y73ZsNU2P3PFqGuQJEmza+IDzd4H/M5zRl3D\n",
       "bLj9B9dwy3VXjroMSZLGwsQHml1222PUJcyKe/6z/6kQkiRtvpxDI0mSOs9AI0mSOs9AI0mSOm/i\n",
       "59BIkrS5STKRD2yuqqxrnYFGkqQJs/CQE0ZdwtB5ykmSJHWegUaSJHWegUaSJHWegUaSJHWegUaS\n",
       "JHWegUaSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHWegUaSJHXeUANNkgOT\n",
       "nJtkZZK1SRZP02dJkpuT3Jvk4iR7963fOsnpSW5LcneSzyd5wvCOQpIkjZthj9BsB1wFHAXcB1Tv\n",
       "yiTHAccARwD7AquBLyXZvqfbacDLgYOBA4AdgfOSONokSdJmakYhoB1Z2WEd67ZPcuBM9lNV51fV\n",
       "26vqs8Davv0EOBo4uarOqaqrgcXADsCr2z47AYcBx1bVl6vq28AhwLOAF82kBkmSNHlmOqqxDPgf\n",
       "61i3F3DxAGrZA5gLXDjVUFX3A5cC+7VNzwG26uuzErimp48kSdrMbDmAfWxN32jLYzSvfV/V174a\n",
       "+PmePg9X1R19fVbRhCFNmCS14V7dVVUZdQ2SNAnWGWiS7EEzajL1F+6+fXNZALYFfh/4weyU94iJ\n",
       "/qWmdVt4yAmjLmHWXHLWiaMuQZImxvpGaBYD7+hZPn0d/R6imcS7qW5t3+cCK3va5/asuxWYk2TX\n",
       "vlGaeTSnpv6LFcsveeTzznPns/O83QdQqiRJGifrCzRn0sydAfgKcDjNXJVePwGum+YU0GNxA01g\n",
       "WQRcCZBkG2B/4Ni2z5XAg22fs9s+T6SZx3PZdDvdfZ+FAyhNkiSNs3UGmqpaAawASPJC4MqqumtT\n",
       "vizJdsCe7eIWwPwkC4A7quqmJKcBxye5Fvg+8HbgLuATbU1rknwYOCXJauBHwKnAcuCiTalNkiR1\n",
       "14wmBVfVsgF93740oz3QzItZ2r7OBA6rqlOSbAucAewCfANYVFX39OzjaJrTXJ+imcNzEfCaqnKe\n",
       "jSRJm6kZBZokWwNvBX4PeDLNlU29qqrmbGg/bTBa76XiVTUVcta1/gHgyPYlSZI048u2T6GZQ3M+\n",
       "8A80c2d6OToiSZJGZqaB5hXAkqo6aTaLkSRJeixmeqfg7VnHVUSSJEmjNtNAcx4wo+c1SZIkDdtM\n",
       "Tzn9BXBWexv6L9BcLv0oVXX9IAuTNgeT/mgHSRqWmQaar7fvf9q++hWwwaucJD3apD7awcc6SBq2\n",
       "mQaaw2a1CkmSpE0w0xvrnTnLdUiSJD1mM50ULEmSNLZmeqfgj7Dum+eF5k7BnpaSJEkjMdM5NAfx\n",
       "6EAT4L/R3J9mDfCfA65LkiRpxmY6h2b36dqTHAj8FfCaAdYkSZK0UTZpDk1VXQq8j+Y+NZIkSSMx\n",
       "iEnBNwDPHsB+JEmSHpNNCjRJtgIWAysHU44kSdLGm+lVThfzX69y2hp4KrAr8IcDrkuSJGnGZnqV\n",
       "U/reAe4CPgt8sqqWDbIoSZKkjTHTq5xeMMt1SJIkPWbeKViSJHXejANNkmcl+WyS25M8nOS2JJ9J\n",
       "8szZLFCSJGlDZjopeF/gEuA+4FxgFTAPeCnwkiQLq+qKWatSkiRpPWY6Kfhk4N+AX6mqu6Yak+wA\n",
       "XNSuf/Hgy5MkSdqwmZ5yeh7wnt4wA9Auvxd4/qALkyRJmqmZjtCs60nbM10vSRMlyUT/vVdV2XAv\n",
       "aXzMNND8C/DWJBdV1Y+nGpNsDxwHfGM2ipOkcbXwkBNGXcKsueSsE0ddgrTRZhpojqeZFLwiyXnA\n",
       "D4HdgJcAPwO8YFaqkyRJmoEZzaGpqsuB5wJfAX4NOAb41Xb5ue36gUiyZZJ3J7k+yX3t+4lJ5vT1\n",
       "W5Lk5iT3Jrk4yd6DqkGSJHXLOkdokmwB/E9gRVV9p6quAl7R1+eZwO5J/q2qBnU++Xjg9cD/Br4D\n",
       "7AOcCfwEOKn93uNoQtVi4DrgHcCXkjytqu4eUB2SJKkj1jdC87+AT9I8s2ld7gbOBn5vgDXtC5xb\n",
       "VV+oqh9U1T8C59GMEJEkwNHAyVV1TlVdTRNsdgBePcA6JElSR6wv0BwCfKSqVqyrQ1XdAHyYZjRl\n",
       "UM4HXpjkaQDtqaSDgC+06/cA5gIX9tRxP3ApsN8A65AkSR2xvkDzbOCfZrCPL9OMqgxEVX0Q+Dhw\n",
       "TZIHaG7od2ZV/VXbZV77vqpv09U96yRJ0mZkfVc57QDcOYN93Nn2HYgkRwKvBQ4GrgZ+EXh/khVV\n",
       "9bcb2Hyi7wshSZKmt75AczswH/jqBvbxpLbvoLwNOKmqPt0uX51kPvBW4G+BW9v2ucDKnu3m9qx7\n",
       "xIrllzzyeee589l53u4DLFWSJI2D9QWar9FMtv34BvZxKBsOPRsjwNq+trVtO8ANNMFlEXAlQJJt\n",
       "gP2BY/t3tvs+CwdYmiRJGkfrCzTvA76a5DTgj6vqgd6VSR4HnAL8Ck2YGJTPAX+S5AbguzSnnN4M\n",
       "fBSgqqqt6fgk1wLfB95OczXWJwZYhyRJ6oh1Bpqq+nqStwCnAq9OciFwY7t6Ps0Iya7AMVX19QHW\n",
       "9Gbgx8AZNKeRfgh8CHhnT22nJNm27bMLzaMXFlXVPQOsQ5IkdcR6H31QVacl+RbN85peDmzTrroP\n",
       "WEbzBO5/HmRBbSg5lmlOH/X1WwosHeR3S5Kkbtrgs5yq6lLg0vbRAz/bNt9RVQ/NamWSJEkzNNOH\n",
       "U1JVD/Nf7/0iSZI0cjN6OKUkSdI4M9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTO\n",
       "M9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BI\n",
       "kqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOG8tAk2S3JB9NsjrJ\n",
       "fUmuTnJgX58lSW5Ocm+Si5PsPap6JUnSaI1doEmyM/A1oICXAHsBRwCre/ocBxzTtu/brvtSku2H\n",
       "XrAkSRq5LUddwDT+GLi5qg7tabtx6kOSAEcDJ1fVOW3bYppQ82rgQ8MrVZIkjYOxG6EBXgZcnuRT\n",
       "SVYl+XaSw3vW7wHMBS6caqiq+4FLgf2GW6okSRoH4xhongK8Efh3YBHwfuA9PaFmXvu+qm+71T3r\n",
       "JEnSZmQcTzltAVxeVW9rl5cn2RM4HDhjA9vWrFYmSZLG0jgGmluA7/a1XQs8uf18a/s+F1jZ02du\n",
       "z7pHrFh+ySOfd547n53n7T6oOiVJ0pgYx0DzNZorm3o9FVjRfr6BJrgsAq4ESLINsD9wbP/Odt9n\n",
       "4WzVKUmSxsQ4zqF5H/C8JMcn+YUkvwu8ifZ0U1UVcBpwXJLfTvIM4EzgLuATI6pZkiSN0NiN0FTV\n",
       "FUleBrwbOIHmku23V9Vf9vQ5Jcm2NCFnF+AbwKKqumcUNUuSpNEau0ADUFVfBL64gT5LgaXDqUiS\n",
       "JI2zcTzlJEmStFEMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfPG8rJtSdJoJfHZeOoUA40k\n",
       "6b9YeMgJoy5h1lxy1omjLkGzwFNOkiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0\n",
       "kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp8ww0kiSp\n",
       "8ww0kiSp8ww0kiSp8ww0kiSp88Y60CR5a5K1SU7va1+S5OYk9ya5OMneo6pRkiSN3tgGmiTPA14H\n",
       "XAVUT/txwDHAEcC+wGrgS0m2H0WdkiRp9MYy0CTZCfg74LXAnT3tAY4GTq6qc6rqamAxsAPw6lHU\n",
       "KkmSRm8sAw3wIeAzVXUJkJ72PYC5wIVTDVV1P3ApsN9QK5QkSWNjy1EX0C/J64Cn8NMRl+pZPa99\n",
       "X9W32Wrg52e5NEmSNKbGKtAkeRrwLmD/qnp4qplHj9KsS03XuGL5JY983nnufHaet/smVilJksbN\n",
       "WAUa4PnAzwJXN9NlAJgDHJDk9cAz2ra5wMqe7eYCt063w933WTg7lUqSpLExbnNozqEJLfu0rwXA\n",
       "FcDZ7efv0wSXRVMbJNkG2B+4bNjFSpKk8TBWIzRVtQZY09uW5F7gzqr6brt8GnB8kmtpAs7bgbuA\n",
       "Twy5XEmSNCbGKtCsQ9EzP6aqTkmyLXAGsAvwDWBRVd0zovokSdKIjX2gqaqDpmlbCiwdQTmSJGkM\n",
       "jdscGkmSpI1moJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1n\n",
       "oJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEk\n",
       "SZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ1noJEkSZ03doEmyVuTfDPJmiSr\n",
       "k5yb5OnT9FuS5OYk9ya5OMneo6hXkiSN3tgFGmAh8AHg+cALgYeAi5LsMtUhyXHAMcARwL7AauBL\n",
       "SbYffrmSJGnUthx1Af2q6td6l5McAqwB9gO+kCTA0cDJVXVO22cxTah5NfCh4VYsSZJGbRxHaPrt\n",
       "SFPnne3yHsBc4MKpDlV1P3ApTeiRJEmbmS4EmvcD3wa+3i7Pa99X9fVb3bNOkiRtRsbulFOvJKfS\n",
       "jLrsX1U1g01m0keSJE2YsQ00Sd4HvBI4qKpW9Ky6tX2fC6zsaZ/bs+4RK5Zf8sjnnefOZ+d5uw+6\n",
       "VEmSNGJjGWiSvB/4XZowc13f6htogssi4Mq2/zbA/sCx/fvafZ+Fs1usJEkaubELNEnOAF4DvAxY\n",
       "k2RqXsxdVXVPVVWS04Djk1wLfB94O3AX8ImRFC1JkkZq7AIN8AaauTBf7mtfArwToKpOSbItcAaw\n",
       "C/ANYFFV3TPEOiVJ0pgYu0BTVTO68qqqlgJLZ7kcSZLUAV24bFuSJGm9DDSSJKnzDDSSJKnzDDSS\n",
       "JKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnz\n",
       "DDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSS\n",
       "JKnzDDSSJKnzDDSSJKnzDDSSJKnzOhtokrwxyQ1J7ktyRZL9R12TJEkajU4GmiSvAk4DTgIWAJcB\n",
       "5yd50kgLkyRJI9HJQAMcA3ykqj5cVd+rqiOBHwJvGHFdkiRpBDoXaJI8Dng2cGHfqguB/YZfkSRJ\n",
       "GrXOBRrgZ4E5wKq+9tXAvOGXI0mSRm3LURcw25ZfeNaaUdcwG+6/Z83WwDajrkOSpHGQqhp1DRul\n",
       "PeV0D3BwVX22p/0MYO+qOqinrVsHJ0mS1quqMl1750ZoquqBJFcCi4DP9qx6MfCZvr7THrQkSZos\n",
       "nQs0rVOBs5JcTnPJ9h/SzJ/5q5FWJUmSRqKTgaaqPp1kV+DtwG7Ad4CXVNVNo61MkiSNQufm0EiS\n",
       "JPXr4mXbMzKpj0ZIcmCSc5OsTLI2yeJR1zRISd6a5JtJ1iRZ3R7r00dd1yAkOTzJ8vbY1iS5LMlL\n",
       "Rl3XbGl/lmuTnD7qWgYhyZL2eHpft4y6rkFKsluSj7b/792X5OokB466rkFIsmKan9/aJOeNurZN\n",
       "lWTLJO9Ocn37c7s+yYlJ5oy6tmGayEAz4Y9G2A64CjgKuA+YtCG2hcAHgOcDLwQeAi5KsstIqxqM\n",
       "m4A/Bn4ReA7wFeBzSfYZaVWzIMnzgNfR/FmdpD+j19LM15t6PXO05QxOkp2Br9H8vF4C7AUcQXOP\n",
       "r0nwHB79s3s2zbF+apRFDcjxwOuBNwFPo/n98EbgraMsatgm8pRTkn8B/rWqXt/Tdh3w91V1/Ogq\n",
       "G6wkdwGHV9XHRl3LbEmyHbAG+K2q+sKo6xm0JHcAf1JV/2/UtQxKkp2AK4HfB5YA32kfT9JpSZYA\n",
       "v1NVExNieiV5N3BAVR0w6lqGIcnbgLcAu1XVT0Zdz6ZI8o/A7VX12p62jwK7VNVvjq6y4Zq4ERof\n",
       "jTBxdqT5c3rnqAsZpCRzkhxMc3PES0ddz4B9CPhMVV0CTNqtE56S5OZ2SP/sJHuMuqABehlweZJP\n",
       "JVmV5NtJDh91UbMhSWgC9991Pcy0zgdemORpAEn2Bg4CvjjSqoask1c5bYCPRpgs7we+DXx91IUM\n",
       "QpJn0hzL1jSnDF9ZVd8bbVWDk+R1wFOAV7dNkzQE/A1gMc1pp7k0V1leluTpVfWjkVY2GE+hOU1x\n",
       "KvBumlOjpyehqs4YaWWD92Jgd2AiRkar6oNJnghck+Qhmt/tJ1XVZnUrk0kMNJoQSU6lGVXbvybn\n",
       "3Oi1wLOAnYDfBT6Z5KCqumK0ZW269l+H76L5eT081cyEjNJU1QU9i/+W5OvADTQh532jqWqgtgAu\n",
       "r6q3tcvLk+wJHA5MWqB5Hc2xfmfUhQxCkiOB1wIHA1fThNH3J1lRVX870uKGaBIDze3AwzT/guo1\n",
       "F/jh8MvRY5HkfcArgYOqasWIyxmYqnoQuL5d/HaSfWl+Ybx23Vt1xvNpRkivbkb0gWa09IAkrwe2\n",
       "a49/IlTVvUmuBn5h1LUMyC3Ad/vargWePIJaZk2SxwO/STMaNSneRjMi8+l2+eok82kmBW82gWbi\n",
       "5tBU1QM0ExIX9a16Mc3VThpzSd4PvAp4YVVdN+p6ZtkcJuf/w3OAZwD7tK8FwBXA2cCCSQozAEm2\n",
       "Af4Hk/MPpa/RXNnU66nAiuGXMqsOBe6n+XM5KQKs7Wtby4SMjs7UJI7QwAQ/GqG96mfPdnELYH6S\n",
       "BcAdk3Cn5PYho6+hmaC4JsnUvKe7quqe0VW26ZK8BzgPWAnsQDPPZCHwa6Osa1Cqag3NFWmPSHIv\n",
       "cGdV9f/Lv3OS/BlwLs3l948HTgC2BT46yroG6H00c4KOBz5Nc9riTUzQpb/tZOD/A3yyqu4ddT0D\n",
       "9DngT5LcQDPK9ovAm5mcP5szMpGXbQMkeQPNPT+mHo3w5qr66mir2nRJXkBz/xJoJlxOJfAzq+qw\n",
       "kRQ1QEnW8ujjmrKkqt45gpIGJslHaK48mEfzi3858H+r6ksjLWwWJbmYybls+2zgQJrTarfRTO4+\n",
       "oaquHWlhA9Te6PHdNPcyuRH4QFV9YLRVDU6Sg4CLgOdOwry1Ke0/dJcCv8NPp1ecDbyzPWuxWZjY\n",
       "QCNJkjYfk3LuXpIkbcYMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNJIkqfMMNFLHJVk7\n",
       "g9f1G97TBr9nQZIlSXaZYf9lPd//UJIfJfl2kr9Isvcm1HFokoE++yrJC9o6XziAfZ2ZZIN37W6P\n",
       "Y22SiXpWkjQqk/roA2lz8ryez6F5ptK/Akt62n8ygO9ZALwD+Bhw5wy3WQ68vv28I/BM4DDgD5Mc\n",
       "VVV/+Riysix2AAAF3UlEQVTqOJTmGVgfeQzbDot3LJWGzEAjdVxVXd67nOQnwO397QO0MQ+8u6uv\n",
       "jouSnE5zW/bTk3xzkm5B32OzeiigNA485SRtBpLskeTjSVYnub899fOyvj5PTXJOklVJ7ktyY5JP\n",
       "J5mT5FDgb9uu3+85lbTRp0uq6iHgjcBDwCPPeEryC0nOSnJ9knuT/EeSDybZuafPMprnKf1yTw1f\n",
       "adf9XJK/TvK9JPck+UF7zD+/sTVOZyb19fXfL8k32/+WNyQ5Yobf8wdJlrfb3Zbkb/pP8yU5Ksk1\n",
       "bR0/ar/nZevap7Q5cIRGmnBJngT8C3ArcDTNgxUPBj6b5GVV9Y9t1y8Ad9A8nf524InAr9P8w+c8\n",
       "4CTg7cAraJ4YTrvPjVZVtyW5Avjlnubd2v0e09bxFOB44IvAfm2fNwB/19Y0dSrrx+37LjSn1t4G\n",
       "rGr3dyzwtSR7VdWmnnabSX1TdgQ+CbwH+Hfg94C/SHJXVa3zCcjtE9mPAd4PvIXmZ3AS8Iwk+1XV\n",
       "2iT/C/gzmocR/jPNE7/3aY9f2mwZaKTJt4RmTsfCqpqa+/KlNui8E/jHJD8L/Heap9Kf17Pt2e37\n",
       "7T0Ti/+1qjZ5kjFwE/DsqYWq+meaX9AAJPk68B/ApUkWVNW/VtU1Se4Ctug/pVZV1/HoEZ85NE/E\n",
       "vpEmmH1uU4qdSX093XcAXldVn26XL0zyBJoQMm2gSbI7TQBbUlUn9bRfB3wVeCnweeD5wFW9fYAL\n",
       "NuXYpEngKSdp8v0azSjCj5NsOfUCLgT2SbI9zYjD9cB7k/yfJHsOoa4Aax9ZSB6X5Pgk1ya5F3gA\n",
       "uLRd/dQZ7TB5Q3u65i7gQZowM+PtN7DvjanvIeCzfW2fAp68nlNgL6b5O/kTfT+ny4G7gQPafpcD\n",
       "C9qrxV6U5Gc28dCkiWCgkSbf44HFNL/gH+h5nUIzcrNrVRXNL9QrgJOB77VzRP5wFut6EvDDnuWT\n",
       "gT+luYrqJcC+wMvbddtsaGdJ3gScQRPUfrvdfuoKsA1uPwMbU99/VtXDfW2r2vcnrGP/j2/f/51H\n",
       "/5weALYDdgWoqo/RnHp7Ls3IzB1JPptk/mM4JmlieMpJmny304wkvHcd638IUFU30AQfkuwDHAF8\n",
       "MMmKqhroKY0kjwd+CfhET/PBwEer6t09/XbciN0eDFxUVX/Us/0em1rrY6xvlyRz+kLN3Pb95nVs\n",
       "c0f7/mKmvyx+aj1V9SHgQ0l2An4V+HOaEaDnTbOdtFkw0EiT7wKaeRffrar7Z7JBVS1P8hbg94Gn\n",
       "t/uYmlS7Sac4kmwFfJBmhPgvelZtS3Oqptd0N9D7Ce1oRZ9tgTUz2P6xmml90Nwn5xU0IWPKwcCN\n",
       "VXXLOra5kOYU3Pyq+vJMCqqqNcCnkzwP+IOZbCNNKgONNHn674HyDpp5F5cm+QDNvJJdgGcAe1TV\n",
       "7yd5Fs2VNZ+kmeg6h+YGdg8CX2n38932/fAkH2vXLa+qB9dTy45JntvWtAPNjfVeC+wJvLGqvt3T\n",
       "9wJgcZLvtDW8nCaI9bsaeGOSV9LM+/lxOyH4AuC4JG8Fvgm8EPid9dQ2nQOT/Le+tger6vMbUR/A\n",
       "XcAp7WTrqaucfoV2BGw6VXV9kvcCH0jyNJpRtftpTs29CPibqlqW5EM0V3Z9A1hNM3/nNcA/beSx\n",
       "ShPFQCNNnkfdpbaqbkrySzRXO70b+Dma0xff4adX3PyQJugcQ3Op8P3AVcBvTIWOdtRmCc1IwOto\n",
       "QsoewA/WU8ezaK40Kppf8tfTBKRXVtU1ff3f1O7zXe3yF2iCQP8NAt8LPA34G2B7YBlNeHknsDPw\n",
       "Zpo5LctoTsfM5Iqsqf9m75hm3d00l2HPtL6iGSl6Fc0I1DNpLm8/sqrOWsf3NgtVb0tyDXB4+yqa\n",
       "q8EuAq5ru32VJhQeAuwE3AKcRTO/R9pspZkLKEmS1F1e5SRJkjrPQCNJkjrPQCNJkjrPQCNJkjrP\n",
       "QCNJkjrPQCNJkjrPQCNJkjrPQCNJkjrPQCNJkjrv/wNeTUGLCw9shQAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aeced90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Remove the plot frame lines. They are unnecessary chartjunk.  \n",
    "ax = plt.subplot(111)  \n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "\n",
    "# Ensure that the axis ticks only show up on the bottom and left of the plot.  \n",
    "# Ticks on the right and top of the plot are generally unnecessary chartjunk.  \n",
    "ax.get_xaxis().tick_bottom()  \n",
    "ax.get_yaxis().tick_left()  \n",
    "\n",
    "# Make sure your axis ticks are large enough to be easily read.  \n",
    "# You don't want your viewers squinting to read your plot.  \n",
    "plt.xticks(unique_test, fontsize=14)  \n",
    "plt.yticks(fontsize=14)  \n",
    "\n",
    "# Along the same vein, make sure your axis labels are large  \n",
    "# enough to be easily read as well. Make them slightly larger  \n",
    "# than your axis tick labels so they stand out.  \n",
    "plt.xlabel(\"Test Data Lables\", fontsize=16)  \n",
    "plt.ylabel(\"Count\", fontsize=16)\n",
    "\n",
    "ax.hist(labels[4000:5000], bins=range(10), cumulative=False, color=\"#3F5D7D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 103.,  130.,  132.,   94.,  134.,  109.,   57.,  148.,   93.]),\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " <a list of 9 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGKCAYAAAAbo9ubAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3X28ZWVd9/HPl0GBQB4km6HUAe9Q8iFIJZV4ENSpSNOs\n",
       "kFAE7fY2BRWROxKkBlFM7kIQsKRUEAPBDCUUQ9SBfEAUbVQEMWFIQBgcaEQe5GF+9x9rnWm7OWdm\n",
       "z7DP3nud+bxfr/3aZ13r2nv/1pwD53uu61prpaqQJEnqso3GXYAkSdLDZaCRJEmdZ6CRJEmdZ6CR\n",
       "JEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdN9JAk2TPJBckuTHJqiQHTdPniUn+JckdSe5KcmWSnXr2b5Lk\n",
       "lCS3Jflpkk8m+ZVRHockSZosox6h2Rz4FvAm4B7g567ql2QH4EvAD4C9gacARwM/7el2EvBSYH9g\n",
       "D2BL4MIkjjZJkrSByriuFJzkTuCQqvpwT9vZwINVdeAMr9kKWA4cXFXntG2PBW4AfreqLp79yiVJ\n",
       "0qSZmFGNdoTlhcDVST6TZHmSK5Ls19PtGcAjgNXBpapuBK4GdhtpwZIkaWJMTKABfgnYAjgK+Azw\n",
       "fOAc4J+S7Nv2WUAzgrOi77W3AvNHVagkSZosG4+7gB5T4eoTVXVS+/W3kjwTOBT49HjKkiRJk26S\n",
       "As2PgQeA7/a1XwO8rP36FmBekm37RmkWAJf1v2GSAo7taVpSVUuGVrEkSZoIExNoquq+JF8Ddurb\n",
       "9URgWfv1lcD9wCKa6aipRcE7AV+e4X0Xz0K5kiRpgow00CTZHNix3dwIWJhkF2BFVf0QOAE4L8m/\n",
       "A1+gOXX7ZcCLAapqZZIPACckWQ7cDpwILAUuGeWxSJKkyTHS07aTPBf4fLtZQNqvz6iqV7d9DqJZ\n",
       "GPw44FrgXVV1bs97PBL4G+AAYDOaIPP6qrppms+rqkp/uyRJmlvGdh2aUTDQSJK0YZik07YlSZLW\n",
       "i4FGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFG\n",
       "kiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1noFGkiR1\n",
       "3sbjLkCSpFFKUuOuYbZVVcZdw6gZaCRJG5y9Djxm3CXMmkvPOm7cJYyFU06SJKnzDDSSJKnzDDSS\n",
       "JKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzDDSSJKnzRhpokuyZ5IIkNyZZleSgNfR9\n",
       "f9vnLX3tmyQ5JcltSX6a5JNJfmX2q5ckSZNq1CM0mwPfAt4E3ANMez+NJH8E7ArcPE2fk4CXAvsD\n",
       "ewBbAhcmcbRJkqQN1Ejv5VRVFwEXASQ5Y7o+SRbShJbnAZ/p27cV8Grg4Kr6XNt2IHAD8Hzg4tmq\n",
       "XZIkTa6JGtVIsjFwDnBcVX1vmi7PAB5BT3CpqhuBq4HdRlKkJEmaOBMVaIBjgeVV9f4Z9i8AHqyq\n",
       "FX3ttwLzZ7UySZI0sUY65bQmSZ4LHATs0r9r9NVIkqQumZhAA+wFbAf8KFmdYeYB707ypqp6PHAL\n",
       "MC/Jtn2jNAuAy6Z70ySLezaXVNWSYRcuSZLGa5ICzfuAj/VsB/g34GzgH9q2K4H7gUU0a21I8lhg\n",
       "J+DL071pVS2enXIlSdKkGGmgSbI5sGO7uRGwMMkuwIqq+iFwW1//+4Fbqur7AFW1MskHgBOSLAdu\n",
       "B04ElgKXjOgwJEnShBn1ouBdgW+0j01pFgF/o30e1GHA+cC5wBeBnwAvqqppr2kjSZLmvlFfh2YJ\n",
       "6xCiqmqHadruA97YPiRJkibutG1JkqR1ZqCRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CR\n",
       "JEmdN0m3PpA0RySZ8xe6rCpvnCtNEAONpFmx14HHjLuEWXPpWceNuwRJfZxykiRJnWegkSRJnWeg\n",
       "kSRJnecaGk0sF5ZKkgZloNFEc2GpJGkQTjlJkqTOM9BIkqTOc8qpwzaENSaSJA3CQNNxrjGRJMkp\n",
       "J0mSNAcYaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJUucZaCRJ\n",
       "UucZaCRJUucZaCRJUucZaCRJUueNNNAk2TPJBUluTLIqyUE9+zZO8u4kS5P8NMnNSf4pyeP63mOT\n",
       "JKckua3t98kkvzLK45AkSZNl1CM0mwPfAt4E3ANU377fAN7RPr8YeBzwmSTzevqdBLwU2B/YA9gS\n",
       "uDCJo02SJG2gNh7lh1XVRcBFAEnO6Nu3EljU25bktcBVwE7AVUm2Al4NHFxVn2v7HAjcADwfuHiW\n",
       "D0GSJE2gSR/V2Kp9vqN9fgbwCHqCS1XdCFwN7Dba0iRJ0qSY2ECT5JHA3wIXVNXNbfMC4MGqWtHX\n",
       "/VZg/ijrkyRJk2OkU06DSrIx8BGa9TEvHHM5kiRpwk1coGnDzDnAU4DnVtUdPbtvAeYl2bZvlGYB\n",
       "cNkM77e4Z3NJVS0ZbsWSJGncJirQJHkE8FHgyTRhZnlflyuB+2kWD5/TvuaxNIuGvzzde1bV4tmq\n",
       "V5IkTYaRBpokmwM7tpsbAQuT7AKsAG4GPgY8E3hR0z0L2r7/XVX3VtXKJB8ATkiyHLgdOBFYClwy\n",
       "wkORJEkTZNSLgncFvtE+NgWObb8+Fngs8PvAdjQjMTf3PPbreY/DgPOBc4EvAj8BXlRVvde0kSRJ\n",
       "G5BRX4dmCWsOUWsNWFV1H/DG9iFJkjS5p21LkiQNykAjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0Aj\n",
       "SZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6z0AjSZI6\n",
       "z0AjSZI6z0AjSZI6z0AjSZI6b+NxFyBJXZSkxl3DbKqqjLsGaV0YaCRpPex14DHjLmHWXHrWceMu\n",
       "QVpnTjlJkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTOM9BIkqTO\n",
       "m/NXCk6y27hrkCRJs2vOB5rNt37Mp8ddw2y47967N7n/3rvGXYYkSRNhpIEmyZ7AEcDTgV8GXlVV\n",
       "Z/b1WQy8BtgG+CpwSFV9t2f/JsDfAPsDmwGfA15fVTdN95nPfNGfbTX8Ixm/G6/+Kj/4+sXjLkOS\n",
       "pIkw6jU0mwPfAt4E3AP83N1qkxwJHA4cCuwKLAc+m2SLnm4nAS+lCTR7AFsCFyZxPZAkSRuokYaA\n",
       "qrqoqt5WVR8HVvXuSxLgMOBdVXV+VV0FHAQ8Cjig7bMV8GrgiKr6XFV9EzgQ+HXg+SM8FEmSNEEm\n",
       "aVRjB2A+sHoeparuBS4Dphb2PgN4RF+fG4Gre/pIkqQNzCQFmgXt86197ct79i0AHqyqFX19bqUJ\n",
       "Q5IkaQM0SYFmTWrtXSRJ0oZqkk7bvqV9ng/c2NM+v2ffLcC8JNv2jdIsoJmaeohlSy9d/fXW8xey\n",
       "9YLth1WvJEmaEJMUaK6nCSyLgCsBkmwK7E5zqjdt+/1tn3PaPo8FdgK+PN2bbr/zXrNatCRJGr9R\n",
       "X4dmc2DHdnMjYGGSXYAVVfXDJCcBRyW5Bvg+8DbgTuBsgKpameQDwAlJlgO3AycCS4FLRnkskiRp\n",
       "cox6hGZX4PPt1wUc2z7OAF5dVSck2Qw4jebCepcDi6qq95K4hwEPAOfSXFjvEuAVVeU6G0mSNlAj\n",
       "DTRVtYS1LESuqqmQM9P++4A3tg9JkqTOnOUkSZI0IwONJEnqPAONJEnqPAONJEnqPAONJEnqPAON\n",
       "JEnqPAONJEnqvEm69YG0wUniBSElaQgMNNIY7XXgMeMuYVZcetZx4y5B0gbGQCNJ0hwzV0d/qyoz\n",
       "7TPQSJI0x8zV0d81cVGwJEnqPAONJEnqPAONJEnqvIECTZI9kzxqhn1bJNlzuGVJkiQNbtARmiXA\n",
       "r82wbyfgC0OpRpIkaT0MY8ppE2DVEN5HkiRpvcx42naSHYAdgKlzvndNskVft82APwX+a3bKkyRJ\n",
       "Wrs1XYfmIOAve7ZPmaHfA8ChQ6tIkiRpHa0p0JxBs3YG4PPAIcDVfX1+BlxbVSuGXpkkSdKAZgw0\n",
       "VbUMWAaQZB/gyqq6czRlSZIkDW6gWx9U1ZJZrkOSJGm9DXodmk2SLE7yvST3JFnV93hwtguVJEma\n",
       "yaA3pzyBZg3NRcC/0Kyd6TUn7+opSZK6YdBA80fA4qp6x2wWI0mStD4GvbDeFsCXZ7MQSZKk9TVo\n",
       "oLkQ8H5NkiRpIg065fRe4KwkBXwKuL2/Q1VdN8zCJEmSBjVooPlK+/xX7aNfAfOGUpEkSdI6GjTQ\n",
       "vHpWq5AkSXoYBr2w3hmzXIckSdJ6G3RR8Mgk2TjJ8Umuay/id12S45LM6+u3OMlNSe5O8oUkTx5X\n",
       "zZIkabwGGqFJ8iFmvnhegKqqYU1LHQW8Fngl8G1gZ5obZf4MeEdbz5HA4TR3BL+W5q7gn03ypKr6\n",
       "6ZDqkCRJHTHoGpq9+flAE+DRNNenWQn89xBr2hW4oKo+1W7/V5ILgWcBJAlwGPCuqjq/bTsIWA4c\n",
       "AJw+xFokSVIHDDTlVFXbV9UOPY/tq2pL4LnAj4A/HGJNFwH7JHkSQDuVtDfN6eIAOwDzgYt76rsX\n",
       "uAzYbYh1SJKkjhh0hGZaVXVZkvfQXKdm92EUVFXvS/JY4OokD7Q1vqOq/r7tsqB9vrXvpcuBXx5G\n",
       "DZIkqVseVqBpXQ88fQjvA0CSNwKvAvYHrgJ+Azg5ybKq+uBaXv6QdT7Lll66+uut5y9k6wXbD6tU\n",
       "SZI0IR5WoEnyCJqFuTcOpxwAjqYZkTmv3b4qyULgrcAHgVva9vl9nzu/Z99q2++81xBLkyRJk2jQ\n",
       "s5y+wENHPzYBnghsC/zZEGsKsKqvbVXbDs2I0C3AIuDKtr5Naaa8jhhiHZIkqSMGHaFJ3zPAncDH\n",
       "gY9W1ZIh1vQJ4C+SXA98l2bK6c3AmdCcH57kJOCoJNcA3wfe1tZz9hDrkCRJHTHolYKfO8t19Hoz\n",
       "8BPgNJpppB/RnIr99p56TkiyWdtnG+ByYFFV3TXCOiVJ0oQYxqLgoWpDyRGsZfqoqo4Fjh1JUZIk\n",
       "aaINfOuDJL+e5ONJfpzkwSS3JflYkqfNZoGSJElrM+ii4F2BS4F7gAtorgGzAHgRsG+Svarq67NW\n",
       "pSRJ0hoMOuX0LuA7wPOq6s6pxiSPAi5p979g+OVJkiSt3aBTTs8G/ro3zAC02+8GnjPswiRJkgY1\n",
       "aKCZ6U7bg+6XJEmaNYMGmq8Cb02yZW9jki2AI2lOm5YkSRqLQdfQHEWzKHhZkgtprg2zHbAv8As0\n",
       "d92WJEkai0EvrHdFkmcBfwn8Ds3F7G4HPg8cV1Xfnr0SJUmS1mzGQJNkI+D3gGVV9e2q+hbwR319\n",
       "ngZsn+Q7VeU6GkmSNBZrWkPzcuCjNPdImslPgXOAPxlmUZIkSetiTYHmQOBDVbVspg5VdT3wAeCV\n",
       "Q65LkiRpYGsKNE8H/m2A9/gcsOtwypEkSVp3awo0jwLuGOA97mj7SpIkjcWaAs2PgYUDvMfj2r6S\n",
       "JEljsaZA8yXgoAHe42Dgi0OpRpIkaT2sKdC8B3hekpOSPLJ/Z5JHJjkJeF7bV5IkaSxmvA5NVX0l\n",
       "yVuAE4EDklwM3NDuXggsArYFDq+qr8x6pZIkSTNY45WCq+qkJN+guV/TS4FN2133AEto7sD977Na\n",
       "oSRJ0lqs9dYHVXUZcFmSecAvts0rquqBWa1MkiRpQIPenJKqehC4dRZrkSRJWi9rWhQsSZLUCQYa\n",
       "SZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeQYaSZLUeRMZaJJs\n",
       "l+TMJMuT3JPkqiR79vVZnOSmJHcn+UKSJ4+rXkmSNF4TF2iSbA18CShgX2An4FBgeU+fI4HD2/Zd\n",
       "232fTbLFyAuWJEljN/DNKUfoz4GbqurgnrYbpr5IEuAw4F1VdX7bdhBNqDkAOH10pUqSpEkwcSM0\n",
       "wEuAK5Kcm+TWJN9MckjP/h2A+cDFUw1VdS9wGbDbaEuVJEmTYBIDzROA1wP/CSwCTgb+uifULGif\n",
       "b+173fKefZIkaQMyiVNOGwFXVNXR7fbSJDsChwCnreW1NauVSZKkiTSJgeZm4Lt9bdcAj2+/vqV9\n",
       "ng/c2NNnfs++1ZYtvXT111vPX8jWC7YfVp2SJGlCTGKg+RLNmU29nggsa7++nia4LAKuBEiyKbA7\n",
       "cET/m22/816zVackSZoQk7iG5j3As5McleRXk/wx8Aba6aaqKuAk4Mgkf5DkqcAZwJ3A2WOqWZIk\n",
       "jdHEjdBU1deTvAQ4HjiG5pTtt1XV3/X0OSHJZjQhZxvgcmBRVd01jpolSdJ4TVygAaiqTwOfXkuf\n",
       "Y4FjR1ORJEmaZJM45SRJkrRODDSSJKnzJnLKSZI0Xkm8rpc6xUAjSXqIvQ48ZtwlzJpLzzpu3CVo\n",
       "FjjlJEmSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9A\n",
       "I0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mS\n",
       "Os9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOs9AI0mSOm+iA02StyZZ\n",
       "leSUvvbFSW5KcneSLyR58rhqlCRJ4zexgSbJs4HXAN8Cqqf9SOBw4FBgV2A58NkkW4yjTkmSNH4T\n",
       "GWiSbAV8BHgVcEdPe4DDgHdV1flVdRVwEPAo4IBx1CpJksZvIgMNcDrwsaq6FEhP+w7AfODiqYaq\n",
       "uhe4DNhtpBVKkqSJsfG4C+iX5DXAE/ifEZfq2b2gfb6172XLgV+e5dIkSdKEmqhAk+RJwDuB3avq\n",
       "walmfn6UZia19i6SJGkumqhAAzwH+EXgqma5DADzgD2SvBZ4ats2H7ix53XzgVume8NlSy9d/fXW\n",
       "8xey9YLth1uxJEkau0kLNOcDV/RsB/gQcC1wPPB9muCyCLgSIMmmwO7AEdO94fY77zWL5UqSpEkw\n",
       "UYGmqlYCK3vbktwN3FFV3223TwKOSnINTcB5G3AncPaIy5UkSRNiogLNDIqe9TFVdUKSzYDTgG2A\n",
       "y4FFVXXXmOqTJEljNvGBpqr2nqbtWODYMZQjSZIm0KReh0aSJGlgBhpJktR5BhpJktR5BhpJktR5\n",
       "BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJ\n",
       "ktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5\n",
       "BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5BhpJktR5Exdokrw1ydeS\n",
       "rEyyPMkFSZ4yTb/FSW5KcneSLyR58jjqlSRJ4zdxgQbYCzgVeA6wD/AAcEmSbaY6JDkSOBw4FNgV\n",
       "WA58NskWoy9XkiSN28bjLqBfVf1O73aSA4GVwG7Ap5IEOAx4V1Wd3/Y5iCbUHACcPtqKJUnSuE3i\n",
       "CE2/LWnqvKPd3gGYD1w81aGq7gUuowk9kiRpA9OFQHMy8E3gK+32gvb51r5+y3v2SZKkDcjETTn1\n",
       "SnIizajL7lVVA7xkkD6SJGmOmdhAk+Q9wH7A3lW1rGfXLe3zfODGnvb5PftWW7b00tVfbz1/IVsv\n",
       "2H7YpUqSpDGbyECT5GTgj2nCzLV9u6+nCS6LgCvb/psCuwNH9L/X9jvvNbvFSpKksZu4QJPkNOAV\n",
       "wEuAlUmm1sXcWVV3VVUlOQk4Ksk1wPeBtwF3AmePpWhJkjRWExdogNfRrIX5XF/7YuDtAFV1QpLN\n",
       "gNOAbYDLgUVVddcI65QkSRNi4gJNVQ105lVVHQscO8vlSJKkDujCaduSJElrZKCRJEmdZ6CRJEmd\n",
       "Z6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CR\n",
       "JEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmd\n",
       "Z6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmdZ6CRJEmd19lA\n",
       "k+T1Sa5Pck+SryfZfdw1SZKk8ehkoEnyMuAk4B3ALsCXgYuSPG6shUmSpLHoZKABDgc+VFUfqKrv\n",
       "VdUbgR8BrxtzXZIkaQw6F2iSPBJ4OnBx366Lgd1GX5EkSRq3zgUa4BeBecCtfe3LgQWjL0eSJI3b\n",
       "xuMuYLYtvfisleOuYTbce9fKTYBNx12HJEmTIFU17hrWSTvldBewf1V9vKf9NODJVbV3T1u3Dk6S\n",
       "JK1RVWW69s6N0FTVfUmuBBYBH+/Z9QLgY319pz1oSZI0t3Qu0LROBM5KcgXNKdt/RrN+5u/HWpUk\n",
       "SRqLTgaaqjovybbA24DtgG8D+1bVD8dbmSRJGofOraGRJEnq18XTtgcyV2+NkGTPJBckuTHJqiQH\n",
       "jbumYUry1iRfS7IyyfL2WJ8y7rqGIckhSZa2x7YyyZeT7DvuumZL+71cleSUcdcyDEkWt8fT+7h5\n",
       "3HUNU5LtkpzZ/rd3T5Krkuw57rqGIcmyab5/q5JcOO7aHq4kGyc5Psl17fftuiTHJZk37tpGaU4G\n",
       "mjl+a4TNgW8BbwLuAebaENtewKnAc4B9gAeAS5JsM9aqhuOHwJ8DvwE8A/g88IkkO4+1qlmQ5NnA\n",
       "a2h+VufSz+g1NOv1ph5PG285w5Nka+BLNN+vfYGdgENprvE1FzyDn//ePZ3mWM8dZ1FDchTwWuAN\n",
       "wJNofj+8HnjrOIsatTk55ZTkq8B/VNVre9quBf65qo4aX2XDleRO4JCq+vC4a5ktSTYHVgIvrqpP\n",
       "jbueYUuyAviLqvqHcdcyLEm2Aq4E/hRYDHy7vT1JpyVZDPxhVc2ZENMryfHAHlW1x7hrGYUkRwNv\n",
       "Abarqp+Nu56HI8m/Aj+uqlf1tJ0JbFNVvz++ykZrzo3QeGuEOWdLmp/TO8ZdyDAlmZdkf5qLI142\n",
       "7nqG7HTgY1V1KTDXLp3whCQ3tUP65yTZYdwFDdFLgCuSnJvk1iTfTHLIuIuaDUlCE7g/0vUw07oI\n",
       "2CfJkwCSPBnYG/j0WKsasU6e5bQW3hphbjkZ+CbwlXEXMgxJnkZzLJvQTBnuV1XfG29Vw5PkNcAT\n",
       "gAPaprk0BHw5cBDNtNN8mrMsv5zkKVV1+1grG44n0ExTnAgcTzM1ekoSquq0sVY2fC8AtgfmxMho\n",
       "Vb0vyWOBq5M8QPO7/R1VtUFdymQuBhrNEUlOpBlV273mztzoNcCvA1sBfwx8NMneVfX18Zb18LV/\n",
       "Hb6T5vv14FQzc2SUpqo+07P5nSRfAa6nCTnvGU9VQ7URcEVVHd1uL02yI3AIMNcCzWtojvXb4y5k\n",
       "GJK8EXgVsD9wFU0YPTnJsqr64FiLG6G5GGh+DDxI8xdUr/nAj0ZfjtZHkvcA+wF7V9WyMZczNFV1\n",
       "P3Bdu/nNJLvS/MJ41cyv6ozn0IyQXtWM6APNaOkeSV4LbN4e/5xQVXcnuQr41XHXMiQ3A9/ta7sG\n",
       "ePwYapk1SX4J+H2a0ai54miaEZnz2u2rkiykWRS8wQSaObeGpqruo1mQuKhv1wtoznbShEtyMvAy\n",
       "YJ+qunbc9cyyecyd/w7PB54K7Nw+dgG+DpwD7DKXwgxAkk2BX2Pu/KH0JZozm3o9EVg2+lJm1cHA\n",
       "vTQ/l3NFgFV9bauYI6Ojg5qLIzQwh2+N0J71s2O7uRGwMMkuwIq5cKXk9iajr6BZoLgyydS6pzur\n",
       "6q7xVfbwJflr4ELgRuBRNOtM9gJ+Z5x1DUtVraQ5I221JHcDd1RV/1/+nZPkb4ALaE6//yXgGGAz\n",
       "4Mxx1jVE76FZE3QUcB7NtMUbmEOn/raLgf838NGqunvc9QzRJ4C/SHI9zSjbbwBvZu78bA5kTp62\n",
       "DZDkdTTX/Ji6NcKbq+qL463q4UvyXJrrl0Cz4HIqgZ9RVa8eS1FDlGQVP39cUxZX1dvHUNLQJPkQ\n",
       "zZkHC2h+8S8F/l9VfXashc2iJF9g7py2fQ6wJ8202m00i7uPqaprxlrYELUXejye5lomNwCnVtWp\n",
       "461qeJLsDVwCPGsurFub0v6heyzwh/zP8opzgLe3sxYbhDkbaCRJ0oZjrszdS5KkDZiBRpIkdZ6B\n",
       "RpIkdZ6BRpIkdZ6BRpIkdZ6BRpIkdZ6BRpIkdZ6BRpplST6R5PYkj5xh/6OS3JVk4HuuJFnWXqhv\n",
       "avvgJKuSrPG+O0m2b/sdNPgRrH7tYUn+YJr2xe0FEUcqyZL2WFYleaD9N/5mkvcmefLDeN+Dkwz1\n",
       "3lpJntvWuc8Q3uuMJGu9KvigPxPSXGGgkWbfGcDWwAtn2P9HrPsl9Kt9TLkQeDZwyzq8fl0dBjwk\n",
       "0AD/0H72OCxtP3s3mpuZfpjmasz/0V4tfH0cDEz6Vbe9IqrUZ67ey0maJJ8CVgCvBP5lmv2vBG6o\n",
       "qkvX9wOq6sc0d5qfbQ+52V1V3QTcNILPns6dVXVFz/YlSU6huez7KUm+Npcucd9jg7rpoDQIR2ik\n",
       "WdbeZfoc4HeTPLp3XzsdsCdwVru9KMmnk9zcTkN9O8nhSdb43+p00wtJfiHJ+5KsSHJnkk8Cj53m\n",
       "tbsm+eckP0xyd5JrkryzvZv0VJ9lwOOBl/dM83yw3feQKackWyY5tT2Oe9v3PKyvz9Q0zIvavre1\n",
       "j7OSbDXIv+10quoB4PXAA8Dqe0gl+dX2va9rj/MH7b/P1j19ltB8P36r5zg/3+57TJL3J/le+735\n",
       "ryT/lOSX17fWXoPU19d/tyRfS3JPkuuTHDrg5/yfJEvb192W5B+TbNPX501Jrm7ruL39nJcM4zil\n",
       "2eIIjTQaZwKHAvsD7+tpfwXNX9sfbrd3oLn56KnAXcCuwGLgMaz7XY/fTzMNsxj4GrAIOHuafo+n\n",
       "mbo5E/h3lAdRAAAGNUlEQVRv4KnAXwJPAP6k7fMS4NPAf7TvB80NGqesngJpw9enaO74ewzNzWFf\n",
       "CJyY5DFVdXTf558M/Gv7WTsBJwAP0kz9rJequi3J14Hf6mnejuZO54fTjJg9ATiqPa7d2j6vAz5C\n",
       "88fea9u2n7TP2wA/A44Gbm3f7wjgS0l2qqqfrW+961DflC2BjwJ/Dfwnzb/de5PcWVUzTl2mueP7\n",
       "4TT/5m+hCbjvAJ6aZLeqWpXk5cDf0Nzs8N9ppkN3bo9fmlxV5cOHjxE8gO8Al/e1XQ18aYb+ofmj\n",
       "42jg9r591wMf7Nk+GFgFPL7dfhLNCMWf973ufW2/V67lM19BEyq26fvMD0/zmsXAqp7tF073GTRr\n",
       "be4Ftm23n9v2+1Bfv1OAewb491wCXLaG/ecAd69h/8bA7m0Nuwz6vj395gGPa1//krX0nTrWfdbh\n",
       "52Wm+s5o2/br638xsGwNPxPbtz8Tb+t73W5tvxe326cCV47zvxUfPtbn4ZSTNDpnAr+ZZEeAJL9J\n",
       "EzxW/0WdZLt2WuMGmtGA+4DjgK2S/NI6fNazaEYZzutr/2h/x3Z66N1JfkATOO6jGTEK8MR1+Mwp\n",
       "e9L8guwfDfon4JE8dAHxp/q2vwNsso7HO520dTQbySOTHNVOf91Nc5yXtbsHOs4kr2una+4E7gdu\n",
       "WJfXr+W916W+B4CP97WdCzx+DVNgL6D5mTg7ycZTD+AK4KfAHm2/K4Bd0pwt9vwkv/AwD00aCQON\n",
       "NDofoR25aLdfSRMgzoXVUzUXAPsCb6c5W+eZwDtpfjlvyuC2a59v7WtfPk3fD9FMr5wEPL/9zEPa\n",
       "fZusw2dOeTTNiNIDfe239OzvdXvf9tTUzboc73QeB/yoZ/tdwF/RhLV9aabzXjroZyV5A3AazUjI\n",
       "H7SvnwpnD7fWda3vv6vqwb62qe/1r8zw/lMB8T9pwlLvY3NgW4Cq+jDN1NuzgM8AK5J8PMnC9Tgm\n",
       "aWRcQyONSFX9KMlngVckeTvwMuBfq2pl2+V/Ac8AXlFVq0c3krx4PT5u6hf5fGBZT/v83k7twt/f\n",
       "B/6qqk7pad95PT5zyu3Ao5Ns3BdqFvTsn1Xt6M4z+flRov2BM6vq+J5+W67D2+4PXFJV/7fn9Ts8\n",
       "3FrXs75tkszrCzVT39uZzjhb0T6/ALhjDfupqtOB09vF2b8N/C1N8B7X6fnSWjlCI43WmcBCmsWc\n",
       "2/Lz156ZGtpfHQKSPAJ4Oet+3ZGv0owGvayvff++7U1o1oL0j6YcPM17/qynxjVZQvP/lv362l/e\n",
       "vsdXBniP9db+m72vreG9Pbs246HHOd0F9GY6zkFfv77W5f3n0Vy/qNf+NKf/3zzDay6m+ZlYWFXf\n",
       "mOZxQ/8LqmplVZ0HfIxmsbg0sRyhkUbrEzRnzRxGM0XwmZ5936VZk/HOJA/S/HJ7M02Y6b/uyBqv\n",
       "Q1JV30tyNvD2dirr6zRnOf1uX7+VSS4H3pLkRzR/pb8amG4dxneBPZL8Xlv7bdP9EgQuAr4I/H2S\n",
       "x7Sv2xf4U+D4qhrmCM2WSZ5F8+/xKOBpNCFgR+D1VfXNnr6fAQ5K8m3gBzTTOc+Z5j2vAl6fZD/g\n",
       "OuAnVXVt+/ojk7yV5qyxfYA/XMd690zfqfvA/VX1yXWoD+BO4IQkv8j/nOX0PGDGK0BX1XVJ3g2c\n",
       "muRJNOtz7qWZmns+8I9VtSTJ6TQ/o5fTTFE+kWaR+L+t47FKI2WgkUaoqu5Nch7NL/ezq2pVz777\n",
       "22t9nEqzjmIF8EHgh8Dp/W813dv3bb+WZrHnETSLcT8HHEATNnr9CfB3NOtD7qGZWvggzanUvd5K\n",
       "c6bSeTSjCWfwP1fUXf3ZVVVt6DkeOJJmJOp64M1VdfIAx7Gm9v4+v04z4lM0v+Svozntfb+qurqv\n",
       "/xtogs872+1P0Rz7FX393k2zWPsfgS1oRpz2oVnXtDVNyNy0bf/t9jMHqRWa0+H7/ZTmNOxB6ytg\n",
       "Jc3o23tpQtwtwBur6qwZPrfZqDo6ydU0a6QOaff/ELgEuLbt9kWaUHggsBVwM811kv5qgOOUxiZV\n",
       "XkFbkiR1m2toJElS5xloJElS5xloJElS5xloJElS5xloJElS5xloJElS5xloJElS5xloJElS5xlo\n",
       "JElS5/1/2MjJTwKILBoAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11251e810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Remove the plot frame lines. They are unnecessary chartjunk.  \n",
    "ax = plt.subplot(111)  \n",
    "ax.spines[\"top\"].set_visible(False)  \n",
    "ax.spines[\"right\"].set_visible(False)  \n",
    "\n",
    "# Ensure that the axis ticks only show up on the bottom and left of the plot.  \n",
    "# Ticks on the right and top of the plot are generally unnecessary chartjunk.  \n",
    "ax.get_xaxis().tick_bottom()  \n",
    "ax.get_yaxis().tick_left()  \n",
    "\n",
    "# Make sure your axis ticks are large enough to be easily read.  \n",
    "# You don't want your viewers squinting to read your plot.  \n",
    "plt.xticks(unique_valid, fontsize=14)  \n",
    "plt.yticks(fontsize=14)  \n",
    "\n",
    "# Along the same vein, make sure your axis labels are large  \n",
    "# enough to be easily read as well. Make them slightly larger  \n",
    "# than your axis tick labels so they stand out.  \n",
    "plt.xlabel(\"Validation Data Lables\", fontsize=16)  \n",
    "plt.ylabel(\"Count\", fontsize=16)\n",
    "\n",
    "ax.hist(labels[5000:], bins=range(10), cumulative=False, color=\"#3F5D7D\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
