{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 9\n",
    "batch_size = 64\n",
    "nb_epoch = 8\n",
    "np.random.seed(1337) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "def scale(X, eps = 0.001):\n",
    "    # scale the data points s.t the columns of the feature space\n",
    "    # (i.e the predictors) are within the range [0, 1]\n",
    "    return (X - np.min(X, axis = 0)) / (np.max(X, axis = 0) + eps)\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "\n",
    "# scale the data to the range [0, 1] and then construct the training\n",
    "# and testing splits\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.4)\n",
    "(valX, testX, valY, testY) = train_test_split(testX, testY, test_size = 0.5)\n",
    "\n",
    "# reshape for convolutions\n",
    "trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "testX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    "valX = valX.reshape((valX.shape[0], 1, 28, 28))\n",
    "# convert class vectors to binary class matrices\n",
    "trainY = np_utils.to_categorical(trainY, nb_classes)\n",
    "testY = np_utils.to_categorical(testY, nb_classes)\n",
    "valY = np_utils.to_categorical(valY, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3600 samples, validate on 1200 samples\n",
      "Epoch 0\n",
      "3600/3600 [==============================] - 150s - loss: 2.1789 - acc.: 0.1486 - val. loss: 2.1543 - val. acc.: 0.1606\n",
      "Epoch 1\n",
      "3600/3600 [==============================] - 141s - loss: 2.0878 - acc.: 0.2564 - val. loss: 1.4304 - val. acc.: 0.4959\n",
      "Epoch 2\n",
      "3600/3600 [==============================] - 143s - loss: 0.7865 - acc.: 0.7636 - val. loss: 0.3048 - val. acc.: 0.9158\n",
      "Epoch 3\n",
      "3600/3600 [==============================] - 138s - loss: 0.3807 - acc.: 0.9044 - val. loss: 0.3089 - val. acc.: 0.9232\n",
      "Epoch 4\n",
      "3600/3600 [==============================] - 141s - loss: 0.3342 - acc.: 0.9186 - val. loss: 0.2908 - val. acc.: 0.9274\n",
      "Epoch 5\n",
      "3600/3600 [==============================] - 138s - loss: 0.3183 - acc.: 0.9211 - val. loss: 0.2675 - val. acc.: 0.9317\n",
      "Epoch 6\n",
      "3600/3600 [==============================] - 138s - loss: 0.2851 - acc.: 0.9353 - val. loss: 0.2671 - val. acc.: 0.9309\n",
      "Epoch 7\n",
      "3600/3600 [==============================] - 444s - loss: 0.2720 - acc.: 0.9342 - val. loss: 0.2760 - val. acc.: 0.9317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': [0.14861111111111111,\n",
       "  0.25638888888888889,\n",
       "  0.76361111111111113,\n",
       "  0.9044444444444445,\n",
       "  0.91861111111111116,\n",
       "  0.9211111111111111,\n",
       "  0.93527777777777776,\n",
       "  0.9341666666666667],\n",
       " 'epoch': [0, 1, 2, 3, 4, 5, 6, 7],\n",
       " 'loss': [2.1789463927896247,\n",
       "  2.0878450813488958,\n",
       "  0.78650011038076728,\n",
       "  0.3807269037923145,\n",
       "  0.33419231585977621,\n",
       "  0.31834055378414006,\n",
       "  0.28511646862568929,\n",
       "  0.27201855536819686],\n",
       " 'val_acc': [0.16063596491228072,\n",
       "  0.49588815789473684,\n",
       "  0.9158442982456141,\n",
       "  0.9232456140350878,\n",
       "  0.9273574561403509,\n",
       "  0.9317434210526315,\n",
       "  0.930921052631579,\n",
       "  0.9317434210526315],\n",
       " 'val_loss': [2.154319376109021,\n",
       "  1.4303748750302472,\n",
       "  0.30476048631872327,\n",
       "  0.308910406799675,\n",
       "  0.2908024769439173,\n",
       "  0.26752330177746464,\n",
       "  0.2671278250036357,\n",
       "  0.2760488027704364]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the model which consists of 3 conv layers followed by\n",
    "# 2 fully conntected layers\n",
    "\n",
    "# Sequential wrapper model\n",
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(Convolution2D(32, 1, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(Convolution2D(48, 32, 2, 2))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# third convolutional layer\n",
    "model.add(Convolution2D(32, 48, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# convert convolutional filters to flatt so they can be feed to \n",
    "# fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# first fully connected layer\n",
    "model.add(Dense(32*6*6, 144, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# second fully connected layer\n",
    "model.add(Dense(144, 144, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# last fully connected layer which output classes\n",
    "model.add(Dense(144, 9, init='lecun_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# setting sgd optimizer parameters\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(trainX, trainY,\n",
    "          batch_size=batch_size,\n",
    "          nb_epoch=nb_epoch,\n",
    "          show_accuracy=True,\n",
    "          verbose=1,\n",
    "          validation_data=(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Convolution2D at 0x122e97fd0>,\n",
       " <keras.layers.core.Activation at 0x118dd14d0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x118dd1d50>,\n",
       " <keras.layers.core.Activation at 0x11ca52590>,\n",
       " <keras.layers.convolutional.MaxPooling2D at 0x11ca67390>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x11ca52c90>,\n",
       " <keras.layers.core.Activation at 0x11ca678d0>,\n",
       " <keras.layers.convolutional.MaxPooling2D at 0x11ca71f10>,\n",
       " <keras.layers.core.Flatten at 0x11ca498d0>,\n",
       " <keras.layers.core.Dense at 0x11ca86ed0>,\n",
       " <keras.layers.core.Activation at 0x11ca71b90>,\n",
       " <keras.layers.core.Dropout at 0x11ca90950>,\n",
       " <keras.layers.core.Dense at 0x11caa5190>,\n",
       " <keras.layers.core.Activation at 0x11caa5050>,\n",
       " <keras.layers.core.Dropout at 0x11cab97d0>,\n",
       " <keras.layers.core.Dense at 0x11cab9c50>,\n",
       " <keras.layers.core.Activation at 0x11caa5e90>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<keras.layers.convolutional.Convolution2D object at 0x122e97fd0>\n",
      "2\n",
      "<keras.layers.convolutional.Convolution2D object at 0x118dd1d50>\n",
      "5\n",
      "<keras.layers.convolutional.Convolution2D object at 0x11ca52c90>\n",
      "9\n",
      "<keras.layers.core.Dense object at 0x11ca86ed0>\n",
      "12\n",
      "<keras.layers.core.Dense object at 0x11caa5190>\n",
      "15\n",
      "<keras.layers.core.Dense object at 0x11cab9c50>\n"
     ]
    }
   ],
   "source": [
    "for l in range(len(model.layers)):\n",
    "    if model.layers[l].get_weights() != []:\n",
    "        print l\n",
    "        print model.layers[l]\n",
    "#         print model.layers[l].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequential wrapper model\n",
    "model1 = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model1.add(Convolution2D(32, 1, 2, 2, weights=model.layers[0].get_weights()))\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "# second convolutional layer\n",
    "model1.add(Convolution2D(48, 32, 2, 2, weights=model.layers[2].get_weights()))\n",
    "model1.add(Activation('relu')) \n",
    "model1.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# third convolutional layer\n",
    "model1.add(Convolution2D(32, 48, 2, 2, weights=model.layers[5].get_weights()))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# convert convolutional filters to flatt so they can be feed to \n",
    "# fully connected layers\n",
    "model1.add(Flatten())\n",
    "\n",
    "# first fully connected layer\n",
    "model1.add(Dense(32*6*6, 144, init='lecun_uniform', weights=model.layers[9].get_weights()))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "# second fully connected layer\n",
    "model1.add(Dense(144, 144, init='lecun_uniform', weights=model.layers[12].get_weights()))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/3600 [==============================] - 39s    \n",
      "1200/1200 [==============================] - 13s    \n"
     ]
    }
   ],
   "source": [
    "trainX_deep = model1.predict(trainX)\n",
    "testX_deep = model1.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escape time :  0.615 s\n",
      "accuracy is 0.9375\n"
     ]
    }
   ],
   "source": [
    "# dimension reduction by CNN : 144 \n",
    "t0 = time()\n",
    "clf = SVC(cache_size=1000, kernel=\"rbf\", C=10.0, gamma=0.03125)\n",
    "\n",
    "labels_train = np_utils.categorical_probas_to_classes(trainY)\n",
    "labels_test = np_utils.categorical_probas_to_classes(testY)\n",
    "\n",
    "clf.fit(trainX_deep, labels_train)\n",
    "\n",
    "y_pred = clf.predict(testX_deep)\n",
    "score_accuracy = accuracy_score(y_pred, labels_test, normalize=True)\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "print \"accuracy is %s\" % score_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escape time :  8.029 s\n",
      "accuracy is 0.9275\n"
     ]
    }
   ],
   "source": [
    "# dimension : 784 \n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.4)\n",
    "(valX, testX, valY, testY) = train_test_split(testX, testY, test_size = 0.5)\n",
    "\n",
    "t0 = time()\n",
    "clf = SVC(cache_size=1000, kernel=\"rbf\", C=10.0, gamma=0.03125)\n",
    "\n",
    "clf.fit(trainX, trainY)\n",
    "\n",
    "y_pred = clf.predict(testX)\n",
    "score_accuracy = accuracy_score(y_pred, testY, normalize=True)\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "print \"accuracy is %s\" % score_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escape time :  1.468 s\n",
      "accuracy is 0.574166666667\n"
     ]
    }
   ],
   "source": [
    "# dimension reduction by RandomizedPCA : 144 \n",
    "\n",
    "pca = RandomizedPCA(n_components=144)\n",
    "\n",
    "trainX = pca.fit_transform(trainX, trainY)\n",
    "testX = pca.fit_transform(testX, testY)\n",
    "\n",
    "t0 = time()\n",
    "clf = SVC(cache_size=1000, kernel=\"rbf\", C=10.0, gamma=0.03125)\n",
    "\n",
    "clf.fit(trainX, trainY)\n",
    "\n",
    "y_pred = clf.predict(testX)\n",
    "score_accuracy = accuracy_score(y_pred, testY, normalize=True)\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "print \"accuracy is %s\" % score_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
