{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_classes = 9\n",
    "batch_size = 64\n",
    "nb_epoch = 50\n",
    "np.random.seed(1337) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train set 1200 rows, 1 columns\n",
      "the shape of test set 2400 rows, 1 columns\n",
      "the shape of validation set 2400 rows, 1 columns\n",
      "Train on 1200 samples, validate on 2400 samples\n",
      "Epoch 0\n",
      "1200/1200 [==============================] - 72s - loss: 2.1896 - acc.: 0.1258 - val. loss: 2.1806 - val. acc.: 0.1488\n",
      "Epoch 1\n",
      "1200/1200 [==============================] - 71s - loss: 2.1738 - acc.: 0.1475 - val. loss: 2.1772 - val. acc.: 0.1488\n",
      "Epoch 2\n",
      "1200/1200 [==============================] - 71s - loss: 2.1697 - acc.: 0.1475 - val. loss: 2.1757 - val. acc.: 0.1488\n",
      "Epoch 3\n",
      "1200/1200 [==============================] - 74s - loss: 2.1641 - acc.: 0.1583 - val. loss: 2.1598 - val. acc.: 0.2286\n",
      "Epoch 4\n",
      "1200/1200 [==============================] - 78s - loss: 2.0644 - acc.: 0.2592 - val. loss: 1.9367 - val. acc.: 0.2936\n",
      "Epoch 5\n",
      "1200/1200 [==============================] - 71s - loss: 1.7413 - acc.: 0.3492 - val. loss: 1.2673 - val. acc.: 0.5452\n",
      "Epoch 6\n",
      "1200/1200 [==============================] - 81s - loss: 1.5537 - acc.: 0.4483 - val. loss: 0.8332 - val. acc.: 0.7677\n",
      "Epoch 7\n",
      "1200/1200 [==============================] - 68s - loss: 0.7499 - acc.: 0.7708 - val. loss: 0.4864 - val. acc.: 0.9071\n",
      "Epoch 8\n",
      "1200/1200 [==============================] - 68s - loss: 0.5006 - acc.: 0.8600 - val. loss: 0.4167 - val. acc.: 0.9042\n",
      "Epoch 9\n",
      "1200/1200 [==============================] - 67s - loss: 0.4309 - acc.: 0.9017 - val. loss: 0.3850 - val. acc.: 0.9062\n",
      "Epoch 10\n",
      "1200/1200 [==============================] - 68s - loss: 0.3503 - acc.: 0.9167 - val. loss: 0.3895 - val. acc.: 0.9062\n",
      "Epoch 11\n",
      "1200/1200 [==============================] - 78s - loss: 0.3227 - acc.: 0.9275 - val. loss: 0.3675 - val. acc.: 0.9091\n",
      "Epoch 12\n",
      "1200/1200 [==============================] - 75s - loss: 0.3130 - acc.: 0.9333 - val. loss: 0.3726 - val. acc.: 0.9083\n",
      "Epoch 13\n",
      "1200/1200 [==============================] - 74s - loss: 0.3092 - acc.: 0.9250 - val. loss: 0.3778 - val. acc.: 0.9124\n",
      "Epoch 14\n",
      "1200/1200 [==============================] - 68s - loss: 0.2682 - acc.: 0.9342 - val. loss: 0.3851 - val. acc.: 0.9116\n",
      "Epoch 15\n",
      "1200/1200 [==============================] - 67s - loss: 0.2606 - acc.: 0.9408 - val. loss: 0.4001 - val. acc.: 0.9137\n",
      "Epoch 16\n",
      "1200/1200 [==============================] - 68s - loss: 0.3060 - acc.: 0.9308 - val. loss: 0.3595 - val. acc.: 0.9120\n",
      "Epoch 17\n",
      "1200/1200 [==============================] - 67s - loss: 0.2205 - acc.: 0.9425 - val. loss: 0.3831 - val. acc.: 0.9194\n",
      "Epoch 18\n",
      "1200/1200 [==============================] - 67s - loss: 0.2301 - acc.: 0.9417 - val. loss: 0.3744 - val. acc.: 0.9198\n",
      "Epoch 19\n",
      "1200/1200 [==============================] - 67s - loss: 0.1975 - acc.: 0.9467 - val. loss: 0.4686 - val. acc.: 0.9174\n",
      "Epoch 20\n",
      "1200/1200 [==============================] - 69s - loss: 0.2040 - acc.: 0.9408 - val. loss: 0.4215 - val. acc.: 0.9206\n",
      "Epoch 21\n",
      "1200/1200 [==============================] - 68s - loss: 0.2058 - acc.: 0.9475 - val. loss: 0.3931 - val. acc.: 0.9219\n",
      "Epoch 22\n",
      "1200/1200 [==============================] - 68s - loss: 0.1900 - acc.: 0.9425 - val. loss: 0.4485 - val. acc.: 0.9215\n",
      "Epoch 23\n",
      "1200/1200 [==============================] - 71s - loss: 0.1991 - acc.: 0.9533 - val. loss: 0.4151 - val. acc.: 0.9178\n",
      "Epoch 24\n",
      "1200/1200 [==============================] - 71s - loss: 0.1968 - acc.: 0.9525 - val. loss: 0.4220 - val. acc.: 0.9186\n",
      "Epoch 25\n",
      "1200/1200 [==============================] - 72s - loss: 0.1896 - acc.: 0.9492 - val. loss: 0.4519 - val. acc.: 0.9182\n",
      "Epoch 26\n",
      "1200/1200 [==============================] - 67s - loss: 0.1814 - acc.: 0.9533 - val. loss: 0.4669 - val. acc.: 0.9186\n",
      "Epoch 27\n",
      "1200/1200 [==============================] - 80s - loss: 0.1718 - acc.: 0.9583 - val. loss: 0.4472 - val. acc.: 0.9211\n",
      "Epoch 28\n",
      "1200/1200 [==============================] - 77s - loss: 0.1612 - acc.: 0.9483 - val. loss: 0.4569 - val. acc.: 0.9215\n",
      "Epoch 29\n",
      "1200/1200 [==============================] - 70s - loss: 0.1822 - acc.: 0.9508 - val. loss: 0.4475 - val. acc.: 0.9161\n",
      "Epoch 30\n",
      "1200/1200 [==============================] - 68s - loss: 0.1841 - acc.: 0.9542 - val. loss: 0.4402 - val. acc.: 0.9174\n",
      "Epoch 31\n",
      "1200/1200 [==============================] - 68s - loss: 0.1702 - acc.: 0.9592 - val. loss: 0.4706 - val. acc.: 0.9161\n",
      "Epoch 32\n",
      "1200/1200 [==============================] - 69s - loss: 0.1705 - acc.: 0.9533 - val. loss: 0.4992 - val. acc.: 0.9194\n",
      "Epoch 33\n",
      "1200/1200 [==============================] - 68s - loss: 0.1651 - acc.: 0.9583 - val. loss: 0.4516 - val. acc.: 0.9198\n",
      "Epoch 34\n",
      "1200/1200 [==============================] - 78s - loss: 0.1565 - acc.: 0.9583 - val. loss: 0.4355 - val. acc.: 0.9211\n",
      "Epoch 35\n",
      "1200/1200 [==============================] - 77s - loss: 0.1526 - acc.: 0.9583 - val. loss: 0.4748 - val. acc.: 0.9194\n",
      "Epoch 36\n",
      "1200/1200 [==============================] - 71s - loss: 0.1688 - acc.: 0.9583 - val. loss: 0.4790 - val. acc.: 0.9178\n",
      "Epoch 37\n",
      "1200/1200 [==============================] - 73s - loss: 0.1490 - acc.: 0.9625 - val. loss: 0.5161 - val. acc.: 0.9202\n",
      "Epoch 38\n",
      "1200/1200 [==============================] - 72s - loss: 0.1327 - acc.: 0.9642 - val. loss: 0.5444 - val. acc.: 0.9190\n",
      "Epoch 39\n",
      "1200/1200 [==============================] - 71s - loss: 0.1641 - acc.: 0.9575 - val. loss: 0.4800 - val. acc.: 0.9190\n",
      "Epoch 40\n",
      "1200/1200 [==============================] - 67s - loss: 0.1469 - acc.: 0.9625 - val. loss: 0.5221 - val. acc.: 0.9202\n",
      "Epoch 41\n",
      "1200/1200 [==============================] - 71s - loss: 0.1537 - acc.: 0.9583 - val. loss: 0.5261 - val. acc.: 0.9174\n",
      "Epoch 42\n",
      "1200/1200 [==============================] - 70s - loss: 0.1440 - acc.: 0.9525 - val. loss: 0.4796 - val. acc.: 0.9169\n",
      "Epoch 43\n",
      "1200/1200 [==============================] - 67s - loss: 0.1317 - acc.: 0.9658 - val. loss: 0.5776 - val. acc.: 0.9186\n",
      "Epoch 44\n",
      "1200/1200 [==============================] - 67s - loss: 0.1298 - acc.: 0.9617 - val. loss: 0.5543 - val. acc.: 0.9194\n",
      "Epoch 45\n",
      "1200/1200 [==============================] - 67s - loss: 0.1433 - acc.: 0.9575 - val. loss: 0.5781 - val. acc.: 0.9186\n",
      "Epoch 46\n",
      "1200/1200 [==============================] - 67s - loss: 0.1417 - acc.: 0.9617 - val. loss: 0.5296 - val. acc.: 0.9194\n",
      "Epoch 47\n",
      "1200/1200 [==============================] - 73s - loss: 0.1298 - acc.: 0.9650 - val. loss: 0.5829 - val. acc.: 0.9206\n",
      "Epoch 48\n",
      "1200/1200 [==============================] - 70s - loss: 0.1289 - acc.: 0.9633 - val. loss: 0.5037 - val. acc.: 0.9215\n",
      "Epoch 49\n",
      "1200/1200 [==============================] - 74s - loss: 0.1508 - acc.: 0.9600 - val. loss: 0.4608 - val. acc.: 0.9215\n",
      "Test score : 0.427060957735\n",
      "Test accuracy : 0.932565789474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10f5464d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEPCAYAAACNyEVOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcXHWZ7/HPlw6r7AZQQzCIiCA714iIEASG4EJ0RsGo\n",
       "KDo6XL3MuA6Ly8B1xmEYx5F7B4eJgsTBuQRXxIuyg6JXgTgJawKJ0A4BDYsG2UnIc//4naLrV93V\n",
       "Vd1d1aeqz/f9evUrdapOn3rqSfL0r5/zO7+jiMDMzPrLBmUHYGZmY+fibWbWh1y8zcz6kIu3mVkf\n",
       "cvE2M+tDLt5mZn2oZfGW9HVJqyXdNso+/1vSCkm3SNqvsyGamVmjdkbeFwBzm70o6Y3AyyNiV+Av\n",
       "gHM7FJuZmTXRsnhHxA3AH0bZ5RjgG8W+NwJbS9qhM+GZmdlIOtHzngHcV7e9CtixA8c1M7MmOnXC\n",
       "Ug3bvubezKyLpnXgGPcDM+u2dyyey0hyQTczG4eIaBwgd6R4XwqcBCySdCCwJiJWtxtAVUk6IyLO\n",
       "KDuOXuKc5JyPXFXz0Wzg27J4S7oIOBSYLuk+4HRgQ4CIWBARP5L0RkkrgSeA93cu7CltVtkB9KBZ\n",
       "ZQfQY2aVHUCPmVV2AL2kZfGOiPlt7HNSZ8IxM7N2+ArL8iwsO4AetLDsAHrMwrID6DELyw6gl2iy\n",
       "bsYgKdzzNjMbm2a10yPvkkiaU3YMvcY5yTkfOecj14nZJmZmbZNQRLnXgkhMI10dLuAuYGUET3fp\n",
       "vTYDdgJeAKwBHgUejWDthI7rtomZTZTEBqRrPF4B7Fb8uR2wFbB1w5+bAbcCPy2+bojgwRGOqeKY\n",
       "ewP7ANsDK0nF9i5gVQTrxxjnxsB7gVOBB4DfF/HOKrbvrjv+XcX2/aO9T/GDYFbxmV9ePN4JeGnx\n",
       "tSXpKvTHGvLwDEPF/HfAb0b4ug/0zEi108XbbJwktgD2IhWWFwP/F7i506NKiU2A3Yv32Rt4Fek/\n",
       "+03F160RPNNGjLsCA50MDXgRqWjtSipCtaK3oojxUYYKVO3PZ4D9gdcDhwAHA78FbgBuIxXA2md9\n",
       "llTobwFWF6/VfjhszVAxv52Ui5sjeGSEPGwKfBA4udj3CxH8rO71acDOxbFrX7UfRFsUn6dW2H9L\n",
       "KtC1fV5WfNa7i/0GSYX3v4o/VzcW/+IH0wtIRXybIo+zGCr4ta+XgDZ08e4hkuZExPVlx9FLOpkT\n",
       "iV1IBeDpuq9n6h4/HMGjbR5rE4aKRq0Q7k36D3cnqbA8DPwZsB74JvDNCO4dQ7wbktYJqvuPe/Gh\n",
       "cNyLgF1IRapWxO4g/bB4DTC7iO02ikJOuuK5Nlrdodj/VmA5TOxX9RE8RDFCjeCx8RxAYoCU10NI\n",
       "P5hWkD7nrRGsHtov//dR/GCqFdi9Sbn4b8CDwI2kfCwGDgI+AfySVLQXjzG+Lcl/o3gJqUDXRuYr\n",
       "InhqjB+73feeBlrr4t1DXLyHm2hOil+J3wZ8iFQMfkm6oGwTYOPiz02ATUm/0q9jxF9TeSFD/1l3\n",
       "Y+g/692kInkLqRiuiOC5uvcXqYAcDxxHKpYXAteQRlc7kAr+DnVftYK9A2lkWYvjv+BMwWkXA8ua\n",
       "jayL930BcEDx3nsVn6EW48r6GPtZO/8+ih8EryTlYjbwatIPg7+PoOk9CXpZs9rp4m1dJbEDQ6PA\n",
       "PUkFqjYqun+kFkPDSKx+NFYbeWZFSWIPUsF+D7AUOA+4pEXBE7Atw39NnQk8wtCvyHcD94715JLE\n",
       "RqR18I8njZAfKj77atKv2LXHD5CK9f0TPYFlU5OLtw1TnAWfBSxv98SPxFbA+0i/nj7NyG2JFzNU\n",
       "sDckFdz6X/dro6J1DBXy20l93UOA15EKXO2EVq0PWjtmrWVxB2kFy5mkm4acH8E948uGWW9y8e4x\n",
       "ZbRNisL7OoZGtHuTRpn1fdq7mnzvHqQFyOYDVwBXkgpzfTui9vUQQyPkZqNrkUa6tUK+N3zjj/C+\n",
       "i4Cf1fc6m8SzJWkkvzlwbQTr2s9Ef3BrLVfVfDSrnZ7n3SckppP6d2uAm9rpYxbTtw4C/hSYQ5oR\n",
       "cBNpNPsZ0qj3KWBf0q/310vcR+rTLiLdQektpKK9B/BVYM+I4Uv+jlVR0AeLr2+leE+YE/G+69v8\n",
       "/j8C/2+icZj1K4+8e1DRztiPoVHpbGA66cz59sXXZaTleK+K4Im6792ANLp+B2n2wyPAd4CrgF9F\n",
       "8Owo7zsNOJxUyN9MaoHcC/wL8N3Reshm1h1um/S44gTXMaQTbweTpqDV5vHeSJqKtb7Yd2fSiPgt\n",
       "pJNhPwN+TBpZv500be3bwLcjWD7OeLYAZoz3+82sM1y8e0ytfyexG+nigfeSCvZ5wPcjeLK947AV\n",
       "cBRwNHAPEyjYZatqT7MZ5yNX1Xy4591D0ij7746U+DxpPvFC4OAIVoz1WMWFJt8qvsysIlqOvCXN\n",
       "Bc4mXVZ7XkSc1fD6NsDXSZeIPg18ICLuGOE4lR95FzMsjgW+QDpR96/ADz2/18yaGVfbRNIA6UKF\n",
       "I0g3Fb4ZmB8Ry+r2+SLwx4j4W0m7AV+JiCPaDaAqJA4D/pG0HsTJEVxbckhm1gfGu573bGBlRAxG\n",
       "xFrS9LF5DfvsDlwHEBF3AbMkbdeBmKcEib0kLgPOB/4ZmB3BtV6beDjnJOd85JyPXKviPYO0TkLN\n",
       "quK5ereQ5hEjaTbpwosdOxVgv5LYSOI80roWVwK7R3DRWJewNDMbSasTlu1MRfkH4H9JWkK6jHkJ\n",
       "jHwBiaSFpF4vpItNltbOHtd+qk6VbViwALbfE972igjWSJoj1b+enz0vO95e2a7PTS/EU/a281G9\n",
       "fBSPTyg+6iBNtOp5HwicERFzi+3TgPWNJy0bvudeYK+IeLzh+cr0vCX2IV0Us18nrkY0s+oab897\n",
       "MbCrpFmSNiItc3lpw4G3Kl5D0oeAnzQW7iop1mW+ADh1tMLt/t1wzknO+cg5H7lR2yYRsU7SSaSF\n",
       "iAaA8yNimaQTi9cXkNa8WCgpSCvD/XmXY+51J5MWg7+g7EDMbOryFZYdJLEnaebN/hHZiV4zs3EZ\n",
       "b9vE2lQs6nQB8BkXbjPrNhfvzvkkaQbN19rZ2f274ZyTnPORcz5yXtukAyR2Bz4FvLrTdw43MxuJ\n",
       "e94TVNxv8WfAv0dwbtnxmNnU4p5393yMtCDXgrIDMbPqcPGeAImNgc8CHxzrZe/u3w3nnOScj5zz\n",
       "kXPxnpjDgDsj+HXZgZhZtbjnPQES5wL3RvCPZcdiZlNTs9rp2SbjVNzo9xjgDWXHYmbV47bJ+B0A\n",
       "PBbBXeP5ZvfvhnNOcs5HzvnIuXiP3zzgkrKDMLNqcs97nCRuA/4igl+UHYuZTV2e591BErsA2wE3\n",
       "lh2LmVWTi/f4zCPd9X3ctzRz/2445yTnfOScj5yL9/jMA35QdhBmVl3ueY+RxHTg18CLIniq7HjM\n",
       "bGobd89b0lxJyyWtkHTKCK9Pl3S5pKWSbpd0Qodi7lVvAq5x4TazMo1avCUNAOcAc0m3O5svafeG\n",
       "3U4ClkTEvsAc4EuSpvLFPx1pmbh/N5xzknM+cs5HrtXIezawMiIGI2ItsIhUvOr9FtiyeLwl8EhE\n",
       "rOtsmL1BYlPgcOCysmMxs2prNUKeAdktvVYBr2nY52vAtZIeALYAju1ceD3ncGBpBA9P9EARcf3E\n",
       "w5lanJOc85FzPnKtinc7ZzM/DSyNiDmSdgGukrRPRDzWuKOkhcBgsbmm+L7ri9fmwNBfUG9uf/O/\n",
       "w7t/0DvxeNvb3p5q28XjE0gGaWLU2SaSDgTOiIi5xfZpwPqIOKtunx8BX4iInxfb1wCnRMTihmP1\n",
       "9WyTYiGqB4DXdWIJWElzPJLIOSc55yNX1XyMd7bJYmBXSbMkbQQcB1zasM9y4IjiTXYAdgPumXjI\n",
       "Pec1wMNeu9vMekHLed6SjgbOBgaA8yPiTEknAkTEAknTgQuAnUg/DM6MiP8zwnH6feR9FrAugs+U\n",
       "HYuZVUez2umLdNoksRx4bwQ3lR2LmVWHF6aaAIndSNMgF7fat/1jes5qI+ck53zknI+ci3d75gGX\n",
       "TmQhKjOzTnLbpA0SlwPnRngxKjObXG6bTMyLgd+UHYSZWY2Ld3u2Bx7q5AHdvxvOOck5HznnI+fi\n",
       "3UJxcc50Oly8zcwmwj3vFiS2BX4dwTZlx2Jm1eOe9/htDzxYdhBmZvVcvFvrSvF2/2445yTnfOSc\n",
       "j5yLd2seeZtZz3HPuwWJjwB7RfDhsmMxs+pxz3v8PPI2s57j4t1ax+d4g/t3I3FOcs5HzvnIuXi3\n",
       "5pG3mfUc97xbkPgJcHoE15cdi5lVj3ve4+eRt5n1nJbFW9JcScslrZB0ygivf0rSkuLrNknrJG3d\n",
       "nXBL4Xnek8Q5yTkfOecjN2rxljQAnAPMBfYA5kvavX6fiPiniNgvIvYDTgOuj4g13Qp4MklsSLoJ\n",
       "w+/LjsXMrF6rkfdsYGVEDEbEWmAR6cYEzbwLuKhTwfWA6cAj3bgJQxXvgt2Kc5JzPnLOR65V8Z4B\n",
       "3Fe3vap4bhhJmwFHAd/tTGg9wf1uM+tJ01q8PpapKG8BfjZay0TSQmCw2FwDLK39NK31s3pr+xMH\n",
       "wJce6tLxP9b7n3/St/eNiLN7KJ6yt52PCuajeHwCySBNjDpVUNKBwBkRMbfYPg1YHxFnjbDv94GL\n",
       "I2JRk2P13VRBiXcBb4lgfuePrTn+NTDnnOScj1xV89GsdrYq3tOAu4DDgQeAm4D5EbGsYb+tgHuA\n",
       "HSPiqbEE0MskPgbsHMFHy47FzKqpWe0ctW0SEesknQRcAQwA50fEMkknFq8vKHZ9K3BFs8Ldx9zz\n",
       "NrOe5CssRyFxHnBjBF/r/LGr+SvgaJyTnPORq2o+fIXl+HjkbWY9ySPvUUj8Evh4BL8oOxYzqyaP\n",
       "vMfHI28z60ku3qPrylre4HUaRuKc5JyPnPORc/FuQmIz0mycx8qOxcyskXveTUi8FLghgp3KjsXM\n",
       "qss977Fzv9vMepaLd3NdLd7u3w3nnOScj5zzkXPxbs4jbzPrWe55NyFxCvDCCE4uOxYzqy73vMeu\n",
       "a9MEzcwmysW7ue1wz3tSOSc55yPnfORcvJtzz9vMepZ73k1I/CfwoQh+VXYsZlZd7nmPnUfeZtaz\n",
       "WhZvSXMlLZe0QtIpTfaZI2mJpNslXd/xKCeZhOjyCUv374ZzTnLOR875yI16Jx1JA8A5wBHA/cDN\n",
       "ki6tvw2apK2BrwBHRcQqSdO7GfAk2Qp4KoKnyw7EzGwkrUbes4GVETEYEWuBRcC8hn3eBXw3IlYB\n",
       "RMTDnQ9z0nW9ZVLFO4K04pzknI+c85FrVbxnAPfVba8qnqu3K7CtpOskLZZ0fCcDLInneJtZT2tV\n",
       "vNuZirIhsD/wRuAo4HOSdp1oYCXr6hxvcP9uJM5JzvnIOR+5UXvepD73zLrtmaTRd737gIeLO8c/\n",
       "JemnwD7AisaDSVoIDBaba4CltV+Fan8xPbK9PfzHgPSeOd16P2BfSb3yeXtle1+gl+Ipe9v5qGA+\n",
       "iscnkAzSxKjzvCVNA+4CDgceAG4C5jecsHwl6aTmUcDGwI3AcRFxZ8Ox+maet8TngI0j+GzZsZhZ\n",
       "tTWrnaOOvCNinaSTgCuAAeD8iFgm6cTi9QURsVzS5cCtwHrga42Fuw9tzwi/OZiZ9QpfYTkCiYuB\n",
       "70ewqHvvoedbMpY4JznnI1fVfPgKy7Hx1ZVm1tM88h6BxB3AcRHcXnYsZlZtHnmPzXZ4nreZ9TAX\n",
       "7wYSA8A2wCPdfR/PWW3knOScj5zzkXPxHu6FwJoI1pUdiJlZM+55N5DYE7g4gleVHYuZmXve7fNM\n",
       "EzPreS7ew01K8Xb/bjjnJOd85JyPnIv3cB55m1nPc8+7gcTfAc9G8PmyYzEzc8+7fV1fDtbMbKJc\n",
       "vIdzz7skzknO+cg5HzkX7+Hc8zaznueedwOJFcCbIri77FjMzNzzbp9H3mbW81y860hsAmwKPNr9\n",
       "93L/rpFzknM+cs5HrmXxljRX0nJJKySdMsLrcyQ9KmlJ8dXPtw7bDngwoq0bL5uZlabVPSwHSPew\n",
       "PIJ0M+KbGX4PyznAJyLimFHfqA963hIHAOdFsF/ZsZiZwfh73rOBlRExGBFrgUXAvJGO34EYe4Hn\n",
       "eJtZX2hVvGcA99VtryqeqxfAQZJukfQjSXt0MsBJNmknK92/G845yTkfOecjN+rd46Gt3u9/AjMj\n",
       "4klJRwOXAK+YcGTl8EwTM+sLrYr3/cDMuu2ZpNH38yLisbrHP5b0r5K2jYjfNx5M0kJgsNhcAyyt\n",
       "3Q269lO13O3zD4APLJ2M96s911ufv/zt+tz0Qjxlbzsf1ctH8fiE4qMO0kSrE5bTSCcsDwceAG5i\n",
       "+AnLHYAHIyIkzQa+FRGzRjhWP5ywXAj8JIILyo7FzAzGecIyItYBJwFXAHcCF0fEMkknSjqx2O3t\n",
       "wG2SlgJnA+/sbOiTyj3vEjknOecj53zkWrVNiIgfAz9ueG5B3eOvAF/pfGilcM/bzPqC1zapI/Eb\n",
       "4NCI5n0mM7PJ5LVNWpAQaeT9UNmxmJm14uI9ZHPguQiemIw3c/9uOOck53zknI+ci/cQ97vNrG+4\n",
       "512QeC3w5QgOLDsWM7Ma97xb88jbzPqGi/eQSS3e7t8N55zknI+c85Fz8R7ikbeZ9Q33vAsS5wFL\n",
       "IqbMBUdmNgW45z2KYo73kcC1ZcdiZtYOF+9kN9INJZZP1hu6fzecc5JzPnLOR87FOzkKuML3rjSz\n",
       "fuGeNyDxI+DrEXyn7FjMzOo1q52VL94Sm5Bmmbw0gj+UHY+ZWT2fsGzuYOD2yS7c7t8N55zknI+c\n",
       "85Fz8S763WUHYWY2Fi2Lt6S5kpZLWiHplFH2e7WkdZL+tLMhdt1cSije9feytMQ5yTkfOecjN2rx\n",
       "ljQAnEMqcHsA8yXt3mS/s4DLSVPu+oLEDOAlwM1lx2JmNhatRt6zgZURMRgRa4FFwLwR9vtL4Dv0\n",
       "340M/gS4OoLnJvuN3b8bzjnJOR855yPXqnjPAO6r215VPPc8STNIBf3c4ql+mivtfreZ9aVWNyBu\n",
       "pxCfDZwaESFJjNI2kbQQnr8/5Bpgaa2PVfupOnnbm74Bfng0HPGpMt6/9lx5n783t+tz0wvxlL3t\n",
       "fFQvH8XjE4qPOkgTo87zlnQgcEZEzC22TwPWR8RZdfvcw1DBng48CXwoIi5tOFZPzfOWmE26MGfP\n",
       "smMxM2tmvPO8FwO7SpolaSPgOCAryhHxsojYOSJ2JvW9P9xYuHtUqS0T9++Gc05yzkfO+ciNWrwj\n",
       "Yh1wEqnI3QlcHBHLJJ0o6cTJCLCLSpkiaGbWCZW8PF5ia9KJ2O0jeKrseMzMmvHl8bnDgZ+7cJtZ\n",
       "v6pq8S59iqD7d8M5JznnI+d85CpXvIu75pRevM3MJqJyPW+JVwJXkpaA7acLisysgtzzHuK75phZ\n",
       "36ti8e6JKYLu3w3nnOScj5zzkatU8S7umnMwcE3ZsZiZTUSlet4SRwL/M4KDyozDzKxd7nknbwJ+\n",
       "XHYQZmYTVZniXUwRnAf8oOxYwP27kTgnOecj53zkKlO84fnVA28rNQozsw6oTM9b4jOktUw+WlYM\n",
       "ZmZj5Z53apn0w1K1ZmYtVaJ4S7wEeDnw07JjqXH/bjjnJOd85JyPXCWKN/Bm4PII1pYdiJlZJ1Si\n",
       "5y1xGXBhBIvKeH8zs/Ead89b0lxJyyWtkHTKCK/Pk3SLpCWSfiXpDZ0KuhMkNgdej+d3m9kUMmrx\n",
       "ljQAnENaD2QPYL6k3Rt2uzoi9omI/Uh3PP5qNwKdgCOBGyN4tOxA6rl/N5xzknM+cs5HrtXIezaw\n",
       "MiIGI2ItsIg0a+N5EfFE3ebmwMOdDXHCeubCHDOzTmlVvGeQ7vVYs6p4LiPprZKWkVoTf9W58CZG\n",
       "YoB0SfwPy46lUURcX3YMvcY5yTkfOecjN63F622dzYyIS4BLJL0euBDYbaT9JC0EBovNNcDS2l9I\n",
       "7Veizm5/ZC/4yv0R/KY7x/e2t73t7c5uF49PIBmkiVFnm0g6EDgjIuYW26cB6yPirFG+59fA7Ih4\n",
       "pOH5SZ9tIvFF4MkITp/M922HpDkeSeSck5zzkatqPsY722QxsKukWZI2Ao6j4SpFSbtIUvF4f4DG\n",
       "wl2iY/BVlWY2BbWc5y3paOBsYAA4PyLOlHQiQEQskHQy8F5gLfA48ImIuHmE40zqyLu4V+XVwEzf\n",
       "8szM+lWz2jllL9KROBmYFcFHJus9zcw6bdwX6fSxnm6ZeM7qcM5JzvnIOR+5KVm8JbYnrd99Xdmx\n",
       "mJl1w5Rsm0i8H3hjBO+YjPczM+uWqrVNerplYmY2UVOueEtsCrwBuKzsWEbj/t1wzknO+cg5H7kp\n",
       "V7yBOcAtEfy+7EDMzLplyvW8Jb4MPBTB33f7vczMuq1KPe8/Aa4sOwgzs26aUsVbYkdgB2BJ2bG0\n",
       "4v7dcM5JzvnIOR+5KVW8STdeuDqC58oOxMysm6ZUz1viIuCqCL7ezfcxM5ssU35tE4kNgNXA/hHZ\n",
       "DSTMzPpWFU5Y7keaZdIXhdv9u+Gck5zzkXM+clOpeHuWiZlVxlRqm1wHfDGCH3XrPczMJtuU7nlL\n",
       "bA78FnhRBE+02t/MrF9MqOctaa6k5ZJWSDplhNffLekWSbdK+rmkvTsR9BgcCizup8Lt/t1wzknO\n",
       "+cg5H7mWxVvSAHAOMBfYA5gvafeG3e4BDomIvYG/Bb7a6UBbcL/bzCqlnXtYvhY4ve4O8qcCRMQ/\n",
       "NNl/G+C2iNix4flutk2WAe+J4FfdOL6ZWVkm0jaZAdn0u1XFc838OUzeSUOJnYDp9MEl8WZmnTKt\n",
       "jX3aPqMp6TDgA8Drmry+EBgsNtcASyPi+uK1OQBj3YbYBbgadIg09u8vcftjnfj8U2x734g4u4fi\n",
       "KXvb+ahgPorHJ5AM0kQ7bZMDgTPq2ianAesj4qyG/fYGvgfMjYiVIxynK20TiYuByyO4oNPH7iZJ\n",
       "c2p/cZY4JznnI1fVfIx7qqCkacBdwOHAA8BNwPyIWFa3z07AtcB7IuKXYwlgIiQGgAeBfSJY1clj\n",
       "m5n1gma1s2XbJCLWSToJuAIYAM6PiGWSTixeXwD8DbANcK4kgLURMbuTH6CJ/YHfuXCbWdX09UU6\n",
       "Ep8Bpkfw8U4edzJU9VfA0TgnOecjV9V8TOginR52JJ7fbWYV1Lcjb4ktSD14XxJvZlPWVBx5Hwrc\n",
       "5MJtZlXUz8W7ry+J9zoNwzknOecj53zk+rJ4Swg4ij4u3mZmE9FXPW+J6cDxwAeBJ4HXRLC+E/GZ\n",
       "mfWivu15S2wgcbjEImAl6XZnHwZmu3CbWVW1s7ZJV0n8GfDKJi9vDhwLPA58DfhwBH+YrNi6qapz\n",
       "VkfjnOScj5zzkSuteEtsQlon/LXAJU12exZ4J+lGC5PT3zEz6wOl9LyLZVy/C9wLfCCCxyclCDOz\n",
       "PtMzPW+JI0iLWy0CjnPhNjMbu0kt3hKnAhcC8yP4UpVbIZ6zOpxzknM+cs5HbrJ73m8DXu1VAM3M\n",
       "JmZSe94Qm0TwzKS8oZnZFNATPW8XbjOzzmireEuaK2m5pBWSThnh9VdK+oWkpyV9svNhTj3u3w3n\n",
       "nOScj5zzkWtZvCUNkOZjzwX2AOZL2r1ht0eAvwT+qeMRTl37lh1AD3JOcs5Hzvmo087IezawMiIG\n",
       "I2ItaYrfvPodIuKhiFgMrO1CjFPV1mUH0IOck5zzkXM+6rRTvGcA99VtryqeMzOzkrRTvCs7F7vL\n",
       "ZpUdQA+aVXYAPWZW2QH0mFllB9BL2pnnfT8ws257JoxvnnaaLmg1kt5Xdgy9xjnJOR8552NIO8V7\n",
       "MbCrpFmke0YeB8xvsm/T9bo7fed4M7Mqa+siHUlHA2cDA8D5EXGmpBMBImKBpBcBNwNbAuuBx4A9\n",
       "IsLrlpiZdcGkXWFpZmad0/UrLFtd4FMFkr4uabWk2+qe21bSVZLulnSlpMpMg5I0U9J1ku6QdLuk\n",
       "vyqer2ROJG0i6UZJSyXdKenM4vlK5qNG0oCkJZJ+WGxXOh+Nulq827zApwouIOWg3qnAVRHxCuCa\n",
       "Yrsq1gIfj4hXAQcC/6P4d1HJnETE08BhEbEvsDdwmKSDqWg+6nwUuJOhGW9Vz0em2yPvlhf4VEFE\n",
       "3ADDbt92DPCN4vE3gLdOalAliojfRcTS4vHjwDLStQNVzsmTxcONSOeW/kCF8yFpR+CNwHkMTYSo\n",
       "bD5G0u3i7Qt8mtshIlYXj1cDO5QZTFmKWUz7ATdS4ZxI2kDSUtLnvi4i7qDC+QC+DPw1ZDcZr3I+\n",
       "hul28fbZ0DZEOmtcuVxJ2px0O7yPRsRj9a9VLScRsb5om+wIHCLpsIbXK5MPSW8GHoyIJTSZflyl\n",
       "fDTT7eLdsQt8pqDVxRRLJL0YeLDkeCaVpA1JhfvCiKjdgLrSOQGIiEeBy4ADqG4+DgKOkXQvcBHw\n",
       "BkkXUt18jKjbxfv5C3wkbUS6wOfSLr9nv7gUqF0t9j7gklH2nVIkCTgfuDMizq57qZI5kTS9NnNC\n",
       "0qbAkcASKpqPiPh0RMyMiJ2BdwLXRsTxVDQfzXR9nvdIF/h09Q17kKSLgEOB6aRe3d8APwC+BewE\n",
       "DALHRsSasmKcTMVMip8CtzL0q+9ppBtTVy4nkvYinYDboPi6MCK+KGlbKpiPepIOBT4ZEcc4Hzlf\n",
       "pGNm1ocm9TZoZmbWGS7eZmZ9yMXbzKwPuXibmfUhF28zsz7k4m1m1odcvM3aIGlObWlSs17g4m1m\n",
       "1odcvG1KkfSe4sYGSyT9W7Gg/+OS/rm48cPVkqYX++4r6ZeSbpH0vbpL1F9e7LdU0q8kvYx0Jejm\n",
       "kr4taZmkb5b5Oc1cvG3KKG7ocCxwUETsBzwHvBvYDLg5IvYEfgKcXnzLvwN/HRH7ALfVPf8fwL8U\n",
       "q/y9FvgtaXW7/Ug3CNgDeJmk103KBzMbQTt3jzfrF4eTVuNbnNa+YhPSynPrgYuLfb4JfE/SlsBW\n",
       "xY0yIK0t8u1imdqXRMQPACLiWYDieDdFxAPF9lJgFvDz7n8ss+FcvG2q+UZEfLr+CUmfq99k5HWg\n",
       "R1w3usEzdY+fw/9/rERum9hUcg3wdknbwfM3rH0p6d/5O4p93gXcEBF/BP5QrHAIcDxwfXFbtlWS\n",
       "5hXH2LilV7vRAAAAiElEQVRYptWsp3jkYFNGRCyT9FngSkkbAM8CJwFPALOL11aT1pWHtCb0v0na\n",
       "DPg18P7i+eOBBZI+XxzjWNJovXHE7iU5rTReEtamPEmPRcQWZcdh1klum1gVeIRiU45H3mZmfcgj\n",
       "bzOzPuTibWbWh1y8zcz6kIu3mVkfcvE2M+tDLt5mZn3o/wOu1Xk0xvr73QAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f55ff10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the model which consists of 3 conv layers followed by\n",
    "# 2 fully conntected layers\n",
    "\n",
    "# Sequential wrapper model\n",
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(Convolution2D(32, 1, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(Convolution2D(48, 32, 2, 2))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# third convolutional layer\n",
    "model.add(Convolution2D(32, 48, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# convert convolutional filters to flatt so they can be feed to \n",
    "# fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# first fully connected layer\n",
    "model.add(Dense(32*6*6, 128, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# second fully connected layer\n",
    "model.add(Dense(128, 128, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# last fully connected layer which output classes\n",
    "model.add(Dense(128, 9, init='lecun_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# setting sgd optimizer parameters\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "def scale(X, eps = 0.001):\n",
    "    # scale the data points s.t the columns of the feature space\n",
    "    # (i.e the predictors) are within the range [0, 1]\n",
    "    return (X - np.min(X, axis = 0)) / (np.max(X, axis = 0) + eps)\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "\n",
    "# scale the data to the range [0, 1] and then construct the training\n",
    "# and testing splits\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.8)\n",
    "(valX, testX, valY, testY) = train_test_split(testX, testY, test_size = 0.5)\n",
    "\n",
    "# reshape for convolutions\n",
    "trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "testX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    "valX = valX.reshape((valX.shape[0], 1, 28, 28))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "trainY = np_utils.to_categorical(trainY, nb_classes)\n",
    "testY = np_utils.to_categorical(testY, nb_classes)\n",
    "valY = np_utils.to_categorical(valY, nb_classes)\n",
    "\n",
    "print \"the shape of train set %s rows, %s columns\" %(trainX.shape[0], trainX.shape[1])\n",
    "print \"the shape of test set %s rows, %s columns\" %(testX.shape[0], testX.shape[1])\n",
    "print \"the shape of validation set %s rows, %s columns\" %(valX.shape[0], valX.shape[1])\n",
    "\n",
    "mm = model.fit(trainX, trainY,\n",
    "               batch_size=batch_size,\n",
    "               nb_epoch=nb_epoch,\n",
    "               show_accuracy=True,\n",
    "               verbose=1,\n",
    "               validation_data=(testX, testY))\n",
    "\n",
    "score = model.evaluate(valX, valY, show_accuracy=True, verbose=0, batch_size=batch_size)\n",
    "print 'Test score : %s' %score[0]\n",
    "print 'Test accuracy : %s' %score[1]\n",
    "\n",
    "df = pd.DataFrame(mm)\n",
    "df.index = df['epoch']\n",
    "df['acc'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train set 1800 rows, 1 columns\n",
      "the shape of test set 2100 rows, 1 columns\n",
      "the shape of validation set 2100 rows, 1 columns\n",
      "Train on 1800 samples, validate on 2100 samples\n",
      "Epoch 0\n",
      "1800/1800 [==============================] - 88s - loss: 2.1884 - acc.: 0.1483 - val. loss: 2.1703 - val. acc.: 0.1552\n",
      "Epoch 1\n",
      "1800/1800 [==============================] - 89s - loss: 2.1760 - acc.: 0.1522 - val. loss: 2.1655 - val. acc.: 0.1552\n",
      "Epoch 2\n",
      "1800/1800 [==============================] - 98s - loss: 2.1627 - acc.: 0.1578 - val. loss: 2.0856 - val. acc.: 0.2747\n",
      "Epoch 3\n",
      "1800/1800 [==============================] - 89s - loss: 2.1742 - acc.: 0.2100 - val. loss: 2.1699 - val. acc.: 0.1552\n",
      "Epoch 4\n",
      "1800/1800 [==============================] - 92s - loss: 2.1578 - acc.: 0.1617 - val. loss: 2.0579 - val. acc.: 0.2602\n",
      "Epoch 5\n",
      "1800/1800 [==============================] - 88s - loss: 1.3818 - acc.: 0.5406 - val. loss: 0.5892 - val. acc.: 0.8086\n",
      "Epoch 6\n",
      "1800/1800 [==============================] - 91s - loss: 0.6009 - acc.: 0.8444 - val. loss: 0.3554 - val. acc.: 0.9105\n",
      "Epoch 7\n",
      "1800/1800 [==============================] - 94s - loss: 0.4050 - acc.: 0.9061 - val. loss: 0.3316 - val. acc.: 0.9129\n",
      "Epoch 8\n",
      "1800/1800 [==============================] - 91s - loss: 0.3689 - acc.: 0.9089 - val. loss: 0.3231 - val. acc.: 0.9193\n",
      "Epoch 9\n",
      "1800/1800 [==============================] - 91s - loss: 0.3952 - acc.: 0.8978 - val. loss: 0.3786 - val. acc.: 0.9159\n",
      "Epoch 10\n",
      "1800/1800 [==============================] - 93s - loss: 0.3258 - acc.: 0.9133 - val. loss: 0.3084 - val. acc.: 0.9220\n",
      "Epoch 11\n",
      "1800/1800 [==============================] - 87s - loss: 0.3158 - acc.: 0.9278 - val. loss: 0.3321 - val. acc.: 0.9244\n",
      "Epoch 12\n",
      "1800/1800 [==============================] - 84s - loss: 0.2762 - acc.: 0.9350 - val. loss: 0.3153 - val. acc.: 0.9249\n",
      "Epoch 13\n",
      "1800/1800 [==============================] - 85s - loss: 0.2595 - acc.: 0.9367 - val. loss: 0.3814 - val. acc.: 0.9249\n",
      "Epoch 14\n",
      "1800/1800 [==============================] - 87s - loss: 0.2643 - acc.: 0.9344 - val. loss: 0.3453 - val. acc.: 0.9277\n",
      "Epoch 15\n",
      "1800/1800 [==============================] - 87s - loss: 0.2494 - acc.: 0.9372 - val. loss: 0.3345 - val. acc.: 0.9258\n",
      "Epoch 16\n",
      "1800/1800 [==============================] - 91s - loss: 0.2318 - acc.: 0.9444 - val. loss: 0.3561 - val. acc.: 0.9282\n",
      "Epoch 17\n",
      "1800/1800 [==============================] - 88s - loss: 0.2450 - acc.: 0.9428 - val. loss: 0.3398 - val. acc.: 0.9277\n",
      "Epoch 18\n",
      "1800/1800 [==============================] - 89s - loss: 0.2250 - acc.: 0.9383 - val. loss: 0.3524 - val. acc.: 0.9291\n",
      "Epoch 19\n",
      "1800/1800 [==============================] - 89s - loss: 0.2365 - acc.: 0.9417 - val. loss: 0.4050 - val. acc.: 0.9291\n",
      "Epoch 20\n",
      "1800/1800 [==============================] - 104s - loss: 0.2188 - acc.: 0.9450 - val. loss: 0.3918 - val. acc.: 0.9301\n",
      "Epoch 21\n",
      "1800/1800 [==============================] - 88s - loss: 0.2107 - acc.: 0.9478 - val. loss: 0.3902 - val. acc.: 0.9291\n",
      "Epoch 22\n",
      "1800/1800 [==============================] - 84s - loss: 0.2181 - acc.: 0.9467 - val. loss: 0.3876 - val. acc.: 0.9301\n",
      "Epoch 23\n",
      "1800/1800 [==============================] - 84s - loss: 0.2174 - acc.: 0.9433 - val. loss: 0.3894 - val. acc.: 0.9296\n",
      "Epoch 24\n",
      "1800/1800 [==============================] - 84s - loss: 0.2052 - acc.: 0.9494 - val. loss: 0.3952 - val. acc.: 0.9286\n",
      "Epoch 25\n",
      "1800/1800 [==============================] - 84s - loss: 0.2086 - acc.: 0.9467 - val. loss: 0.4171 - val. acc.: 0.9305\n",
      "Epoch 26\n",
      "1800/1800 [==============================] - 84s - loss: 0.1856 - acc.: 0.9522 - val. loss: 0.4361 - val. acc.: 0.9296\n",
      "Epoch 27\n",
      "1800/1800 [==============================] - 85s - loss: 0.1797 - acc.: 0.9544 - val. loss: 0.3969 - val. acc.: 0.9315\n",
      "Epoch 28\n",
      "1800/1800 [==============================] - 100s - loss: 0.1837 - acc.: 0.9572 - val. loss: 0.4184 - val. acc.: 0.9291\n",
      "Epoch 29\n",
      "1800/1800 [==============================] - 84s - loss: 0.1822 - acc.: 0.9550 - val. loss: 0.4622 - val. acc.: 0.9286\n",
      "Epoch 30\n",
      "1800/1800 [==============================] - 90s - loss: 0.1839 - acc.: 0.9539 - val. loss: 0.4224 - val. acc.: 0.9305\n",
      "Epoch 31\n",
      "1800/1800 [==============================] - 86s - loss: 0.1705 - acc.: 0.9544 - val. loss: 0.4770 - val. acc.: 0.9301\n",
      "Epoch 32\n",
      "1800/1800 [==============================] - 86s - loss: 0.1652 - acc.: 0.9589 - val. loss: 0.4434 - val. acc.: 0.9296\n",
      "Epoch 33\n",
      "1800/1800 [==============================] - 85s - loss: 0.1770 - acc.: 0.9528 - val. loss: 0.4364 - val. acc.: 0.9315\n",
      "Epoch 34\n",
      "1800/1800 [==============================] - 84s - loss: 0.1699 - acc.: 0.9528 - val. loss: 0.4461 - val. acc.: 0.9295\n",
      "Epoch 35\n",
      "1800/1800 [==============================] - 85s - loss: 0.1510 - acc.: 0.9550 - val. loss: 0.4605 - val. acc.: 0.9291\n",
      "Epoch 36\n",
      "1800/1800 [==============================] - 89s - loss: 0.1610 - acc.: 0.9556 - val. loss: 0.4970 - val. acc.: 0.9290\n",
      "Epoch 37\n",
      "1800/1800 [==============================] - 86s - loss: 0.1603 - acc.: 0.9589 - val. loss: 0.4545 - val. acc.: 0.9291\n",
      "Epoch 38\n",
      "1800/1800 [==============================] - 84s - loss: 0.1547 - acc.: 0.9583 - val. loss: 0.5162 - val. acc.: 0.9291\n",
      "Epoch 39\n",
      "1800/1800 [==============================] - 85s - loss: 0.1487 - acc.: 0.9606 - val. loss: 0.5485 - val. acc.: 0.9282\n",
      "Epoch 40\n",
      "1800/1800 [==============================] - 93s - loss: 0.1483 - acc.: 0.9606 - val. loss: 0.5049 - val. acc.: 0.9296\n",
      "Epoch 41\n",
      "1800/1800 [==============================] - 96s - loss: 0.1561 - acc.: 0.9572 - val. loss: 0.5051 - val. acc.: 0.9286\n",
      "Epoch 42\n",
      "1800/1800 [==============================] - 98s - loss: 0.1492 - acc.: 0.9561 - val. loss: 0.5319 - val. acc.: 0.9285\n",
      "Epoch 43\n",
      "1800/1800 [==============================] - 86s - loss: 0.1538 - acc.: 0.9572 - val. loss: 0.5404 - val. acc.: 0.9281\n",
      "Epoch 44\n",
      "1800/1800 [==============================] - 99s - loss: 0.1475 - acc.: 0.9600 - val. loss: 0.5073 - val. acc.: 0.9277\n",
      "Epoch 45\n",
      "1800/1800 [==============================] - 90s - loss: 0.1505 - acc.: 0.9578 - val. loss: 0.5494 - val. acc.: 0.9301\n",
      "Epoch 46\n",
      "1800/1800 [==============================] - 85s - loss: 0.1447 - acc.: 0.9650 - val. loss: 0.5792 - val. acc.: 0.9315\n",
      "Epoch 47\n",
      "1800/1800 [==============================] - 86s - loss: 0.1448 - acc.: 0.9622 - val. loss: 0.4937 - val. acc.: 0.9291\n",
      "Epoch 48\n",
      "1800/1800 [==============================] - 94s - loss: 0.1450 - acc.: 0.9600 - val. loss: 0.5578 - val. acc.: 0.9296\n",
      "Epoch 49\n",
      "1800/1800 [==============================] - 85s - loss: 0.1415 - acc.: 0.9622 - val. loss: 0.5306 - val. acc.: 0.9277\n",
      "Test score : 0.497851541662\n",
      "Test accuracy : 0.926755536131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e14e390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEPCAYAAACNyEVOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAH+9JREFUeJzt3X+UXHWZ5/H3h4QYA/IjBoFJAi0YFVwlqBMj7gxBdGzd\n",
       "0XjcGTH4ixGdHM/g6ODORlBHXMdVzjqCI+rEkTGu7BBlVYadFVFRFFkEggkEk2iitiYEQ0DCDwFJ\n",
       "zLN/3Ft0fetHVyddVfdW3c/rnDpd36qbuk8/SZ7+9nO/915FBGZmNlgOKDoAMzPbdy7eZmYDyMXb\n",
       "zGwAuXibmQ0gF28zswHk4m1mNoA6Fm9J/yJph6T1E2zzj5I2S7pN0sndDdHMzBpNZub9eWC03ZuS\n",
       "XgE8LSIWAH8JfKZLsZmZWRsdi3dEXA/cN8EmrwK+kG97E3CYpCO7E56ZmbXSjZ73XGBr3XgbMK8L\n",
       "n2tmZm1064ClGsY+597MrIemd+Ez7gTm143n5a8lJLmgm5nth4honCB3pXhfBZwDrJa0GNgVETsm\n",
       "G0BVSbogIi4oOo4ycU5SzkeqqvloN/HtWLwlXQ6cCsyRtBX4AHAgQESsjIivS3qFpC3Ab4G/6F7Y\n",
       "Q22k6ABKaKToAEpmpOgASmak6ADKpGPxjohlk9jmnO6EY2Zmk+EzLIuzqugASmhV0QGUzKqiAyiZ\n",
       "VUUHUCbq180YJIV73mZm+6Zd7fTMuyCSlhQdQ9k4JynnI+V8pFy8zcy6QOJQiZMljpaY1vP9uW1i\n",
       "ZkWTEHAQcDjNJ/3V/A64O6IcJwFKzAROAU7PH88CxoAjgCcDO4HtdY9fA/fkr++se34PMC3/c0cA\n",
       "c9Lnem+v1nmbWQOJGcBRwB8ATwLuJf+PGsEjXdzPIcAJwIn516cCPwVuBH4YwT3d2leb/YusUB0D\n",
       "HFv3mE+2pHh3w+Mx4PdkRbq+UM0B9gK78vdbeSJwsMRW4JcNjx3Aw2TLlR9ueH4AMKvucVDd16eQ\n",
       "/R0dnX+tPZ4CPEhaZGvP9wB/BCwGfgx8GzgPuDGCR/O8HAgc2fCZR5H9PTV+30/Ov/dWhX1n29x7\n",
       "5l0MSUsi4rqi4yiTsudEYhbZf8hWM6QjSAvAoWQFZTvwEDC7brvdjP8HvY+2ReczI/D2bWRFsPaY\n",
       "kT9GyArBocBPgI3ABrKZ3zOBFwKL8hhuBH4I/Ihs9trKE0gLSv3XQ+r2fWDD8zn591NfSH+VPx5r\n",
       "iL32mE5WpJNCFcHDE6Q/73nHzTT/oDiWrNi2K9B7W+eXh4G7gbtIZ8h35XEd3CIXRwAzgf8HfC+C\n",
       "+yeKeTIkDgCi3W8U7WqnZ95WKRKHAy8gK1a1/7Q7ItjdsN3BwMnA84Hn5V+PJfvPvpPmGdJmGv7z\n",
       "R7C3xf5FVhRqBeFw2hadA2eStRAeAR5gfOa6G/gqWbHe2mo/+b6mkRX4F5LNEs+m/f/53aSzvZ1k\n",
       "M/h7gPtpnj3Xnt8bwQNtPrPr8gK/KX/02oNkf5c91e7vrxPPvK2l/D/+kWT/gB/qVZ8xby/MJ5tN\n",
       "1f+KWT+LnUM2Y6yfNdW+3k82y0t+jY7goXxGUytetcc84FayYlj7/CPI2hp3kc1UazO7O4A1+eNW\n",
       "YEMEe3qRB7N22tVOF28DHp8RPh14CdnBlyVkM6uDyH5NfICsUO7Kv95FNvvZQPYr++aI5l/J8xls\n",
       "7Vfb+l93R/KvR+Sf9Suyywlvb/G4h2ym3Dg7nUU2c231a/QjZAeBdpK1DWqtg/WNBVhiOtmv3Ufn\n",
       "j23Ajxtn42ZFcPEumW70d/OZ5ZPI+p6HkhWsncADE82UJQ5ifGZ7HHAaWcHeC1ybP74TwfZ8+wPJ\n",
       "+p6HAoflX+eRHSCrPUbICvDG/HNqRfSJtJgZM94bvbNWTLvV885/EM0h6yP29IBdL5X9GEC/VTUf\n",
       "7nkPqLwQPZOsuL4YOJ7xInowWetgF9nMeBZZ0ZopJcuQ7iObodbaETMZn9X+Cvg+8PfAllZFP5+B\n",
       "3ps/2sU5A1hAVshhvEDv7PfSrnx/bY/Smw0Dz7xLSGI+42tHX0zWvqjNiDcw3rp4IKJ5WVW+/nQO\n",
       "40fIZwO/Ybxg7yrLWlkzm5jbJgNAYjHwYeAk4Dtk60evBX7uYmtWTb62ScnUX6dB4tkSVwJXAJcD\n",
       "R0fw2gg+G8HPqlK4fe2KlPORcj5SLt4Fkjhe4jKyGfb3gAURfM6rHMysk47FW9KopE2SNkta0eL9\n",
       "wyV9TdJtkm6S9KzehDo8JI6GeB1wE9nZcU+L4KLaqbVVVcWVBBNxPlLOR2rC4i1pGnAJMEp2ssMy\n",
       "SSc0bHY+8KOIOAl4E/CJXgRaJhLT8iuHPVfipfla5sn8uSdKvBdYT3bK9DMi+FAED/Y0YDMbOp1m\n",
       "3ouALRExFhG7gdXA0oZtTgC+CxARPwFGJB3R9UgLJHG2xFUSt0jcCTwKrAMuJbun568kPi1xUps/\n",
       "f4DEmWQntSwEFoH+PaL90rsqck8z5XyknI9Up3Xec4GtdeNtZNeFqHcb8BrgB5IWkZ2YMY8hWWcr\n",
       "cQTwMeBtZGuim66FITGP7LoR/y6xDVgJfDmChyVOAS4i+0H5hgiuz//MMf39TsxsmHQq3pNZ5fBR\n",
       "4BOS1pK1A9bS5pKOklaRXfUMsrXK62p9rNpP1bKNIU4FrgDdA8yKiG2N20ewTdL34KAfwEMHAcvh\n",
       "25+QHtoCr34KcD7M2Aa7p9WntP6MsbJ8v0WP63NThniKHjsf1ctH/vys/Fsdo40J13lLWgxcEBGj\n",
       "+fg8YG9EXDjBn/kF8OyIeKjh9YFb552f7PJL4LQINuzjnz2W7Jq/X4vgt72Iz8yG3/6u814DLJA0\n",
       "ImkGcAZwVcMHH5q/h6S3Ad9rLNwD7A3ArftauAEi+GUEl7Ur3O7fNXNOUs5HyvlITdg2iYg9ks4B\n",
       "riG7QtulEbFR0vL8/ZVkq1BWSQqyS2ie3eOY+yK/psi5wDuKjsXMrJFPj29DYhS4EFhYlTMczax8\n",
       "fHr8vns38HEXbjMrIxfvFiSeQ3Yn6Mt7tw/37xo5JynnI+V8pFy8W/sb4JIIHis6EDOzVtzzbpBd\n",
       "d4QNwPER/KboeMys2tzznry/Av7VhdvMyszFu05+b8flwMW935f7d42ck5TzkXI+Ui7eqTcBN0Sw\n",
       "uehAzMwm4p53Lr8T+ybgrRF8v+h4zMzAPe/J+FOyO7BfX3QgZmaduHiPGwUu69dJOe7fNXNOUs5H\n",
       "yvlIuXiPO4rseuVmZqXnnndO4gbgPbWbJZiZlYF73p0dCewoOggzs8lw8R7X1+Lt/l0z5yTlfKSc\n",
       "j5SLN4+fnDOdbLWJmVnpuecNSBwHfCeCkaJjMTOrt989b0mjkjZJ2ixpRYv350j6hqR1ku6QdFaX\n",
       "Yu4n97vNbKBMWLwlTQMuIVsDfSKwTNIJDZudA6yNiIXAEuAfJHW6K33Z9L14u3/XzDlJOR8p5yPV\n",
       "aea9CNgSEWMRsRtYDSxt2OYu4JD8+SHAvRGxp7th9tyRwK+LDsLMbLI6zZDnAlvrxtuAFzRs88/A\n",
       "dyRtB54EvLZ74fXNUfR55h0R1/Vzf4PAOUk5HynnI9WpeE/maOb5wLqIWCLpeOBbkk6KiAcbN5S0\n",
       "ChjLh7vyP3dd/t4SGP8L6vP4SLhot3TukpLE47HHHld0nD8/i8wYbUy42kTSYuCCiBjNx+cBeyPi\n",
       "wrptvg58OCJuyMfXAisiYk3DZ5V5tclXgNURXNG/ferxHxSWcU5SzkeqqvnY39Uma4AFkkYkzQDO\n",
       "AK5q2GYT8JJ8J0cCzwB+PvWQ+8qrTcxsoHRc5y3p5WR3lpkGXBoRH5G0HCAiVkqaA3weOIbsh8FH\n",
       "IuJfW3xOmWfem4H/FMFPi47FzKxeu9rpk3QAiQeBeRHcX3QsZmb1fGGqNiRmAQfS51PjvWa1mXOS\n",
       "cj5Szkeq8sWbvN/dr5swmJl1Q+XbJhKLgX+MYFHRsZiZNXLbpL2j8NmVZjZgXLwLWibo/l0z5yTl\n",
       "fKScj5SLt9d4m9kAcs9bfArYFMEni47FzKyRe97teeZtZgPHxbugA5bu3zVzTlLOR8r5SLl4e+Zt\n",
       "ZgPIPW/xAHBMBLuKjsXMrJF73i3kp8bPAF/TxMwGS6WLN1nL5O4iTo13/66Zc5JyPlLOR8rF22dX\n",
       "mtkAqnTPW2Ip8NYIXll0LGZmrbjn3ZpXmpjZQOpYvCWNStokabOkFS3e/y+S1uaP9ZL2SDqsN+F2\n",
       "XWHF2/27Zs5JyvlIOR+pCYu3pGnAJcAocCKwTNIJ9dtExMci4uSIOBk4D7guIgZl2d1ReOZtZgOo\n",
       "08x7EbAlIsYiYjewGlg6wfZnApd3K7g+KOyAZRXvgt2Jc5JyPlLOR6pT8Z4LbK0bb8tfayJpFvAy\n",
       "4CvdCa0v3PM2s4E0vcP7+7IU5ZXADyZqmUhaBYzlw13AutpP01o/q7/jq0dgdEdB+39X8d9/6cYL\n",
       "I+LiEsVT9Nj5qGA+8udnkRmjjQmXCkpaDFwQEaP5+Dxgb0Rc2GLbrwFfiojVbT6rjEsFHwCOjeC+\n",
       "/u9bS/xrYMo5STkfqarmo13t7FS8pwM/AU4HtgM3A8siYmPDdocCPwfmRcQj+xJAUSSeSDb7n+mb\n",
       "D5tZWbWrnRO2TSJij6RzgGuAacClEbFR0vL8/ZX5pq8GrmlXuEvKd403s4FV2TMsJV4AXBLBHxaz\n",
       "/2r+CjgR5yTlfKSqmg+fYdnMK03MbGBVeeb9l8ALIji76FjMzNrxzLuZryhoZgOr6sW7sLaJr9PQ\n",
       "zDlJOR8p5yPl4m1mNoCq3PO+Hnh/BNcVHYuZWTvueTfzzNvMBlbVi3dhByzdv2vmnKScj5Tzkapk\n",
       "8ZaYCcwkOz3ezGzgVLLnLXEs8IMI5hcdi5nZRNzzTvkOOmY20KpavAs/WOn+XTPnJOV8pJyPVJWL\n",
       "t8+uNLOBVdWe9/uAWRGcX3QsZmYTcc87VXjbxMxsKjoWb0mjkjZJ2ixpRZttlkhaK+kOSdd1Pcru\n",
       "K/yApft3zZyTlPORcj5SE95JR9I04BLgJcCdwC2Srqq/DZqkw4BPAS+LiG2S5vQy4C7xzNvMBlqn\n",
       "mfciYEtEjEXEbmA1sLRhmzOBr0TENoCIuKf7YXZd4Qcsq3hHkE6ck5TzkXI+Up2K91xga914W/5a\n",
       "vQXAbEnflbRG0hu7GWCPeOZtZgOtU/GezFKUA4HnAq8AXga8X9KCqQbWK/mp8bOA+4qNw/27Rs5J\n",
       "yvlIOR+pCXveZH3u+lPI55PNvuttBe7J7xz/iKTvAycBmxs/TNIqYCwf7gLW1X4Vqv3F9HoM8Qvg\n",
       "btCpUu/3124MLJRU2P5LOl4IlCmeosfORwXzkT8/i8wYbUy4zlvSdOAnwOnAduBmYFnDActnkh3U\n",
       "fBnwBOAm4IyI2NDwWaVY5y2xCPh0BM8vOhYzs07a1c4JZ94RsUfSOcA1wDTg0ojYKGl5/v7KiNgk\n",
       "6RvA7cBe4J8bC3fJuN9tZgOvcmdYSrwVOCWCtxQbh5b46HnKOUk5H6mq5sNnWI4r/AQdM7OpquLM\n",
       "+5PAzyK4uOhYzMw68cx7XOEn6JiZTVVVi3fhbROvWW3mnKScj5Tzkapi8XbP28wGXhV73ruA4yO4\n",
       "t+hYzMw6cc+b8pwab2Y2VZUq3sBTgLsj2Ft0IO7fNXNOUs5HyvlIVa14l+JgpZnZVFWq5y3xSuDt\n",
       "EbyiyDjMzCbLPe/MU4C7iw7CzGyqqla8nwyU4k4/7t81c05SzkfK+UhVsXh7iaCZDbyq9bw/B9wc\n",
       "wWeLjMPMbLLc887MBn5TdBBmZlNVteJdmraJ+3fNnJOU85FyPlIdi7ekUUmbJG2WtKLF+0sk3S9p\n",
       "bf54X29C7QrPvM1sKHS6h+U0sntYvoTsZsS30HwPyyXAuRHxqgl3VI6e93ZgUUTTTZTNzEppf3ve\n",
       "i4AtETEWEbuB1cDSVp/fhRh7SkKUqG1iZjYVnYr3XGBr3Xhb/lq9AE6RdJukr0s6sZsBdtEsYG8E\n",
       "jxQdCLh/14pzknI+Us5HasK7x5MV5k5+BMyPiIclvRy4Enj6lCPrPs+6zWxodCredwLz68bzIe0X\n",
       "R8SDdc+vlvRpSbMjounAoKRVwFg+3AWsq90NuvZTtVdjeMOfwJmPkl/WpNf76xxPejfsouMpy7g+\n",
       "N2WIp+ix81G9fOTPz8q/1THa6HTAcjrZAcvTge3AzTQfsDwSuDsiQtIi4MsRMdLiswo9YClxOvC+\n",
       "CE4rKgYzs321XwcsI2IPcA5wDbAB+FJEbJS0XNLyfLM/A9ZLWgdcDLyuu6F3TanaJu7fNXNOUs5H\n",
       "yvlIdWqbEBFXA1c3vLay7vmngE91P7Su8xpvMxsalbm2icR7gYMjOK+oGMzM9pWvbVKytomZ2VRU\n",
       "qXiXqm3i/l0z5yTlfKScj1SVirdn3mY2NKrU874BWBHBD4qKwcxsX7nnnc28S9M2MTObiqoV79K0\n",
       "Tdy/a+acpJyPlPORqkTxljgAOBy4r+hYzMy6oRI9b4nDgF9FcEgR+zcz219V73nPpkQtEzOzqapK\n",
       "8S7dwUr375o5JynnI+V8pKpUvD3zNrOhUZWe95nAKyNYVsT+zcz2V9V73qVrm5iZTUVVinfpDli6\n",
       "f9fMOUk5HynnI1WV4u2Zt5kNlY7FW9KopE2SNktaMcF2fyhpj6TXdDfErijdAcv6e1laxjlJOR8p\n",
       "5yM1YfGWNA24BBgFTgSWSTqhzXYXAt8ACrv41ARK1zYxM5uKTjPvRcCWiBiLiN3AamBpi+3eAfxv\n",
       "YGeX4+uW0rVN3L9r5pyknI+U85HqVLznAlvrxtvy1x4naS5ZQf9M/lJ/1h7uG8+8zWyodLoB8WQK\n",
       "8cXAeyIiJIkJ2iaSVgFj+XAXsK7Wx6r9VO3R+Mnw7GdKd8zt0/46jmuvlSWesozrc1OGeIoeOx/V\n",
       "y0f+/Kz8Wx2jjQlP0pG0GLggIkbz8XnA3oi4sG6bnzNesOcADwNvi4irGj6rkJN0JKYDjwJPiOD3\n",
       "/d6/mdlU7O9JOmuABZJGJM0AzgCSohwRx0XEUyPiqWR977c3Fu6CHQbcX7bC7f5dM+ck5XyknI/U\n",
       "hG2TiNgj6RzgGmAacGlEbJS0PH9/ZR9inKrSHaw0M5uqob+2icQLgYsiWNzvfZuZTVWVr21SuhN0\n",
       "zMymqirFu3RtE/fvmjknKecj5XykqlC8vcbbzIZOFXrefw/8LoIP9XvfZmZTVfWed+naJmZmU1GF\n",
       "4l3Kton7d82ck5TzkXI+UlUo3p55m9nQqULP+0fA2yK4td/7NjObqqr3vEvXNjEzm4qqFO/StU3c\n",
       "v2vmnKScj5TzkRrq4i3xBGAG8GDRsZiZddNQ97wljgbWRnBUP/drZtYtVe15z6aELRMzs6ka9uJd\n",
       "2oOV7t81c05SzkfK+UhVoXh75m1mQ2fYe95nAy+K4C393K+ZWbfsd89b0qikTZI2S1rR4v2lkm6T\n",
       "tFbSrZJe3K2gu6C0bRMzs6mYsHhLmgZcAowCJwLLJJ3QsNm3I+KkiDiZ7I7Hn+1FoPuptAcs3b9r\n",
       "5pyknI+U85HqNPNeBGyJiLGI2A2sBpbWbxARv60bHgzc090Qp8QzbzMbSp2K91xga914W/5aQtKr\n",
       "JW0Ergb+unvhTVlpi3dEXFd0DGXjnKScj5TzkZrw7vHApI5mRsSVwJWS/gj4IvCMVttJWgWM5cNd\n",
       "wLraX0jtV6Lujq88Dpb+pnef77HHHnvc3XH+/CwyY7Qx4WoTSYuBCyJiNB+fB+yNiAsn+DM/AxZF\n",
       "xL0Nrxex2mQ98PoIbu/nfidD0hLPJFLOScr5SFU1H/u72mQNsEDSiKQZwBnAVQ0ffLwk5c+fC9BY\n",
       "uAtU2gOWZmZT0XGdt6SXAxcD04BLI+IjkpYDRMRKSf8VeBOwG3gIODcibmnxOX2deUsIeAQ4PIJH\n",
       "+rVfM7Nualc7h/YkHYmDgJ0RzOrXPs3Mum2/T9IZYKVumXjNajPnJOV8pJyP1DAX79IuEzQzm6ph\n",
       "bpu8GHhfBGU6Xd/MbJ9UsW3iKwqa2dAa9uJd2raJ+3fNnJOU85FyPlLDXLxLfcDSzGwqhrnn/Q/A\n",
       "XRF8rF/7NDPrtir2vGdT4raJmdlUDHPxLvUBS/fvmjknKecj5Xykhr14e+ZtZkNpmHveG4HXRLCx\n",
       "X/s0M+u2Kva8S902MTObiqEs3vkVBQ+nxMXb/btmzknK+Ug5H6mhLN7AIcAjEewuOhAzs14Yyp63\n",
       "xHHAtRE8tR/7MzPrlar1vL3G28yG2qSKt6RRSZskbZa0osX7r5d0m6TbJd0g6TndD3WflP5gpft3\n",
       "zZyTlPORcj5SHYu3pGnAJcAocCKwTNIJDZv9HPjjiHgO8CHgs90ONI2J4yXWS8xps4nXeJvZUJvM\n",
       "zHsRsCUixiJiN7AaWFq/QUTcGBH358ObgHndDbPJB8laIx9s837p2yZVvAt2J85JyvlIOR+pyRTv\n",
       "ucDWuvG2/LV2zga+PpWgJiLxbOClwIuAP5d4VovNSt82MTObiumT2GbSy1EknQa8haywtnp/FTCW\n",
       "D3cB62o/TWv9rE5jiHOBj4JG4KLV8K6PS4yCTq3bfjZ84gDpXUv29fP7OH7X/nz/Qz5eGBEXlyie\n",
       "osfORwXzkT8/i8wYbXRcKihpMXBBRIzm4/OAvRFxYcN2zwG+CoxGxJYWnzPlpYISp5C1bZ4ewaMS\n",
       "BwLrgXMjxmf7EpcB10Twxansr5ckPf6DxTLOScr5SFU1H1NZKrgGWCBpRNIM4AzgqoYPP4ascL+h\n",
       "VeHuhvysyf8OfDCCRwHyk3DOBT6eF/Ka0h+wrOI/wk6ck5TzkXI+Uh2Ld0TsAc4BrgE2AF+KiI2S\n",
       "lktanm/2d2Sno39G0lpJN/cg1j8BjgK+0PD61WS/Wry97rXSH7A0M5uKgTjDUuIA4BbgoxFc0eL9\n",
       "ZwHfBU6I4F6JLcDLI9g8paB7qKq/Ak7EOUk5H6mq5mPQz7D8z/nXr7R6M4IfA18GPpC/5Jm3mQ21\n",
       "0s+8JaYDdwDvjOCaCbabA2wETgPWATMi2Lu/8ZqZlcEgz7zfDPwa+OZEG0VwD/Bh4HPA/S7cZjbM\n",
       "Sl28JWaStULOi5jUevNPMyAtE1+noZlzknI+Us5HqtTFm2wFydoIbpzMxhE8BryTrG1iZja0StPz\n",
       "zmfZzwGenz+eB4wAL4rgjr4EaWZWMu1qZ9+Lt8QhwNPqHguAhcAzgJ8At5KdGLQGWB/B7/oSoJlZ\n",
       "CZWieEPsBA4CtjQ8bgduj+CRvgRTAlVdszoR5yTlfKSqmo92xXsyF6bqppOAX0/y4KOZmbVRmp63\n",
       "mZk1G+R13mZm1sDFuyBes9rMOUk5HynnI+XibWY2gNzzNjMrMfe8zcyGyKSKt6RRSZskbZa0osX7\n",
       "z5R0o6RHJb27+2EOH/fvmjknKecj5XykOhZvSdOAS4BR4ERgmaQTGja7F3gH8LGuRzi8FhYdQAk5\n",
       "JynnI+V81JnMzHsRsCUixiJiN9kNgJfWbxAROyNiDbC7BzEOq8OKDqCEnJOU85FyPupMpnjPBbbW\n",
       "jbflr5mZWUEmU7x9KntvjBQdQAmNFB1AyYwUHUDJjBQdQJlM5tomdwLz68bzyWbf+yy7OJXVSHpz\n",
       "0TGUjXOScj5Szse4yRTvNcACSSPAduAMYFmbbduu4/YabzOz7pnUSTqSXg5cDEwDLo2Ij0haDhAR\n",
       "KyUdBdwCHALsBR4EToyIh3oWuZlZhfXtDEszM+uenp9h2ekEnyqQ9C+SdkhaX/fabEnfkvRTSd+U\n",
       "VJllUJLmS/qupB9LukPSX+evVzInkmZKuknSOkkbJH0kf72S+aiRNE3SWkn/Jx9XOh+Nelq8J3mC\n",
       "TxV8niwH9d4DfCsing5cm4+rYjfwNxHxLGAx8Ff5v4tK5iQiHgVOi4iFZPdxPU3Sf6Si+ajzTmAD\n",
       "4yveqp6PRK9n3h1P8KmCiLgeuK/h5VcBX8iffwF4dV+DKlBE/Doi1uXPHwI2kp07UOWcPJw/nUF2\n",
       "bOk+KpwPSfOAVwCfY3whRGXz0Uqvi7dP8GnvyIjYkT/fARxZZDBFyVcxnQzcRIVzIukASevIvu/v\n",
       "RsSPqXA+gIuAvyVbAFFT5Xw06XXx9tHQSYjsqHHlciXpYOArwDsj4sH696qWk4jYm7dN5gF/LOm0\n",
       "hvcrkw9JfwrcHRFrabP8uEr5aKfXxbtrJ/gMoR35EkskHQ3cXXA8fSXpQLLC/cWIuDJ/udI5AYiI\n",
       "+4H/CzyP6ubjFOBVkn4BXA68WNIXqW4+Wup18X78BB9JM8hO8Lmqx/scFFcBtbPF3gxcOcG2Q0WS\n",
       "gEuBDRFxcd1blcyJpDm1lROSngi8FFhLRfMREedHxPyIeCrwOuA7EfFGKpqPdnq+zrvVCT493WEJ\n",
       "SbocOBWYQ9ar+zvg34AvA8cAY8BrI2JXUTH2U76S4vvA7Yz/6nsecDMVzImkZ5MdgDsgf3wxIv6H\n",
       "pNlUMB/1JJ0KvDsiXuV8pHySjpnZAPJt0MzMBpCLt5nZAHLxNjMbQC7eZmYDyMXbzGwAuXibmQ0g\n",
       "F2+zSZC0pHZpUrMycPE2MxtALt42VCS9Ib+xwVpJ/5Rf0P8hSR/Pb/zwbUlz8m0XSvqhpNskfbXu\n",
       "FPWn5dutk3SrpOPIzgQ9WNIVkjZKuqzI79PMxduGRn5Dh9cCp0TEycDvgdcDs4BbIuI/AN8DPpD/\n",
       "kf8J/G1EnASsr3v9fwGfzK/y90LgLrKr251MdoOAE4HjJL2oL9+YWQuTuXu82aA4nexqfGuya18x\n",
       "k+zKc3uBL+XbXAZ8VdIhwKH5jTIgu7bIFfllav8gIv4NICIeA8g/7+aI2J6P1wEjwA29/7bMmrl4\n",
       "27D5QkScX/+CpPfXD2l9HeiW141u8Lu657/H/3+sQG6b2DC5FvgzSUfA4zesPZbs3/mf59ucCVwf\n",
       "EQ8A9+VXOAR4I3Bdflu2bZKW5p/xhPwyrWal4pmDDY2I2CjpfcA3JR0APAacA/wWWJS/t4PsuvKQ\n",
       "XRP6nyTNAn4G/EX++huBlZL+W/4ZryWbrTfO2H1JTiuMLwlrQ0/SgxHxpKLjMOsmt02sCjxDsaHj\n",
       "mbeZ2QDyzNvMbAC5eJuZDSAXbzOzAeTibWY2gFy8zcwGkIu3mdkA+v9U3goWrdYs/wAAAABJRU5E\n",
       "rkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c0e1050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the model which consists of 3 conv layers followed by\n",
    "# 2 fully conntected layers\n",
    "\n",
    "# Sequential wrapper model\n",
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(Convolution2D(32, 1, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(Convolution2D(48, 32, 2, 2))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# third convolutional layer\n",
    "model.add(Convolution2D(32, 48, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# convert convolutional filters to flatt so they can be feed to \n",
    "# fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# first fully connected layer\n",
    "model.add(Dense(32*6*6, 128, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# second fully connected layer\n",
    "model.add(Dense(128, 128, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# last fully connected layer which output classes\n",
    "model.add(Dense(128, 9, init='lecun_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# setting sgd optimizer parameters\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "def scale(X, eps = 0.001):\n",
    "    # scale the data points s.t the columns of the feature space\n",
    "    # (i.e the predictors) are within the range [0, 1]\n",
    "    return (X - np.min(X, axis = 0)) / (np.max(X, axis = 0) + eps)\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "\n",
    "# scale the data to the range [0, 1] and then construct the training\n",
    "# and testing splits\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.7)\n",
    "(valX, testX, valY, testY) = train_test_split(testX, testY, test_size = 0.5)\n",
    "\n",
    "# reshape for convolutions\n",
    "trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "testX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    "valX = valX.reshape((valX.shape[0], 1, 28, 28))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "trainY = np_utils.to_categorical(trainY, nb_classes)\n",
    "testY = np_utils.to_categorical(testY, nb_classes)\n",
    "valY = np_utils.to_categorical(valY, nb_classes)\n",
    "\n",
    "print \"the shape of train set %s rows, %s columns\" %(trainX.shape[0], trainX.shape[1])\n",
    "print \"the shape of test set %s rows, %s columns\" %(testX.shape[0], testX.shape[1])\n",
    "print \"the shape of validation set %s rows, %s columns\" %(valX.shape[0], valX.shape[1])\n",
    "\n",
    "mm = model.fit(trainX, trainY,\n",
    "               batch_size=batch_size,\n",
    "               nb_epoch=nb_epoch,\n",
    "               show_accuracy=True,\n",
    "               verbose=1,\n",
    "               validation_data=(testX, testY))\n",
    "\n",
    "score = model.evaluate(valX, valY, show_accuracy=True, verbose=0, batch_size=batch_size)\n",
    "print 'Test score : %s' %score[0]\n",
    "print 'Test accuracy : %s' %score[1]\n",
    "\n",
    "df = pd.DataFrame(mm)\n",
    "df.index = df['epoch']\n",
    "df['acc'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train set 3000 rows, 1 columns\n",
      "the shape of test set 1500 rows, 1 columns\n",
      "the shape of validation set 1500 rows, 1 columns\n",
      "Train on 3000 samples, validate on 1500 samples\n",
      "Epoch 0\n",
      "3000/3000 [==============================] - 151s - loss: 2.1777 - acc.: 0.1540 - val. loss: 2.1739 - val. acc.: 0.1425\n",
      "Epoch 1\n",
      "3000/3000 [==============================] - 145s - loss: 1.9790 - acc.: 0.2783 - val. loss: 1.6423 - val. acc.: 0.3968\n",
      "Epoch 2\n",
      "3000/3000 [==============================] - 162s - loss: 1.2428 - acc.: 0.5650 - val. loss: 0.5846 - val. acc.: 0.8588\n",
      "Epoch 3\n",
      "3000/3000 [==============================] - 163s - loss: 0.6615 - acc.: 0.8010 - val. loss: 0.3414 - val. acc.: 0.9165\n",
      "Epoch 4\n",
      "3000/3000 [==============================] - 156s - loss: 0.4018 - acc.: 0.9000 - val. loss: 0.3038 - val. acc.: 0.9217\n",
      "Epoch 5\n",
      "3000/3000 [==============================] - 133s - loss: 0.3377 - acc.: 0.9150 - val. loss: 0.3096 - val. acc.: 0.9310\n",
      "Epoch 6\n",
      "3000/3000 [==============================] - 123s - loss: 0.3107 - acc.: 0.9197 - val. loss: 0.2853 - val. acc.: 0.9321\n",
      "Epoch 7\n",
      "3000/3000 [==============================] - 121s - loss: 0.3023 - acc.: 0.9273 - val. loss: 0.2841 - val. acc.: 0.9290\n",
      "Epoch 8\n",
      "3000/3000 [==============================] - 120s - loss: 0.2679 - acc.: 0.9323 - val. loss: 0.3051 - val. acc.: 0.9329\n",
      "Epoch 9\n",
      "3000/3000 [==============================] - 121s - loss: 0.2648 - acc.: 0.9303 - val. loss: 0.2770 - val. acc.: 0.9315\n",
      "Epoch 10\n",
      "3000/3000 [==============================] - 120s - loss: 0.2424 - acc.: 0.9370 - val. loss: 0.2984 - val. acc.: 0.9310\n",
      "Epoch 11\n",
      "3000/3000 [==============================] - 121s - loss: 0.2314 - acc.: 0.9410 - val. loss: 0.3454 - val. acc.: 0.9295\n",
      "Epoch 12\n",
      "3000/3000 [==============================] - 120s - loss: 0.2342 - acc.: 0.9390 - val. loss: 0.2826 - val. acc.: 0.9321\n",
      "Epoch 13\n",
      "3000/3000 [==============================] - 121s - loss: 0.2237 - acc.: 0.9383 - val. loss: 0.2931 - val. acc.: 0.9316\n",
      "Epoch 14\n",
      "3000/3000 [==============================] - 120s - loss: 0.2222 - acc.: 0.9407 - val. loss: 0.3144 - val. acc.: 0.9302\n",
      "Epoch 15\n",
      "3000/3000 [==============================] - 128s - loss: 0.2069 - acc.: 0.9477 - val. loss: 0.3044 - val. acc.: 0.9321\n",
      "Epoch 16\n",
      "3000/3000 [==============================] - 164s - loss: 0.2190 - acc.: 0.9377 - val. loss: 0.3042 - val. acc.: 0.9336\n",
      "Epoch 17\n",
      "3000/3000 [==============================] - 146s - loss: 0.1964 - acc.: 0.9480 - val. loss: 0.3099 - val. acc.: 0.9315\n",
      "Epoch 18\n",
      "3000/3000 [==============================] - 177s - loss: 0.2009 - acc.: 0.9497 - val. loss: 0.3216 - val. acc.: 0.9310\n",
      "Epoch 19\n",
      "3000/3000 [==============================] - 130s - loss: 0.2063 - acc.: 0.9447 - val. loss: 0.3315 - val. acc.: 0.9336\n",
      "Epoch 20\n",
      "3000/3000 [==============================] - 151s - loss: 0.1948 - acc.: 0.9460 - val. loss: 0.3138 - val. acc.: 0.9328\n",
      "Epoch 21\n",
      "3000/3000 [==============================] - 161s - loss: 0.2021 - acc.: 0.9450 - val. loss: 0.3089 - val. acc.: 0.9302\n",
      "Epoch 22\n",
      "3000/3000 [==============================] - 133s - loss: 0.1855 - acc.: 0.9480 - val. loss: 0.3381 - val. acc.: 0.9334\n",
      "Epoch 23\n",
      "3000/3000 [==============================] - 122s - loss: 0.1877 - acc.: 0.9527 - val. loss: 0.3509 - val. acc.: 0.9336\n",
      "Epoch 24\n",
      "3000/3000 [==============================] - 122s - loss: 0.1773 - acc.: 0.9510 - val. loss: 0.3453 - val. acc.: 0.9336\n",
      "Epoch 25\n",
      "3000/3000 [==============================] - 121s - loss: 0.1712 - acc.: 0.9600 - val. loss: 0.2916 - val. acc.: 0.9321\n",
      "Epoch 26\n",
      "3000/3000 [==============================] - 122s - loss: 0.1904 - acc.: 0.9493 - val. loss: 0.3135 - val. acc.: 0.9336\n",
      "Epoch 27\n",
      "3000/3000 [==============================] - 122s - loss: 0.1863 - acc.: 0.9493 - val. loss: 0.3011 - val. acc.: 0.9321\n",
      "Epoch 28\n",
      "3000/3000 [==============================] - 146s - loss: 0.1846 - acc.: 0.9530 - val. loss: 0.3346 - val. acc.: 0.9328\n",
      "Epoch 29\n",
      "3000/3000 [==============================] - 151s - loss: 0.1608 - acc.: 0.9533 - val. loss: 0.3427 - val. acc.: 0.9323\n",
      "Epoch 30\n",
      "3000/3000 [==============================] - 145s - loss: 0.1693 - acc.: 0.9520 - val. loss: 0.3296 - val. acc.: 0.9341\n",
      "Epoch 31\n",
      "3000/3000 [==============================] - 146s - loss: 0.1636 - acc.: 0.9563 - val. loss: 0.3606 - val. acc.: 0.9347\n",
      "Epoch 32\n",
      "3000/3000 [==============================] - 142s - loss: 0.1577 - acc.: 0.9543 - val. loss: 0.3829 - val. acc.: 0.9341\n",
      "Epoch 33\n",
      "3000/3000 [==============================] - 124s - loss: 0.1534 - acc.: 0.9563 - val. loss: 0.3159 - val. acc.: 0.9302\n",
      "Epoch 34\n",
      "3000/3000 [==============================] - 123s - loss: 0.1529 - acc.: 0.9577 - val. loss: 0.3670 - val. acc.: 0.9321\n",
      "Epoch 35\n",
      "3000/3000 [==============================] - 121s - loss: 0.1517 - acc.: 0.9573 - val. loss: 0.3411 - val. acc.: 0.9334\n",
      "Epoch 36\n",
      "3000/3000 [==============================] - 130s - loss: 0.1513 - acc.: 0.9533 - val. loss: 0.4086 - val. acc.: 0.9321\n",
      "Epoch 37\n",
      "3000/3000 [==============================] - 139s - loss: 0.1611 - acc.: 0.9567 - val. loss: 0.3624 - val. acc.: 0.9328\n",
      "Epoch 38\n",
      "3000/3000 [==============================] - 141s - loss: 0.1481 - acc.: 0.9583 - val. loss: 0.3773 - val. acc.: 0.9347\n",
      "Epoch 39\n",
      "3000/3000 [==============================] - 161s - loss: 0.1457 - acc.: 0.9597 - val. loss: 0.3819 - val. acc.: 0.9347\n",
      "Epoch 40\n",
      "3000/3000 [==============================] - 138s - loss: 0.1258 - acc.: 0.9610 - val. loss: 0.4029 - val. acc.: 0.9341\n",
      "Epoch 41\n",
      "3000/3000 [==============================] - 128s - loss: 0.1381 - acc.: 0.9580 - val. loss: 0.3737 - val. acc.: 0.9315\n",
      "Epoch 42\n",
      "3000/3000 [==============================] - 130s - loss: 0.1404 - acc.: 0.9607 - val. loss: 0.4252 - val. acc.: 0.9303\n",
      "Epoch 43\n",
      "3000/3000 [==============================] - 132s - loss: 0.1395 - acc.: 0.9620 - val. loss: 0.3654 - val. acc.: 0.9321\n",
      "Epoch 44\n",
      "3000/3000 [==============================] - 145s - loss: 0.1344 - acc.: 0.9577 - val. loss: 0.3967 - val. acc.: 0.9289\n",
      "Epoch 45\n",
      "3000/3000 [==============================] - 154s - loss: 0.1354 - acc.: 0.9620 - val. loss: 0.4238 - val. acc.: 0.9295\n",
      "Epoch 46\n",
      "3000/3000 [==============================] - 148s - loss: 0.1342 - acc.: 0.9623 - val. loss: 0.3823 - val. acc.: 0.9302\n",
      "Epoch 47\n",
      "3000/3000 [==============================] - 129s - loss: 0.1484 - acc.: 0.9567 - val. loss: 0.4135 - val. acc.: 0.9321\n",
      "Epoch 48\n",
      "3000/3000 [==============================] - 132s - loss: 0.1379 - acc.: 0.9587 - val. loss: 0.4222 - val. acc.: 0.9334\n",
      "Epoch 49\n",
      "3000/3000 [==============================] - 133s - loss: 0.1434 - acc.: 0.9580 - val. loss: 0.3295 - val. acc.: 0.9321\n",
      "Test score : 0.382670487636\n",
      "Test accuracy : 0.936662946429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x111a94e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEPCAYAAACNyEVOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAHytJREFUeJzt3Xu4XXV95/H3JycElDsEAUNojHJXBB3TeKlGYcqBR4lT\n",
       "FYyWMWrbzIxpdaZ2EMcqbWfG8tTO4BSVWCNxaGusSpE+RYMXwEsRiCSAkmACnjEXCHJJCCLk9p0/\n",
       "1tpm//bl7H3O2efstfb6vJ5nPWf/9l5n7e/5Jud7fvu7booIzMysXKb1OwAzMxs7F28zsxJy8TYz\n",
       "KyEXbzOzEnLxNjMrIRdvM7MS6li8JX1e0jZJ946yzv+RtEHS3ZLO7m2IZmbWqJuZ9zXAcLsXJV0A\n",
       "vCgiTgL+APhMj2IzM7M2OhbviPge8MQoq1wIfCFf93bgCEnH9iY8MzNrpRc971nAprrxZuCEHmzX\n",
       "zMza6NUOSzWMfc69mdkkmt6DbWwBZteNT8ifS0hyQTczG4eIaJwg96R43wAsBVZKmg9sj4ht3QZQ\n",
       "VZIuj4jL+x1HkTgnKecjVdV8tJv4dizekr4IvA6YKWkT8DHgAICIWBYRN0q6QNJG4JfAu3sX9kCb\n",
       "0+8ACmhOvwMomDn9DqBg5vQ7gCLpWLwjYlEX6yztTThmZtYNn2HZPyv6HUABreh3AAWzot8BFMyK\n",
       "fgdQJJqqmzFICve8zczGpl3t9My7TyQt6HcMReOcpJyPlPORcvE2Mysht03MrHAkpgEHA4fky6Fk\n",
       "k80twCMR7O1iGwcAxwJH5t9/SN3XQ/LtPwysA+6P4MlRtvUc4GTgVOAFwAxgKF+m1z1+CrgLWA1s\n",
       "iZj4CYvtaqeLt1Ve/ku+AHgr8EayX+blwD9F8EwfQ2spLyR7I9g1hu+ZDhxBWsDqC9lBwD5gb4vl\n",
       "CWADsCmCfV281wFkl82YCRyev2/j11Zx1MfzXOBpsmK4M/8K8HyyYvww2aU4assu4HjguPzr8fl7\n",
       "/QJ4vGE7teXpfHunAqcA24H1ZP/+P8tfOy1//Xjgwfy1B4Fn89zsacjV4cDLgVfk49XAnfnyEHA0\n",
       "cFSLr9Pzn2FXvu1d+xf9mYt3gUhaEBG39DuOIullTiSOJvsl3wHsaCx0EgcC55AV7AuBB4CvAP8M\n",
       "vBR4L/Ay4IvA8gjWjiOGA4HfIPvFr5+d1T/ey/6i0vB1/pvgh4+zv4DUvj4v/95ngMfIitNj+bKD\n",
       "rPjVCkOtOBwKPJlvu9X7PUs2sx1qsRwNnJR/fZCskNeWafnPWFtOzOPbRlY4d5AVxfqvO9rE8VTd\n",
       "+JeNfyhq/z/yvB5PdjZ3bTmQrDjWL492M0PPts00sjPFT82XuWSz/F8X8wj2dLOtfHvKt/eKumUm\n",
       "6b9X/dfdZLP5A/OvM/aP9REX7wIpe/GWOIjWM6rDyWZqdwMPdDNT27/NsedE4nDgdODFwBl1Xw8m\n",
       "Kx61uHaRFo9TgJ+QFezrIvh5i23PITvp7N35tr5ANuNrpVao59Ytx5JdtG0r2S9nq1nt9DzWFrPQ\n",
       "b/0Szr2H/QVkfb78P7JZ8mE0F+kjyApgrZjXCsSObgtZOxIHAy8kK+QnkbUR9ubx1C9bxlLoun//\n",
       "cv/OjJfbJgaAxBDZzPL1+XIqcCNwLbB6tB6dxPOAdwCLyQrmdlrPqmbm7zET+DFwD1kxv5dshlf/\n",
       "8bj2+GCyAvc08Ku65WmyAlGbac0inXEdBNxHVoh/XPd1c+1nyWdBzyX9IzMSwdYx5Oxc4OI81lZ2\n",
       "kxWuB+uWzeMtYhLqRb/Uys/FuwQkDgFeRDaj+vVHqgieHef2ppMV0FnAa8iK9WuBR4Cbge+QffRd\n",
       "CFxC1r+7Fvj7CEbybcwALiAr2AuAr5GdLHFrp1m1xBHAS4AzyYr5S8g+Zjd+VN5JVqQPAJ5DVmif\n",
       "U7ccQPYxeDPZR9n6XuejLnI2yFy8C0RiFnzk3fDfd5F+BD2CrPe6g6xfW/sovIv9xfwp2u7Y4DDg\n",
       "GLKe4/PY/0dgG3A7WcG+pdWMM5+dzicr4heRzWDvA95C9lF9BfDlCHb2NBlJDNX8WNyO85Gqaj7a\n",
       "1c5eXFWwsvKCdwxZEX2y1QwwX2cu2Yy3thwOZ28A/hX4EbCSbAa8uXknDSLdAXUwLXdqMINsh9Qj\n",
       "+fILsll7Vz3nPPbbgNskPgCcT7aD7FURbOwyJWY2RTzz7lJ+eNYZ7G8BnJkvsP/j/hOkO4n2AL+Z\n",
       "r3Mr8N18WT+WHXlmVl1um4xRfjTFa4DzgN8ma2v8lGzHW20H3D0RbMvXn0Ha6jiabGfanWSHGbkv\n",
       "a2Zj5uLdQd6eOBkYJivYryE7amFVvtw1lpMiOr9fNft3o3FOUs5Hqqr5cM+7jsSRZC2Q+uOCzyDb\n",
       "6bcK+Dzwzgie6FuQZmaj6DjzljQMXEl2ptXnIuKKhtePJCt2c8nO+HpPRPykxXb6OvPOz7j7b2TH\n",
       "6h5GdjRFbakdH7zV7Q0zK5JxzbwlDQFXkZ2gsAW4U9INEbGubrUPA3dFxL+TdArwqXz9Qsh3NL4f\n",
       "+CDwJbKjPR50kTazMut0Sdh5wMaIGImI3WSHtC1sWOc0suOHiYj7gTmSjul5pGMkMSTxHrKdjP+G\n",
       "7JC390XwQBEKt69N3Mw5STkfKecj1al4zyK7NkPN5vy5encDvwMgaR7Z9R1O6FWA4yFxAbCW7JoU\n",
       "F0Xw1gh+2s+YzMx6qdMOy25mqH8JfFLSGrJrV6yB1hfAkbQCstOuya6Fsba297j2V3Wi4zzkz8KH\n",
       "Pw1X/GvE3tt6uf1ejWvPFSWeoozrc1OEePo9dj6ql4/88eL8Rx2hjVF3WEqaD1weEcP5+DJgX+NO\n",
       "y4bv+Rnwkoh4quH5KdlhKfEJYGcEfzbZ72VmNtna1c5ObZPVwEmS5kiaQXakxg0NGz48fw1Jvw/c\n",
       "2li4p9h5wDf6+P5dcf+umXOScj5Szkdq1LZJROyRtJTs2OchYHlErJO0JH99GdmlQVdICrJD7t47\n",
       "yTG3lV3wieeT/dExMxtYA3WGZX50yXkRXDyZ72NmNlXG2zYpm/PIPiWYmQ20gSnedXc7KUXxdv+u\n",
       "mXOScj5SzkdqYIo32Q0+t0awpd+BmJlNtoHpeUt8DDg0gg9O1nuYmU21KvS83e82s8oYiOKdX+L1\n",
       "xcD3+h1Lt9y/a+acpJyPlPORGojiTbaj8vsRPNPvQMzMpsJA9LwlPgfcG8EnJ2P7Zmb9MrA97/z2\n",
       "Ze53m1mllL54k11PfC9wf78DGQv375o5JynnI+V8pAaheA8Dq4pwgwUzs6lS+p63xCpgWQTX9Xrb\n",
       "Zmb91q52lrp45/enfAQ4IYIdvdy2mVkRDOoOy9cBa8tYuN2/a+acpJyPlPORKnvx9lEmZlZJZW+b\n",
       "3Ae8K4I7e7ldM7OiGHfbRNKwpPWSNki6tMXrMyV9Q9JaST+WtLhHMXeIixOB5wF3TcX7mZkVyajF\n",
       "W9IQcBXZ4XinA4skndaw2lJgTUScBSwA/lpSp7vS98J5wE0Rre9UX3Tu3zVzTlLOR8r5SHWaec8D\n",
       "NkbESETsBlYCCxvWeQg4LH98GPBYROzpbZgtud9tZpXVqXjPAjbVjTfnz9X7W+AMSVuBu4H39y68\n",
       "1vK75pwD3DTZ7zVZIuKWfsdQNM5JyvlIOR+pTu2NbvZmfhhYGxELJL0Q+Kakl0bEzsYVJa0ARvLh\n",
       "9vz7bslfWwD7/4E6jE+Am/bAeadAPDSO7/fYY489LuQ4f7yYzAhtjHq0iaT5wOURMZyPLwP2RcQV\n",
       "devcCPyPiPhBPv42cGlErG7YVs+ONpH4LeAvI3h1L7bXD5IWeCaRck5SzkeqqvkY79Emq4GTJM2R\n",
       "NAO4GLihYZ31ZNfTRtKxwCnAgxMPeVSzgZ9P8nuYmRVWx+O8JZ0PXAkMAcsj4uOSlgBExDJJM4Fr\n",
       "gBPJ/hh8PCL+ocV2ejnz/hBwZARNhy6amQ2Sgbq2icSngZ9E8KlebM/MrKgG7domJ5IeBVM6Pma1\n",
       "mXOScj5SzkeqzMXbPW8zq6yytk22A3MjeLwX2zMzK6qBaZtIHE52fPoT/Y7FzKxfSle8yQ8TLPtt\n",
       "z9y/a+acpJyPlPORKmPxdr/bzCqvdD1vif8AvCyCP+hBWGZmhTYwPW98dqWZWSmL90C0Tdy/a+ac\n",
       "pJyPlPORKmvxLvUJOmZmE1XGnvfPgHMjeKAHYZmZFdpAXNskvwnD08BhETzbm8jMzIprUHZYHgc8\n",
       "PgiF2/27Zs5JyvlIOR+pshXvgdhZaWY2UWVrm1wMvDWCt/UoLDOzQhuUtoln3mZmdFG8JQ1LWi9p\n",
       "g6SmO9dI+qCkNflyr6Q9ko6YnHAHp3i7f9fMOUk5HynnIzVq8ZY0BFwFDAOnA4sknVa/TkR8IiLO\n",
       "joizgcuAWyJi+yTF67MrzczoPPOeB2yMiJGI2A2sBBaOsv47gC/2KrgWBuYEnSreBbsT5yTlfKSc\n",
       "j1Sn4j2LtFhuzp9rIum5wHnAV3sTWksD0zYxM5uI6R1eH8uhKG8Cvj9ay0TSCmAkH24H1tb+mtb6\n",
       "We3HJw7DikPhDb/obv3Cjz8wtp+/EuOzIuLKAsXT77HzUcF85I8XkxmhjVEPFZQ0H7g8Iobz8WXA\n",
       "voi4osW6/wR8KSJWttnWhA4VlDgVuCGCk8e7jSKRtMAfA1POScr5SFU1H+M6PV7SdOB+4BxgK3AH\n",
       "sCgi1jWsdzjwIHBCRPxqLAF0/wPw28B/jeDc8W7DzKxs2tXOUdsmEbFH0lJgFTAELI+IdZKW5K8v\n",
       "y1d9M7CqXeHuEfe7zcxypTnDUuLPgX0RXN67qPqnqh8BR+OcpJyPVFXzMQhnWHrmbWaWK9PM+zvA\n",
       "/4zgWz0My8ys0AZh5j2bATlBx8xsokpRvCWmMWDF29dpaOacpJyPlPORKkXxBo4BdkbwdL8DMTMr\n",
       "glL0vCVeAVwdwct7HJaZWaGVveftI03MzOq4ePeJ+3fNnJOU85FyPlIu3mZmJVSWnvdXgZURfLnH\n",
       "YZmZFZp73mZmA6QsxXugjvEG9+9acU5SzkfK+UgVvnhLHAQcCTzc71jMzIqi8D1viRcBN0UwdxLC\n",
       "MjMrtDL3vN3vNjNr0LF4SxqWtF7SBkmXtllngaQ1kn4s6ZYexziQxdv9u2bOScr5SDkfqVHvpCNp\n",
       "CLgKOBfYAtwp6Yb626BJOgL4FHBeRGyWNLPHMQ5k8TYzm4hOM+95wMaIGImI3cBKYGHDOu8AvhoR\n",
       "mwEi4tEexziQxbuKdwTpxDlJOR8p5yPVqXjPIj1Eb3P+XL2TgKMk3SxptaRLehkgA1q8zcwmolPx\n",
       "7uZQlAOAlwEXAOcBfyrppIkGVmcgi7f7d82ck5TzkXI+UqP2vMn63LPrxrPJZt/1NgGP5neO/5Wk\n",
       "7wIvBTY0bkzSCmAkH24H1tY+CtX+YdLxNGDvicCm1q+XdwycJakw8RRkfBZQpHj6PXY+KpiP/PFi\n",
       "MiO0Mepx3pKmA/cD5wBbgTuARQ07LE8l26l5HnAgcDtwcUTc17CtMR/nLXE0sDGCI8fyfWZmg6Jd\n",
       "7Rx15h0ReyQtBVYBQ8DyiFgnaUn++rKIWC/pG8A9wD7gbxsL9wQMZMvEzGyiCn2GpcRC4PcieNMk\n",
       "hdU3khZ473nKOUk5H6mq5qOsZ1h65m1m1kLRZ95/BTwawRWTFJaZWaF55m1mNkBcvPvEx6w2c05S\n",
       "zkfK+UgVvXi3Oq7czKzyCtvzlpgGPAscHMGuyYvMzKy4ytjzngnscOE2M2tW5OJ9HAN86zP375o5\n",
       "JynnI+V8pIpcvI8HHup3EGZmRVTknvdi4JwIen2JWTOz0ihjz/s4PPM2M2upyMV7oNsm7t81c05S\n",
       "zkfK+UgVuXgP9A5LM7OJKHLP+7vARyOyi6+bmVVRGXvex+OZt5lZS0Uu3gO9w9L9u2bOScr5SDkf\n",
       "qY7FW9KwpPWSNki6tMXrCyTtkLQmXz4y0aAkDiG7c8+TE92Wmdkg6nQPyyGye1ieS3Yz4jtpvofl\n",
       "AuC/RMSFo77RGHreEi8Cbopgbjfrm5kNqvH2vOcBGyNiJCJ2AyuBha2234MY6w30YYJmZhPVqXjP\n",
       "AjbVjTfnz9UL4FWS7pZ0o6TTexDXwO+sdP+umXOScj5Szkdq1LvHkxXmTu4CZkfE05LOB64HTp5g\n",
       "XAO9s9LMbKI6Fe8tZDdEqGm6OUJE7Kx7/HVJn5Z0VEQ83rgxSSuAkXy4HVhbuxt07a9qPj4ePnOQ\n",
       "9J8WtHm99OPac0WJpyjj+twUIZ5+j52P6uUjf7w4/1FHaKPTDsvpZDsszwG2AnfQvMPyWOCRiAhJ\n",
       "84B/jIg5LbY1lh2W1wDfj2B5N+ubmQ2qce2wjIg9wFJgFXAf8KWIWCdpiaQl+WpvBe6VtBa4Enh7\n",
       "D+Id+B2W7t81c05SzkfK+Uh1apsQEV8Hvt7w3LK6x58CPtXjuAZ+h6WZ2UQU8tomEtuAsyIGe/Zt\n",
       "ZtZJaa5tIjEdOAp4pN+xmJkVVeGKN/A84LEI9vY7kMnk/l0z5yTlfKScj1QRi/fA76w0M5uowvW8\n",
       "Jd4IvC+C86cgLDOzQitNzxufXWlm1lERi3cl2ibu3zVzTlLOR8r5SBWxePvelWZmHRSx530d8A8R\n",
       "fGUKwjIzKzT3vM3MBkgRi3clTo13/66Zc5JyPlLOR6pQxVtCVKR4m5lNRKF63hJHAD+P4LApCcrM\n",
       "rODK0vOuxGGCZmYTVbTiXZmdle7fNXNOUs5HyvlIFa14u99tZtaFjsVb0rCk9ZI2SLp0lPVeIWmP\n",
       "pN+ZQDyVaZvU38vSMs5JyvlIOR+pUYu3pCHgKmAYOB1YJOm0NutdAXwD6OqGC2347Eozsy50mnnP\n",
       "AzZGxEhE7AZWAgtbrPeHwFeAX0wwnsrMvN2/a+acpJyPlPOR6lS8ZwGb6sab8+d+TdIssoL+mfyp\n",
       "iRx7WJkdlmZmE9HpBsTdFOIrgQ9FREgSo7RNJK0ARvLhdmBtrY+V/VW98YVw/sP7x/v7XIM2rj1X\n",
       "lHiKMq7PTRHi6ffY+ahePvLHi/MfdYQ2Rj1JR9J84PKIGM7HlwH7IuKKunUeZH/Bngk8Dfx+RNzQ\n",
       "sK1uTtJ5HDg5gkdHW8/MrCrGe5LOauAkSXMkzQAuBpKiHBFzI+IFEfECsr73f2ws3N0FyIHAIcDj\n",
       "Y/3eMnL/rplzknI+Us5HatS2SUTskbQUWAUMAcsjYp2kJfnry3oYy3HAtgj29XCbZmYDqTDXNpH4\n",
       "TeBvIpg3JQGZmZVAGa5t4rMrzcy6VLTiXZnDBN2/a+acpJyPlPORKlLx9tmVZmZdKlLP+7PAXRFc\n",
       "PSUBmZmVQBl63j670sysS0Uq3pXaYen+XTPnJOV8pJyPVNGKt2feZmZdKETPW2Ia8AxwaATPTklA\n",
       "ZmYlUPSe99HAThduM7PuFKV4V25npft3zZyTlPORcj5SRSneldpZaWY2UUXpeb8LODeCS6YkGDOz\n",
       "kih6z9tnV5qZjUFRinflDhN0/66Zc5JyPlLOR6ooxbtyOyzNzCaiKD3vW4HLI7h5SoIxMyuJcfe8\n",
       "JQ1LWi9pg6RLW7y+UNLdktZI+pGkN4wjvsq1TczMJmLU4i1pCLgKGAZOBxZJOq1htW9FxEsj4myy\n",
       "Ox5/dhxxVG6Hpft3zZyTlPORcj5SnWbe84CNETESEbuBlcDC+hUi4pd1w0NgbHd+lzgYOADYMZbv\n",
       "MzOrsk7FexawqW68OX8uIenNktYBXwf+aIwxHAc8FMHUNN8LIiJu6XcMReOcpJyPlPORGvXu8dBd\n",
       "QY2I64HrJf0WcC1wSqv1JK0ARvLhdmAtxB7g4dpHoto/kMcee+xxFcf548VkRmhj1KNNJM0HLo+I\n",
       "4Xx8GbAvIq4Y5XseAOZFxGMNz7fcYyrxNuDtEbylbSADSNICzyRSzknK+UhVNR/jPdpkNXCSpDmS\n",
       "ZgAXAzc0bPiFkpQ/fhlAY+HuoHI7K83MJmrUtklE7JG0FFgFDAHLI2KdpCX568uAtwD/XtJu4Cng\n",
       "7WOMoZKHCVZxBtGJc5JyPlLOR6rvJ+lIfB74QQTLpyQQM7MSKfKFqWYDW/sdxFTzMavNnJOU85Fy\n",
       "PlJ9Ld757c9eDtzVzzjMzMqmr20TidOAf4lg7pQEYWZWMkVtm8wHbutzDGZmpdPv4v1KKlq83b9r\n",
       "5pyknI+U85Fy8TYzK6G+9bwlDge2AEdGsHtKgjAzK5ki9rxfAdzlwm1mNnb9LN6Vbpm4f9fMOUk5\n",
       "HynnI+XibWZWQn3peUuI7KYNZ0T4olRmZu0Ured9MvCkC7eZ2fj0q3hXvmXi/l0z5yTlfKScj1Q/\n",
       "i/cP+/TeZmal16+e993A70Vw55S8uZlZSbW9nPZUF2+JQ8luvnBUBLum5M3NzEpqQjssJQ1LWi9p\n",
       "g6RLW7z+Tkl3S7pH0g8knTnK5uYBa6peuN2/a+acpJyPlPOR6li8JQ0BVwHDwOnAIkmnNaz2IPDa\n",
       "iDgT+Avgs6Ns0v1uM7MJ6mbmPQ/YGBEjEbEbWAksrF8hIm6LiB358HbghFG258vA4vvxteKcpJyP\n",
       "lPOR6qZ4zwI21Y0358+1817gxlYv5CfnuHibmU3QqHePz3W9R1PS64H3AK9uvcYxX4X3Tocrlkhs\n",
       "B9bW/prW+lkVGn+g4j9/q/FZEXFlgeLp99j5qGA+8seLyYzQRsejTSTNBy6PiOF8fBmwLyKuaFjv\n",
       "TOA6YDgiNrbYTkAsBs6P4O2jvmkFSFrgj4Ep5yTlfKSqmo9xHyooaTpwP3AO2V3e7wAWRcS6unVO\n",
       "BL4D/G5EtNwZmRfvq4H1EXxy3D+JmVmFtCveHdsmEbFH0lJgFTAELI+IdZKW5K8vAz4KHAl8RhLA\n",
       "7oiY12JzrwSuGf+PYWZmMMUn6UA8TXbnnEof4w3V/Qg4Guck5XykqpqPCZ2k00NrXbjNzCZuqmfe\n",
       "fx3BB6fkDc3MBkBRZt4+vtvMrAemunj7tPicr9PQzDlJOR8p5yM1pcU7gi1T+X5mZoOqL9fzNjOz\n",
       "7hSl521mZj3g4t0n7t81c05SzkfK+Ui5eJuZlZB73mZmBeaet5nZAHHx7hP375o5JynnI+V8pFy8\n",
       "zcxKyD1vM7MCc8/bzGyAdFW8JQ1LWi9pg6RLW7x+qqTbJD0j6Y97H+bgcf+umXOScj5SzkeqY/GW\n",
       "NARcBQwDpwOLJJ3WsNpjwB8Cn+h5hIPrrH4HUEDOScr5SDkfdbqZec8DNkbESETsBlYCC+tXiIhf\n",
       "RMRqYPckxDiojuh3AAXknKScj5TzUaeb4j0L2FQ33pw/Z2ZmfdJN8Z6aw1GqZ06/AyigOf0OoGDm\n",
       "9DuAgpnT7wCKpOPd44EtwOy68Wyy2feYZbdCsxpJ7+p3DEXjnKScj5TzsV83xXs1cJKkOcBW4GJg\n",
       "UZt12x7H7WO8zcx6p6uTdCSdD1wJDAHLI+LjkpYARMQySccBdwKHAfuAncDpEfHUpEVuZlZhU3aG\n",
       "pZmZ9c6kn2HZ6QSfKpD0eUnbJN1b99xRkr4p6aeSbpJUmcOgJM2WdLOkn0j6saQ/yp+vZE4kHSTp\n",
       "dklrJd0n6eP585XMR42kIUlrJP1zPq50PhpNavHu8gSfKriGLAf1PgR8MyJOBr6dj6tiN/CfI+IM\n",
       "YD7wvvz/RSVzEhHPAK+PiLOAM4HXS3oNFc1HnfcD97H/iLeq5yMx2TPvjif4VEFEfA94ouHpC4Ev\n",
       "5I+/ALx5SoPqo4h4OCLW5o+fAtaRnTtQ5Zw8nT+cQbZv6QkqnA9JJwAXAJ9j/4EQlc1HK5NdvH2C\n",
       "T3vHRsS2/PE24Nh+BtMv+VFMZwO3U+GcSJomaS3Zz31zRPyECucD+N/An5AdAFFT5Xw0mezi7b2h\n",
       "XYhsr3HlciXpEOCrwPsjYmf9a1XLSUTsy9smJwCvlfT6htcrkw9JbwQeiYg1tDn8uEr5aGeyi3fP\n",
       "TvAZQNvyQyyRdDzwSJ/jmVKSDiAr3NdGxPX505XOCUBE7AD+BXg51c3Hq4ALJf0M+CLwBknXUt18\n",
       "tDTZxfvXJ/hImkF2gs8Nk/yeZXEDUDtb7F3A9aOsO1AkCVgO3BcRV9a9VMmcSJpZO3JC0nOAfwus\n",
       "oaL5iIgPR8TsiHgB8HbgOxFxCRXNRzuTfpx3qxN8JvUNC0jSF4HXATPJenUfBb4G/CNwIjACXBQR\n",
       "2/sV41TKj6T4LnAP+z/6XgbcQQVzIuklZDvgpuXLtRHxV5KOooL5qCfpdcAfR8SFzkfKJ+mYmZWQ\n",
       "b4NmZlZCLt5mZiXk4m1mVkIu3mZmJeTibWZWQi7eZmYl5OJt1gVJC2qXJjUrAhdvM7MScvG2gSLp\n",
       "d/MbG6yRdHV+Qf+nJP2v/MYP35I0M1/3LEk/lHS3pOvqTlF/Ub7eWkk/kjSX7EzQQyR9WdI6SX/X\n",
       "z5/TzMXbBkZ+Q4eLgFdFxNnAXuCdwHOBOyPixcCtwMfyb/m/wJ9ExEuBe+ue/3vgb/Kr/L0SeIjs\n",
       "6nZnk90g4HRgrqRXT8kPZtZCN3ePNyuLc8iuxrc6u/YVB5FdeW4f8KV8nb8DrpN0GHB4fqMMyK4t\n",
       "8uX8MrXPj4ivAUTELoB8e3dExNZ8vBaYA/xg8n8ss2Yu3jZovhARH65/QtKf1g9pfR3olteNbvBs\n",
       "3eO9+PfH+shtExsk3wbeKukY+PUNa3+D7P/52/J13gF8LyKeBJ7Ir3AIcAlwS35bts2SFubbODC/\n",
       "TKtZoXjmYAMjItZJ+ghwk6RpwC5gKfBLYF7+2jay68pDdk3oqyU9F3gAeHf+/CXAMkl/nm/jIrLZ\n",
       "euOM3ZfktL7xJWFt4EnaGRGH9jsOs15y28SqwDMUGzieeZuZlZBn3mZmJeTibWZWQi7eZmYl5OJt\n",
       "ZlZCLt5mZiXk4m1mVkL/HwN5FiGGtjxNAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c57d950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the model which consists of 3 conv layers followed by\n",
    "# 2 fully conntected layers\n",
    "\n",
    "# Sequential wrapper model\n",
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(Convolution2D(32, 1, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(Convolution2D(48, 32, 2, 2))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# third convolutional layer\n",
    "model.add(Convolution2D(32, 48, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# convert convolutional filters to flatt so they can be feed to \n",
    "# fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# first fully connected layer\n",
    "model.add(Dense(32*6*6, 128, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# second fully connected layer\n",
    "model.add(Dense(128, 128, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# last fully connected layer which output classes\n",
    "model.add(Dense(128, 9, init='lecun_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# setting sgd optimizer parameters\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "def scale(X, eps = 0.001):\n",
    "    # scale the data points s.t the columns of the feature space\n",
    "    # (i.e the predictors) are within the range [0, 1]\n",
    "    return (X - np.min(X, axis = 0)) / (np.max(X, axis = 0) + eps)\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "\n",
    "# scale the data to the range [0, 1] and then construct the training\n",
    "# and testing splits\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.5)\n",
    "(valX, testX, valY, testY) = train_test_split(testX, testY, test_size = 0.5)\n",
    "\n",
    "# reshape for convolutions\n",
    "trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "testX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    "valX = valX.reshape((valX.shape[0], 1, 28, 28))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "trainY = np_utils.to_categorical(trainY, nb_classes)\n",
    "testY = np_utils.to_categorical(testY, nb_classes)\n",
    "valY = np_utils.to_categorical(valY, nb_classes)\n",
    "\n",
    "print \"the shape of train set %s rows, %s columns\" %(trainX.shape[0], trainX.shape[1])\n",
    "print \"the shape of test set %s rows, %s columns\" %(testX.shape[0], testX.shape[1])\n",
    "print \"the shape of validation set %s rows, %s columns\" %(valX.shape[0], valX.shape[1])\n",
    "\n",
    "mm = model.fit(trainX, trainY,\n",
    "               batch_size=batch_size,\n",
    "               nb_epoch=nb_epoch,\n",
    "               show_accuracy=True,\n",
    "               verbose=1,\n",
    "               validation_data=(testX, testY))\n",
    "\n",
    "score = model.evaluate(valX, valY, show_accuracy=True, verbose=0, batch_size=batch_size)\n",
    "print 'Test score : %s' %score[0]\n",
    "print 'Test accuracy : %s' %score[1]\n",
    "\n",
    "df = pd.DataFrame(mm)\n",
    "df.index = df['epoch']\n",
    "df['acc'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of train set 3420 rows, 1 columns\n",
      "the shape of test set 1290 rows, 1 columns\n",
      "the shape of validation set 1290 rows, 1 columns\n",
      "Train on 3420 samples, validate on 1290 samples\n",
      "Epoch 0\n",
      "3420/3420 [==============================] - 150s - loss: 2.1782 - acc.: 0.1550 - val. loss: 2.1755 - val. acc.: 0.1499\n",
      "Epoch 1\n",
      "3420/3420 [==============================] - 150s - loss: 2.1425 - acc.: 0.2096 - val. loss: 1.9116 - val. acc.: 0.3308\n",
      "Epoch 2\n",
      "3420/3420 [==============================] - 157s - loss: 1.5503 - acc.: 0.4126 - val. loss: 0.8621 - val. acc.: 0.8539\n",
      "Epoch 3\n",
      "3420/3420 [==============================] - 141s - loss: 1.0735 - acc.: 0.6120 - val. loss: 0.4641 - val. acc.: 0.8784\n",
      "Epoch 4\n",
      "3420/3420 [==============================] - 140s - loss: 0.7830 - acc.: 0.7535 - val. loss: 0.3412 - val. acc.: 0.9219\n",
      "Epoch 5\n",
      "3420/3420 [==============================] - 138s - loss: 0.5168 - acc.: 0.8579 - val. loss: 0.2784 - val. acc.: 0.9308\n",
      "Epoch 6\n",
      "3420/3420 [==============================] - 140s - loss: 0.4313 - acc.: 0.8898 - val. loss: 0.2965 - val. acc.: 0.9360\n",
      "Epoch 7\n",
      "3420/3420 [==============================] - 139s - loss: 0.3774 - acc.: 0.9076 - val. loss: 0.2660 - val. acc.: 0.9330\n",
      "Epoch 8\n",
      "3420/3420 [==============================] - 142s - loss: 0.3598 - acc.: 0.9137 - val. loss: 0.2809 - val. acc.: 0.9353\n",
      "Epoch 9\n",
      "3420/3420 [==============================] - 141s - loss: 0.3327 - acc.: 0.9132 - val. loss: 0.2513 - val. acc.: 0.9382\n",
      "Epoch 10\n",
      "3420/3420 [==============================] - 141s - loss: 0.3320 - acc.: 0.9187 - val. loss: 0.2783 - val. acc.: 0.9353\n",
      "Epoch 11\n",
      "3420/3420 [==============================] - 143s - loss: 0.3146 - acc.: 0.9216 - val. loss: 0.2618 - val. acc.: 0.9353\n",
      "Epoch 12\n",
      "3420/3420 [==============================] - 136s - loss: 0.2903 - acc.: 0.9243 - val. loss: 0.2577 - val. acc.: 0.9368\n",
      "Epoch 13\n",
      "3420/3420 [==============================] - 141s - loss: 0.2878 - acc.: 0.9266 - val. loss: 0.2640 - val. acc.: 0.9368\n",
      "Epoch 14\n",
      "3420/3420 [==============================] - 135s - loss: 0.2742 - acc.: 0.9269 - val. loss: 0.2599 - val. acc.: 0.9382\n",
      "Epoch 15\n",
      "3420/3420 [==============================] - 133s - loss: 0.2662 - acc.: 0.9342 - val. loss: 0.2385 - val. acc.: 0.9390\n",
      "Epoch 16\n",
      "3420/3420 [==============================] - 133s - loss: 0.2637 - acc.: 0.9322 - val. loss: 0.2520 - val. acc.: 0.9382\n",
      "Epoch 17\n",
      "3420/3420 [==============================] - 134s - loss: 0.2471 - acc.: 0.9327 - val. loss: 0.2426 - val. acc.: 0.9353\n",
      "Epoch 18\n",
      "3420/3420 [==============================] - 133s - loss: 0.2595 - acc.: 0.9354 - val. loss: 0.2664 - val. acc.: 0.9382\n",
      "Epoch 19\n",
      "3420/3420 [==============================] - 133s - loss: 0.2686 - acc.: 0.9351 - val. loss: 0.2450 - val. acc.: 0.9368\n",
      "Epoch 20\n",
      "3420/3420 [==============================] - 133s - loss: 0.2448 - acc.: 0.9365 - val. loss: 0.2618 - val. acc.: 0.9382\n",
      "Epoch 21\n",
      "3420/3420 [==============================] - 133s - loss: 0.2398 - acc.: 0.9395 - val. loss: 0.2579 - val. acc.: 0.9345\n",
      "Epoch 22\n",
      "3420/3420 [==============================] - 133s - loss: 0.2423 - acc.: 0.9374 - val. loss: 0.2524 - val. acc.: 0.9390\n",
      "Epoch 23\n",
      "3420/3420 [==============================] - 133s - loss: 0.2265 - acc.: 0.9406 - val. loss: 0.2531 - val. acc.: 0.9405\n",
      "Epoch 24\n",
      "3420/3420 [==============================] - 133s - loss: 0.2263 - acc.: 0.9383 - val. loss: 0.2432 - val. acc.: 0.9412\n",
      "Epoch 25\n",
      "3420/3420 [==============================] - 134s - loss: 0.2133 - acc.: 0.9442 - val. loss: 0.2497 - val. acc.: 0.9405\n",
      "Epoch 26\n",
      "3420/3420 [==============================] - 133s - loss: 0.2231 - acc.: 0.9465 - val. loss: 0.2723 - val. acc.: 0.9420\n",
      "Epoch 27\n",
      "3420/3420 [==============================] - 133s - loss: 0.2196 - acc.: 0.9406 - val. loss: 0.2710 - val. acc.: 0.9382\n",
      "Epoch 28\n",
      "3420/3420 [==============================] - 133s - loss: 0.2246 - acc.: 0.9450 - val. loss: 0.2460 - val. acc.: 0.9397\n",
      "Epoch 29\n",
      "3420/3420 [==============================] - 133s - loss: 0.2114 - acc.: 0.9421 - val. loss: 0.2703 - val. acc.: 0.9420\n",
      "Epoch 30\n",
      "3420/3420 [==============================] - 133s - loss: 0.2280 - acc.: 0.9409 - val. loss: 0.2451 - val. acc.: 0.9420\n",
      "Epoch 31\n",
      "3420/3420 [==============================] - 153s - loss: 0.2029 - acc.: 0.9480 - val. loss: 0.2831 - val. acc.: 0.9435\n",
      "Epoch 32\n",
      "3420/3420 [==============================] - 146s - loss: 0.2100 - acc.: 0.9447 - val. loss: 0.2552 - val. acc.: 0.9420\n",
      "Epoch 33\n",
      "3420/3420 [==============================] - 147s - loss: 0.1936 - acc.: 0.9488 - val. loss: 0.2612 - val. acc.: 0.9420\n",
      "Epoch 34\n",
      "3420/3420 [==============================] - 142s - loss: 0.2002 - acc.: 0.9459 - val. loss: 0.2669 - val. acc.: 0.9420\n",
      "Epoch 35\n",
      "3420/3420 [==============================] - 163s - loss: 0.1915 - acc.: 0.9459 - val. loss: 0.2410 - val. acc.: 0.9420\n",
      "Epoch 36\n",
      "3420/3420 [==============================] - 219s - loss: 0.2021 - acc.: 0.9468 - val. loss: 0.2470 - val. acc.: 0.9420\n",
      "Epoch 37\n",
      "3420/3420 [==============================] - 145s - loss: 0.1762 - acc.: 0.9512 - val. loss: 0.3059 - val. acc.: 0.9435\n",
      "Epoch 38\n",
      "3420/3420 [==============================] - 139s - loss: 0.1892 - acc.: 0.9482 - val. loss: 0.2590 - val. acc.: 0.9442\n",
      "Epoch 39\n",
      "3420/3420 [==============================] - 141s - loss: 0.1829 - acc.: 0.9515 - val. loss: 0.2465 - val. acc.: 0.9449\n",
      "Epoch 40\n",
      "3420/3420 [==============================] - 144s - loss: 0.1817 - acc.: 0.9515 - val. loss: 0.3160 - val. acc.: 0.9420\n",
      "Epoch 41\n",
      "3420/3420 [==============================] - 179s - loss: 0.1803 - acc.: 0.9494 - val. loss: 0.2649 - val. acc.: 0.9427\n",
      "Epoch 42\n",
      "3420/3420 [==============================] - 146s - loss: 0.1871 - acc.: 0.9497 - val. loss: 0.2528 - val. acc.: 0.9420\n",
      "Epoch 43\n",
      "3420/3420 [==============================] - 151s - loss: 0.1774 - acc.: 0.9515 - val. loss: 0.3107 - val. acc.: 0.9420\n",
      "Epoch 44\n",
      "3420/3420 [==============================] - 140s - loss: 0.1651 - acc.: 0.9573 - val. loss: 0.2822 - val. acc.: 0.9435\n",
      "Epoch 45\n",
      "3420/3420 [==============================] - 188s - loss: 0.1611 - acc.: 0.9526 - val. loss: 0.3485 - val. acc.: 0.9449\n",
      "Epoch 46\n",
      "3420/3420 [==============================] - 144s - loss: 0.1910 - acc.: 0.9503 - val. loss: 0.2977 - val. acc.: 0.9435\n",
      "Epoch 47\n",
      "3420/3420 [==============================] - 145s - loss: 0.1693 - acc.: 0.9535 - val. loss: 0.2720 - val. acc.: 0.9412\n",
      "Epoch 48\n",
      "3420/3420 [==============================] - 138s - loss: 0.1643 - acc.: 0.9553 - val. loss: 0.2655 - val. acc.: 0.9412\n",
      "Epoch 49\n",
      "3420/3420 [==============================] - 144s - loss: 0.1569 - acc.: 0.9567 - val. loss: 0.3504 - val. acc.: 0.9435\n",
      "Test score : 0.422514762865\n",
      "Test accuracy : 0.930952380952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e1d75d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEPCAYAAACNyEVOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAHxJJREFUeJzt3Xu4XHV97/H3hx3CRe6EBkyC4U6iQPASwRsBcg5bPBJP\n",
       "jxVjpaX1eHJ6TGtPrU/EFqHaPsgp7eFUrE0VDMUKeKFAH0W8YNT6VC6aAEqCCbDPSQiEi4Q7kpDv\n",
       "+WOtYc9vZs+efZnZs9asz+t51rPnN7P2mu98A9/9m++6KSIwM7Ny2aXXAZiZ2fi5eJuZlZCLt5lZ\n",
       "Cbl4m5mVkIu3mVkJuXibmZVQ2+It6QpJWyXdPco6fydpg6Q7JZ3Y2RDNzKzRWGbeXwQGW70o6Uzg\n",
       "yIg4CvhvwOc6FJuZmbXQtnhHxI+AJ0ZZ5SzgynzdW4H9JM3sTHhmZjaSTvS8ZwGb6sabgdkd2K6Z\n",
       "mbXQqR2Wahj7nHszsy6a1oFtPAjMqRvPzp9LSHJBNzObgIhonCB3pHjfCCwHrpF0ErAtIraONYCq\n",
       "knRhRFzY6ziKxDlJOR+pquaj1cS3bfGWdDVwCjBD0ibgAmBXgIhYGRHflHSmpI3As8DvdS7svja3\n",
       "1wEU0NxeB1Awc3sdQMHM7XUARdK2eEfE0jGss7wz4ZiZ2Vj4DMveWdXrAApoVa8DKJhVvQ6gYFb1\n",
       "OoAi0VTdjEFSuOdtZjY+rWqnZ949ImlRr2MoGuck5XyknI+Ui7eZWQm5bWJmVmCtamcnjvM2M+sb\n",
       "EgcDxwFbgF9GsH2K338XYC9gb2CfVuu5ePeIpEURsbrXcRSJc5JyPlLdyIfEXsDrgDcCC/PlFcBd\n",
       "wCuBQyXuA34O/CJf1gEPA9siWl8KRELAAcChZGehHwzsD+yXL/WP9yUr1Hvn7/888BTwdKvtu3ib\n",
       "9bm8iBxIdhG5R4GtEbzUwe3vQlac5tUtRwMvkF0qY3P+s7ZsBWaQFbXG5WBa7ou7aVeJB4HHR1ie\n",
       "BQby363/OQDsyXChrC+YBwKHAHcCtwHXASuA+2tFWWJ34FjgNcCryU5CPAaYCewh8SjwCLz889dk\n",
       "lwipfZ4Xgf+XLw+TXaF1G9nF/GqPn8x/Pk1WsJ+p//eRRv4D4Z63WR2J6WQF5CDgNxqW/YD1ZP+j\n",
       "/yyCZ9tsa1fgiHxbDwEPRvD8BGLahax4nAqcBrwV2E5WEDYxXBxqBeKVZMWzfhFZET2IbDb4CGlh\n",
       "fQzY2SKEacDuIyx7kBWqY8gK0Lp8WQ/cC+xG9gejfplNVvgebYi7tjwELf+wTM9jP3CEZc/8917K\n",
       "P0f9z+cYLpS1n7XHD0TwYov3G5XEbgz/d1L7uQfD/yabInhqIttO32fk2unibX1HYhrZjGpPsiI1\n",
       "4tfbvCgew/DX5TcC88lmcrWZVG15lGxWNC9f7zXARuBWsmK+nuz07drM81jgcLLi+AjZH4RXkhWS\n",
       "+qL5KNmssbY8V/f4SLJifQpZsfk+cAvwg/wjzKF55noIea82X+7Nfz5eN5vcNV+vVkxnkc2EW3mJ\n",
       "7Gv8C3XL82SzzIeA9RE8Ocrv2yS4eBeM+5nJjpl9gH3hTwbhbx9juKDUlgPJZnYjfV3eTvo1tfbV\n",
       "+1GyAnMQ2WzoMdJCPBN4PfArhgvwbcCaCJ4bQ+y7AcczXPSPBoZIZ5+/jOCFut+ptS/qP98Msj8y\n",
       "r2hevrwD3vdlYHVEcs38Sqrq/zMu3gXT6/8Q8z3qp5EVsGcZuTA+TfaVeTrZxcjqf+5NViQPyX/W\n",
       "P96D4a+s9cvO/LXaXvQ9yWaaT2XLDS/Akp+T9kdrX+n3YeSvy9PJZrH1X7231H8Vbvh6W/uK+yvg\n",
       "tggenXQyu6TX/40UTVXz4eJdcRJ7A28DFufLbGA18BOy/uVIhXEvspntdrIdL/WPnyH7yvxww8+t\n",
       "DO88ql9qO5Dq96I/E9Gyz2pmuHiXXt5iOJDs637jzrTaeHfSvey1x3uSfa2/Hfhuvvwsgh1T+ynM\n",
       "bLxcvAum9hUwL8oHke48OoThFkTt52+QzVa30rwjrfbzedK97LXHLwJ3jaWX20tV/VrcivORqmo+\n",
       "fIZlj+WHoL2arMf8erjhTRL7kBXmp0h7vFuAOxhuRzxMdmzur3sRu5kVT9uZt6RB4FKyr99fiIiL\n",
       "G17fH7iC7LCoF4Dfj4hfjLCdvpp5S+xHdpTBa8l24tX3hWs/dwVOIDuD6zXA/WRF+adkZ3BtItu5\n",
       "9kLj9s3MYIJtE0kDZMeJLiabEd4OLI2IdXXr/DXwVER8StIxwGcjYvFYAyiDvLVxLHBy3XIoWRG+\n",
       "naxdMdIRGTuBu8kK9tp2J3WYmTWaaNtkIbAxIobyjVwDLCE7jrVmHvBpgIi4V9JcSQdFRGEPwRoP\n",
       "idOBlWQ7//49X/4euHsyF6ypav9uNM5JyvlIOR+pdsV7FiQnB2wmaxXUuxP4TeDfJC0EXkW2463U\n",
       "xTtvi1wC/EfgDyL4Ro9DMjN7WbviPZZDUT4N/B9Ja8haBGtocW0CSavIzkKD7HTftbW/pLW7ZBRh\n",
       "LPEu+PbnYeuP4ZzXRPBUp9+v9lwRPm+RxvW5KUI8vR47H9XLR/743PyjDtFCu573ScCFETGYj88D\n",
       "djbutGz4nQeA4yLimYbnC9/zlpgJfAZYAPzXCH7Y45DMrOJa1c52t0G7Azgq72NPB84GbmzY8L75\n",
       "a0j6IPCDxsJdBhJnkR0Bch9wQrcLd+NMwpyTRs5HyvlIjdo2iYgdkpYDN5MdKnh5RKyTtCx/fSXZ\n",
       "VdhWSQqyC5Z/oMsxd5zEW4EvAO+M4NZex2Nm1k7lz7CUOBr4IfA7EXy71/GYmdWbaNukr0kcBHwD\n",
       "ON+F28zKpLLFO7+90fXA1yL4/NS/v/t3jZyTlPORcj5SlSze+RmTV5Idw/5nPQ7HzGzcKtnzlriI\n",
       "7NrWp/u6ImZWZL6qYE7ig8C7gZNduM2srCrVNpE4GfgUcGYEj/U2FvfvGjknKecj5XykKlW8gfcD\n",
       "fxPBhl4HYmY2GZXqeUusB5ZGsKaXcZiZjVXlj/OWmA3MILsKoplZqVWmeAOnA7cU5W7l7t81c05S\n",
       "zkfK+UhVqXgvJrtruplZ6VWi5y0hspv6viWC+3oRg5nZRFS95z2P7ObI9/c6EDOzTqhK8V4MfC9i\n",
       "THcGmhLu3zVzTlLOR8r5SFWleJ+O+91m1kf6vuctMQ14DDg6gkem+v3NzCZjwj1vSYOS1kvaIGnF\n",
       "CK/PkPQtSWsl/VzSuR2KuVNeD/xfF24z6yejFm9JA8BlwCDZ7c6WSprXsNpyYE1ELAAWAX8jqUgX\n",
       "vCrkIYLu3zVzTlLOR8r5SLWbeS8ENkbEUERsB64BljSs8xCwT/54H+DxiNjR2TAnZTHwvV4HYWbW\n",
       "Se1myLPIblhQsxl4Y8M6nwdukbQF2Bt4T+fCmxyJV5C1Tbp6J/iJiIjVvY6haJyTlPORcj5S7Yr3\n",
       "WPZmfhxYGxGLJB0BfEfSCRHxdOOKklYBQ/lwW/57q/PXFsHwP1Bnxh95A1yyJoJnurN9jz322OPO\n",
       "jvPH55IZooVRjzaRdBJwYUQM5uPzgJ0RcXHdOt8E/ioifpyPvwesiIg7GrY15UebSPwv4NkI/mIq\n",
       "33csJC3yTCLlnKScj1RV8zHRo03uAI6SNFfSdOBs4MaGddaT9ZWRNBM4huKcyeh+t5n1pbbHeUt6\n",
       "O3ApMABcHhEXSVoGEBErJc0AvggcSvbH4KKI+PII25nSmbfEDOA+YEYE26fqfc3MOqlV7ezbk3Qk\n",
       "fgs4N4J3TNV7mpl1WhUvTFXoU+J9zGoz5yTlfKScj1Q/F+9CnpxjZtYJfdk2kZgL3AocXKQrCZqZ\n",
       "jVfV2ianU7BLwJqZdVK/Fu/CHyLo/l0z5yTlfKScj1TfFW+JXYDTcL/bzPpY3/W8JY4D/iWCI7v9\n",
       "XmZm3ValnvcbgJ/0Oggzs27qx+J9IvCzXgfRjvt3zZyTlPORcj5S/Vi8X0sJireZ2WT0Vc9bYgB4\n",
       "EpgdwbZuvpeZ2VSoSs/7aOBhF24z63f9VrxL0zJx/66Zc5JyPlLOR6ofi/eaXgdhZtZt/dbzvgW4\n",
       "OIKbu/k+ZmZTpe+v5y0h4Ang6Age6db7mJlNpQnvsJQ0KGm9pA2SVozw+p9KWpMvd0vaIWm/TgU+\n",
       "DocBT5elcLt/18w5STkfKecjNWrxljQAXAYMAvOBpZLm1a8TEZdExIkRcSJwHrA6InpxtEdpdlaa\n",
       "mU1Wu5n3QmBjRAxFxHbgGmDJKOu/D7i6U8GNU6mKdxXvgt2Oc5JyPlLOR6pd8Z4FbKobb86fayJp\n",
       "T+AM4OudCW3cfKSJmVXGtDavj2dv5juBfxutZSJpFTCUD7cBa2t/TWv9rImMs52V33kj/NXlsJrJ\n",
       "bm+Kxn/cqc/fR+MFEXFpgeLp9dj5qGA+8sfnkhmihVGPNpF0EnBhRAzm4/OAnRFx8Qjr/gtwbURc\n",
       "02JbXTvaRGIW2ax7ZlnuniNpkb8GppyTlPORqmo+JnSooKRpwL1ktxXbAtwGLI2IdQ3r7QvcD8yO\n",
       "iOfHE0AnSLwT+FAEg93YvplZr7SqnaO2TSJih6TlwM3AAHB5RKyTtCx/fWW+6ruAm1sV7ilQqp2V\n",
       "ZmaT1Rcn6UjcAFwVwde6sf1uqOpXwNE4JynnI1XVfPT7VQV9pImZVUrpZ94SBwEbgP3LsrPSzGys\n",
       "+nnmfSKwxoXbzKqkH4p3KXdW+joNzZyTlPORcj5SLt5mZiXUDz3vjcA7I1jXdmUzs5Lpy563xH7A\n",
       "wcAvex2LmdlUKnXxBhYAd0XwUq8DGS/375o5JynnI+V8pMpevN3vNrNKKnXPW+Iq4PsRXNHJ7ZqZ\n",
       "FUVf9rzxzNvMKqq0xVviFcBhwD29jmUi3L9r5pyknI+U85EqbfEGjgfuieDFXgdiZjbVStvzlvgQ\n",
       "sCCCD3Zqm2ZmRdOPPW/3u82sstoWb0mDktZL2iBpRYt1FklaI+nnklZ3PMqRnUiJi7f7d82ck5Tz\n",
       "kXI+UqPeSUfSAHAZsBh4ELhd0o31t0GTtB/wWeCMiNgsaUY3A87ek+nAscDd3X4vM7MiajfzXghs\n",
       "jIihiNgOXAMsaVjnfcDXI2IzQEQ81vkwmxwGbInguSl4r66o4h1B2nFOUs5HyvlItSves4BNdePN\n",
       "+XP1jgIOkPR9SXdIOqeTAbZwJHDfFLyPmVkhtSveYzkUZVeynYdnAmcA50s6arKBtXEEsLHL79FV\n",
       "7t81c05SzkfK+UiN2vMm63PPqRvPIZt919sEPJbfOf55ST8ETiC7NVlC0ipgKB9uA9bWvgrV/mHG\n",
       "OD4S/g7pw4sm+Ps9HwMLJBUmnoKMFwBFiqfXY+ejgvnIH59LZogWRj3OW9I04F7gdGALcBuwtGGH\n",
       "5bFkOzXPAHYDbgXOjoh7GrbVseO8Jb4BrIzgxk5sz8ysqFrVzlFn3hGxQ9Jy4GZgALg8ItZJWpa/\n",
       "vjIi1kv6FnAXsBP4fGPh7oIjcM/bzCqsdGdYSgwAz5LdLf75yUfWG5JebvlYxjlJOR+pquajn86w\n",
       "nA08VubCbWY2WWWceZ8GXBDBKR0Iy8ys0Ppp5u1jvM2s8spYvEt/jDf4mNWROCcp5yPlfKTKWrw9\n",
       "8zazSitjz3st8IEIftqBsMzMCq0vet4SwjNvM7NyFW/gIODFCLb1OpDJcv+umXOScj5SzkeqbMX7\n",
       "SPpgZ6WZ2WSVquctcQ7w9gje16GwzMwKrS963vgYbzMzoHzFuy+O8Qb370binKScj5TzkSpj8fbM\n",
       "28wqr2w970eB4yJ4uENhmZkVWul73hL7AHsAW3sdi5lZr5WmeJO1TO6PGNN9NQvP/btmzknK+Ug5\n",
       "H6m2xVvSoKT1kjZIWjHC64skPSlpTb78eXdC9THeZmY17e5hOUB2D8vFZDcjvp3me1guAv4kIs4a\n",
       "9Y0m2fOW+BhwYAQfneg2zMzKZqI974XAxogYiojtwDXAkpG234EY2/GRJmZmuXbFexawqW68OX+u\n",
       "XgBvknSnpG9Kmt/JAOv0VdvE/btmzknK+Ug5H6lR7x4PY9o5+DNgTkQ8J+ntwPXA0ZOOrJln3mZm\n",
       "uXbF+0FgTt14Dtns+2UR8XTd45sk/b2kAyLiV40bk7QKGMqH24C1tbtB1/6qjjSW2B1uORjOOhye\n",
       "eaDd+mUY154rSjxFGdfnpgjx9HrsfFQvH/njc/OPOkQL7XZYTiPbYXk6sAW4jeYdljOBRyIiJC0E\n",
       "vhIRc0fY1oR3WErMA26I6MqM3syssCa0wzIidgDLgZuBe4BrI2KdpGWSluWrvRu4W9Ja4FLgvZ0N\n",
       "HejDlon7d82ck5TzkXI+Uu3aJkTETcBNDc+trHv8WeCznQ8t0Vc7K83MJqsU1zaR+AxwXwSXdjgs\n",
       "M7NCK/u1TfqubWJmNhllKd591zZx/66Zc5JyPlLOR6rwxVtiADgUeKDXsZiZFUXhe94Sc4EfRnBo\n",
       "56MyMyu2Mve8fd9KM7MGZSjefbmz0v27Zs5JyvlIOR+pshTvvtpZaWY2WWXoeV8HXB3BV7sQlplZ\n",
       "oZW5592XbRMzs8kodPGWEH1avN2/a+acpJyPlPORKnTxBmYCz0fwZK8DMTMrkkL3vCXeDFwSwcld\n",
       "CsvMrNDK2vPuy5aJmdlkFb149+0JOu7fNXNOUs5HyvlIFb14+xhvM7MRtC3ekgYlrZe0QdKKUdZ7\n",
       "g6Qdkn6zg/H17cy7/l6WlnFOUs5HyvlIjVq8JQ0AlwGDwHxgqaR5Lda7GPgWMKEbLrTgnreZ2Qja\n",
       "zbwXAhsjYigitgPXAEtGWO8Pga8Bj3YqMIl9gd2ARzq1zSJx/66Zc5JyPlLOR6pd8Z4FbKobb86f\n",
       "e5mkWWQF/XP5U5069vBw4P6Ijm3PzKxvtLsB8VgK56XAxyIiJIlR2iaSVgFD+XAbsLbWx6r9VR3u\n",
       "a11wFhz3ZHZz+ubXyz6uPVeUeIoyrs9NEeLp9dj5qF4+8sfn5h91iBZGPUlH0knAhRExmI/PA3ZG\n",
       "xMV169zPcMGeATwHfDAibmzY1rhO0pFYARwUwZ+O9XfMzPrNRE/SuQM4StJcSdOBs4GkKEfE4RFx\n",
       "WEQcRtb3/oPGwj1Bfb2z0v27Zs5JyvlIOR+pUYt3ROwAlgM3A/cA10bEOknLJC3rcmyH08fF28xs\n",
       "Mgp7bROJB4DFES7gZlZdrWpnIYu3xHTgaWCvCLZ3NzIzs+Iq24WpXgU82M+F2/27Zs5JyvlIOR+p\n",
       "ohbvvt5ZaWY2WUVtm/wP4PgI/nuXwzIzK7SytU2OAO7vdRBmZkVV5OLd120T9++aOScp5yPlfKRc\n",
       "vM3MSqhwPe/8jvHPAIdE8FT3IzMzK64y9bxnAs+5cJuZtVbE4l2Jlon7d82ck5TzkXI+Ui7eZmYl\n",
       "VMSe94XALhF8ovtRmZkVW5l63j7G28ysjaIW775vm7h/18w5STkfKecj5eJtZlZChep5S+wNbAVe\n",
       "4RsPm5lNouctaVDSekkbJK0Y4fUlku6UtEbSTyWdNok4DwMecOE2MxvdqMVb0gBwGTAIzAeWSprX\n",
       "sNp3I+KEiDiR7I7H/ziJeCrTMnH/rplzknI+Us5Hqt3MeyGwMSKGImI7cA2wpH6FiHi2brgX8Ngk\n",
       "4qlM8TYzm4x2xXsWsKluvDl/LiHpXZLWATcBfzSJeCpTvCNida9jKBrnJOV8pJyP1LQ2r4+p9xwR\n",
       "1wPXS3orcBVwzEjrSVoFDOXDbcDa2j9I9pXoutfBf/7X4fHwP5jHHnvscRXG+eNzyQzRwqhHm0g6\n",
       "CbgwIgbz8XnAzoi4eJTfuQ9YGBGPNzw/lqNNNgLviODe0dbrB5IWeSaRck5SzkeqqvmY6NEmdwBH\n",
       "SZoraTpwNnBjw4aPkKT88WsBGgv32AJkGjCHUf7SmJlZZtS2SUTskLQcuBkYAC6PiHWSluWvrwT+\n",
       "C/A7kraTXYf7vROM5VDg4Qh+PcHfL5UqziDacU5SzkfK+UgV5iQdicXAn0Vw6pQEZGZWAmW4MFVl\n",
       "jjQBH7M6Euck5XyknI+Ui7eZWQkVqW3ydeDaCL4yJQGZmZVAWdomvo63mdkYFKJ453eMP5wKtU3c\n",
       "v2vmnKScj5TzkSpE8QZmADsieKLXgZiZlUEhet4SJwGfieANUxKMmVlJFL3n7X63mdk4FKV4V6rf\n",
       "De7fjcQ5STkfKecjVZTi7WO8zczGoSg97x8B50ewekqCMTMrCfe8zcz6SM+Lt8SewAHAg72OZSq5\n",
       "f9fMOUk5HynnI9Xz4g0cBgxF8FKvAzEzK4ue97wlzgKWRfCOKQnEzKxEitzz9pEmZmbjNKbiLWlQ\n",
       "0npJGyStGOH135Z0p6S7JP1Y0vHjiKGSOyvdv2vmnKScj5TzkWpbvCUNAJcBg8B8YKmkeQ2r3Q+8\n",
       "LSKOBz4F/OM4YlgA/HIc65uZVV7bnrekk4EL6u4g/zGAiPh0i/X3B+6OiNkNzzf1bSTeAnwJODqC\n",
       "Fyf8KczM+tRket6zgE114835c618APjmGOO6EPhLF24zs/EZ9e7xuTEfjiLpVOD3gTe3eH0VMJSN\n",
       "3rw/nD8fzrgyf20RDN8hugLjPwbWFiieIowXRMSlBYqn12Pno4L5yB+fS2aIFsbSNjkJuLCubXIe\n",
       "sDMiLm5Y73jgOmAwIjaOsJ1k6i9xC/ClCK4YNYA+JWlR7R/OMs5JyvlIVTUfLQ+zHkPxngbcC5wO\n",
       "bAFuA5ZGxLq6dQ4FbgHeHxE/aReAxCnAFcCxEWyf2EcyM+t/rYp327ZJROyQtBy4GRgALo+IdZKW\n",
       "5a+vBD4B7A98ThLA9ohYOMpm/wL4lAu3mdnETPkZlhKnkh1KOC+CHVPy5gVU1a+Ao3FOUs5Hqqr5\n",
       "KMQZlvmNhmuz7soWbjOzyZrSmTfEYuBzwHwXbzOz9gox8yabdX/ShdvMbHKmunjPAK6e4vcsJF+n\n",
       "oZlzknI+Us5HaqqL9yd93W4zs8mb6p73NBdvM7OxK0TP24XbzKwzinAzhkpy/66Zc5JyPlLOR8rF\n",
       "28yshHp+D0szM2utED1vMzPrDBfvHnH/rplzknI+Us5HysXbzKyE3PM2Mysw97zNzPrImIq3pEFJ\n",
       "6yVtkLRihNePlfTvkl6Q9JHOh9l/3L9r5pyknI+U85FqW7wlDQCXAYPAfGCppHkNqz0O/CFwSccj\n",
       "7F8Leh1AATknKecj5XzUGcvMeyGwMSKGImI7cA2wpH6FiHg0Iu4A39ZsHPbrdQAF5JyknI+U81Fn\n",
       "LMV7FrCpbrw5f87MzHpkLMV7ag5HqZ65vQ6ggOb2OoCCmdvrAApmbq8DKJK2d48HHgTm1I3nkM2+\n",
       "xy27LKzVSPrdXsdQNM5JyvlIOR/DxlK87wCOkjQX2AKcDSxtsW7L47h9jLeZWeeM6SQdSW8HLgUG\n",
       "gMsj4iJJywAiYqWkg4HbgX2AncDTwPyIeKZrkZuZVdiUnWFpZmad0/UzLNud4FMFkq6QtFXS3XXP\n",
       "HSDpO5J+KenbkipzGJSkOZK+L+kXkn4u6Y/y5yuZE0m7S7pV0lpJ90i6KH++kvmokTQgaY2kf83H\n",
       "lc5Ho64W7zGe4FMFXyTLQb2PAd+JiKOB7+XjqtgO/M+IeDVwEvCh/L+LSuYkIl4ATo2IBcDxwKmS\n",
       "3kJF81Hnw8A9DB/xVvV8JLo98257gk8VRMSPgCcanj4LuDJ/fCXwrikNqoci4uGIWJs/fgZYR3bu\n",
       "QJVz8lz+cDrZvqUnqHA+JM0GzgS+wPCBEJXNx0i6Xbx9gk9rMyNia/54KzCzl8H0Sn4U04nArVQ4\n",
       "J5J2kbSW7HN/PyJ+QYXzAfxv4KNkB0DUVDkfTbpdvL03dAwi22tcuVxJ2gv4OvDhiHi6/rWq5SQi\n",
       "duZtk9nA2ySd2vB6ZfIh6T8Bj0TEGlocflylfLTS7eLdsRN8+tDW/BBLJB0CPNLjeKaUpF3JCvdV\n",
       "EXF9/nSlcwIQEU8C3wBeR3Xz8SbgLEkPAFcDp0m6iurmY0TdLt4vn+AjaTrZCT43dvk9y+JGoHa2\n",
       "2O8C14+ybl+RJOBy4J6IuLTupUrmRNKM2pETkvYA/gOwhormIyI+HhFzIuIw4L3ALRFxDhXNRytd\n",
       "P857pBN8uvqGBSTpauAUYAZZr+4TwA3AV4BDgSHgPRGxrVcxTqX8SIofAncx/NX3POA2KpgTSceR\n",
       "7YDbJV+uioi/lnQAFcxHPUmnAB+JiLOcj5RP0jEzKyHfBs3MrIRcvM3MSsjF28yshFy8zcxKyMXb\n",
       "zKyEXLzNzErIxdtsDCQtql2a1KwIXLzNzErIxdv6iqT35zc2WCPpH/IL+j8j6W/zGz98V9KMfN0F\n",
       "kn4i6U5J19Wdon5kvt5aST+VdDjZmaB7SfqqpHWSvtTLz2nm4m19I7+hw3uAN0XEicBLwG8DewK3\n",
       "R8RrgB8AF+S/8k/ARyPiBODuuuf/GfhMfpW/k4GHyK5udyLZDQLmA4dLevOUfDCzEYzl7vFmZXE6\n",
       "2dX47siufcXuZFee2wlcm6/zJeA6SfsA++Y3yoDs2iJfzS9T+8qIuAEgIl4EyLd3W0RsycdrgbnA\n",
       "j7v/scyauXhbv7kyIj5e/4Sk8+uHjHwd6BGvG93g13WPX8L//1gPuW1i/eR7wLslHQQv37D2VWT/\n",
       "nf9Wvs77gB9FxFPAE/kVDgHOAVbnt2XbLGlJvo3d8su0mhWKZw7WNyJinaQ/B74taRfgRWA58Cyw\n",
       "MH9tK9l15SG7JvQ/SNoTuA/4vfz5c4CVkj6Zb+M9ZLP1xhm7L8lpPeNLwlrfk/R0ROzd6zjMOslt\n",
       "E6sCz1Cs73jmbWZWQp55m5mVkIu3mVkJuXibmZWQi7eZWQm5eJuZlZCLt5lZCf1/tPb5xhLrN2EA\n",
       "AAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f55f7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the model which consists of 3 conv layers followed by\n",
    "# 2 fully conntected layers\n",
    "\n",
    "# Sequential wrapper model\n",
    "model = Sequential()\n",
    "\n",
    "# first convolutional layer\n",
    "model.add(Convolution2D(32, 1, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(Convolution2D(48, 32, 2, 2))\n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# third convolutional layer\n",
    "model.add(Convolution2D(32, 48, 2, 2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(poolsize=(2,2)))\n",
    "\n",
    "# convert convolutional filters to flatt so they can be feed to \n",
    "# fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# first fully connected layer\n",
    "model.add(Dense(32*6*6, 128, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# second fully connected layer\n",
    "model.add(Dense(128, 128, init='lecun_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# last fully connected layer which output classes\n",
    "model.add(Dense(128, 9, init='lecun_uniform'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# setting sgd optimizer parameters\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "features = joblib.load(\"./mldata/features_1200.mat\")\n",
    "labels = joblib.load(\"./mldata/lables_1200.mat\")\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(labels, 'int')\n",
    "\n",
    "def scale(X, eps = 0.001):\n",
    "    # scale the data points s.t the columns of the feature space\n",
    "    # (i.e the predictors) are within the range [0, 1]\n",
    "    return (X - np.min(X, axis = 0)) / (np.max(X, axis = 0) + eps)\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "\n",
    "# scale the data to the range [0, 1] and then construct the training\n",
    "# and testing splits\n",
    "(trainX, testX, trainY, testY) = train_test_split(features, labels, test_size = 0.43)\n",
    "(valX, testX, valY, testY) = train_test_split(testX, testY, test_size = 0.5)\n",
    "\n",
    "# reshape for convolutions\n",
    "trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "testX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    "valX = valX.reshape((valX.shape[0], 1, 28, 28))\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "trainY = np_utils.to_categorical(trainY, nb_classes)\n",
    "testY = np_utils.to_categorical(testY, nb_classes)\n",
    "valY = np_utils.to_categorical(valY, nb_classes)\n",
    "\n",
    "print \"the shape of train set %s rows, %s columns\" %(trainX.shape[0], trainX.shape[1])\n",
    "print \"the shape of test set %s rows, %s columns\" %(testX.shape[0], testX.shape[1])\n",
    "print \"the shape of validation set %s rows, %s columns\" %(valX.shape[0], valX.shape[1])\n",
    "\n",
    "mm = model.fit(trainX, trainY,\n",
    "               batch_size=batch_size,\n",
    "               nb_epoch=nb_epoch,\n",
    "               show_accuracy=True,\n",
    "               verbose=1,\n",
    "               validation_data=(testX, testY))\n",
    "\n",
    "score = model.evaluate(valX, valY, show_accuracy=True, verbose=0, batch_size=batch_size)\n",
    "print 'Test score : %s' %score[0]\n",
    "print 'Test accuracy : %s' %score[1]\n",
    "\n",
    "df = pd.DataFrame(mm)\n",
    "df.index = df['epoch']\n",
    "df['acc'].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
