{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt, cm\n",
    "from skimage import io\n",
    "from skimage import data, segmentation, filters, color, img_as_float, img_as_ubyte, exposure, feature, measure, morphology\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "from skimage.morphology import square\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plan 1\n",
    "# train data : captcha 1000(feature : HOG)\n",
    "# test data : captcha 200 images (feature : HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of files is 200\n",
      "(1000, 784)\n",
      "(1000,)\n",
      "escape time :  13.673 s\n",
      "escape time :  0.936 s\n",
      "BernoulliNB(alpha=1, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.79      0.85       103\n",
      "          1       0.76      0.65      0.70       130\n",
      "          2       0.86      0.73      0.79       132\n",
      "          3       0.62      0.45      0.52        94\n",
      "          4       0.81      0.88      0.84       134\n",
      "          5       0.71      0.72      0.71       109\n",
      "          6       0.82      0.32      0.46        57\n",
      "          7       0.79      0.91      0.85       148\n",
      "          8       0.45      0.83      0.58        93\n",
      "\n",
      "avg / total       0.76      0.73      0.73      1000\n",
      "\n",
      "0.731\n",
      "[[ 81   1   2   3   9   0   0   1   6]\n",
      " [  0  85   1  10   0   0   1  31   2]\n",
      " [  0   5  97   4   0   6   0   2  18]\n",
      " [  0   1   0  42   1   9   2   0  39]\n",
      " [  1   4   2   1 118   2   0   0   6]\n",
      " [  3   6   3   4   6  78   0   1   8]\n",
      " [  2   7   4   0  10   6  18   0  10]\n",
      " [  1   1   2   0   1   3   0 135   5]\n",
      " [  0   2   2   4   1   6   1   0  77]]\n",
      "====================================================================================================\n",
      "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_density=None, min_samples_leaf=1, min_samples_split=5,\n",
      "            random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.90      0.89       103\n",
      "          1       0.95      0.98      0.97       130\n",
      "          2       0.92      0.91      0.92       132\n",
      "          3       0.92      0.83      0.87        94\n",
      "          4       0.96      0.94      0.95       134\n",
      "          5       0.84      0.84      0.84       109\n",
      "          6       0.58      0.75      0.66        57\n",
      "          7       0.96      0.91      0.94       148\n",
      "          8       0.92      0.88      0.90        93\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1000\n",
      "\n",
      "0.897\n",
      "[[ 93   2   0   0   1   1   3   2   1]\n",
      " [  1 128   0   0   0   0   1   0   0]\n",
      " [  1   0 120   1   2   2   4   1   1]\n",
      " [  1   3   1  78   0   6   3   0   2]\n",
      " [  1   0   3   0 126   2   2   0   0]\n",
      " [  1   0   2   3   1  92   7   2   1]\n",
      " [  4   1   4   2   1   0  43   0   2]\n",
      " [  3   1   0   1   0   2   6 135   0]\n",
      " [  1   0   0   0   0   5   5   0  82]]\n",
      "====================================================================================================\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_neighbors=5, p=2, weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.92      0.94       103\n",
      "          1       0.93      1.00      0.96       130\n",
      "          2       0.97      0.92      0.94       132\n",
      "          3       0.97      0.95      0.96        94\n",
      "          4       0.99      0.96      0.97       134\n",
      "          5       0.96      0.91      0.93       109\n",
      "          6       0.69      0.86      0.77        57\n",
      "          7       0.97      0.97      0.97       148\n",
      "          8       0.94      0.94      0.94        93\n",
      "\n",
      "avg / total       0.95      0.94      0.94      1000\n",
      "\n",
      "0.941\n",
      "[[ 95   2   0   0   0   0   3   2   1]\n",
      " [  0 130   0   0   0   0   0   0   0]\n",
      " [  1   1 121   1   0   0   6   1   1]\n",
      " [  0   1   0  89   0   2   1   0   1]\n",
      " [  1   2   1   1 128   0   1   0   0]\n",
      " [  0   1   1   0   1  99   5   1   1]\n",
      " [  2   2   1   1   0   0  49   0   2]\n",
      " [  1   0   0   0   0   2   2 143   0]\n",
      " [  0   1   1   0   0   0   4   0  87]]\n",
      "====================================================================================================\n",
      "LinearSVC(C=100.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
      "     random_state=None, tol=0.0001, verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.92      0.93       103\n",
      "          1       0.95      1.00      0.97       130\n",
      "          2       0.93      0.92      0.92       132\n",
      "          3       0.92      0.93      0.92        94\n",
      "          4       0.98      0.95      0.96       134\n",
      "          5       0.94      0.87      0.90       109\n",
      "          6       0.67      0.72      0.69        57\n",
      "          7       0.96      0.95      0.96       148\n",
      "          8       0.88      0.91      0.89        93\n",
      "\n",
      "avg / total       0.92      0.92      0.92      1000\n",
      "\n",
      "0.922\n",
      "[[ 95   2   0   1   0   0   2   1   2]\n",
      " [  0 130   0   0   0   0   0   0   0]\n",
      " [  0   0 121   1   0   2   4   2   2]\n",
      " [  0   1   1  87   0   2   1   0   2]\n",
      " [  1   1   2   0 127   0   2   0   1]\n",
      " [  2   1   1   1   0  95   6   1   2]\n",
      " [  4   0   3   4   2   0  41   1   2]\n",
      " [  0   1   1   0   1   1   2 141   1]\n",
      " [  0   1   1   1   0   1   3   1  85]]\n",
      "====================================================================================================\n",
      "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.92      0.93       103\n",
      "          1       0.94      1.00      0.97       130\n",
      "          2       0.93      0.93      0.93       132\n",
      "          3       0.92      0.93      0.92        94\n",
      "          4       0.98      0.95      0.97       134\n",
      "          5       0.96      0.87      0.91       109\n",
      "          6       0.68      0.75      0.72        57\n",
      "          7       0.96      0.95      0.96       148\n",
      "          8       0.89      0.91      0.90        93\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1000\n",
      "\n",
      "0.926\n",
      "[[ 95   2   0   1   0   0   2   1   2]\n",
      " [  0 130   0   0   0   0   0   0   0]\n",
      " [  0   1 123   1   0   0   5   1   1]\n",
      " [  0   1   1  87   0   2   0   0   3]\n",
      " [  1   1   2   0 127   0   2   0   1]\n",
      " [  2   1   1   1   0  95   6   1   2]\n",
      " [  4   1   3   4   1   0  43   1   0]\n",
      " [  0   1   1   0   1   1   2 141   1]\n",
      " [  0   0   1   1   0   1   3   2  85]]\n",
      "====================================================================================================\n",
      "Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.001, n_components=200, n_iter=20,\n",
      "       random_state=None, verbose=True)), ('logistic', LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.92      0.81       103\n",
      "          1       0.82      0.88      0.85       130\n",
      "          2       0.96      0.92      0.94       132\n",
      "          3       0.93      0.86      0.90        94\n",
      "          4       0.98      0.96      0.97       134\n",
      "          5       0.86      0.78      0.82       109\n",
      "          6       0.00      0.00      0.00        57\n",
      "          7       0.83      0.97      0.89       148\n",
      "          8       0.77      0.91      0.83        93\n",
      "\n",
      "avg / total       0.81      0.85      0.83      1000\n",
      "\n",
      "0.853\n",
      "[[ 95   3   0   0   0   0   0   2   3]\n",
      " [  0 115   0   0   0   0   0  15   0]\n",
      " [  0   5 121   1   0   1   0   3   1]\n",
      " [  0   2   2  81   0   7   0   0   2]\n",
      " [  0   4   2   0 128   0   0   0   0]\n",
      " [  8   6   0   1   0  85   0   4   5]\n",
      " [ 28   3   1   2   1   3   0   5  14]\n",
      " [  1   1   0   0   1   1   0 143   1]\n",
      " [  1   2   0   2   0   2   0   1  85]]\n",
      "====================================================================================================\n",
      "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
      "            min_samples_split=10, n_estimators=70, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.92      0.95       103\n",
      "          1       0.94      1.00      0.97       130\n",
      "          2       0.98      0.92      0.95       132\n",
      "          3       0.98      0.94      0.96        94\n",
      "          4       0.99      0.96      0.97       134\n",
      "          5       0.93      0.89      0.91       109\n",
      "          6       0.66      0.86      0.75        57\n",
      "          7       0.97      0.97      0.97       148\n",
      "          8       0.89      0.91      0.90        93\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1000\n",
      "\n",
      "0.937\n",
      "[[ 95   2   0   0   0   1   3   1   1]\n",
      " [  0 130   0   0   0   0   0   0   0]\n",
      " [  0   0 122   1   0   0   5   1   3]\n",
      " [  0   1   0  88   0   1   2   0   2]\n",
      " [  0   0   1   1 128   1   2   1   0]\n",
      " [  0   3   0   0   0  97   6   1   2]\n",
      " [  2   2   1   0   0   1  49   0   2]\n",
      " [  0   0   0   0   1   2   2 143   0]\n",
      " [  0   1   1   0   0   1   5   0  85]]\n",
      "====================================================================================================\n",
      "SVC(C=100.0, cache_size=1000, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.125, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.93      0.96       103\n",
      "          1       0.93      1.00      0.96       130\n",
      "          2       0.98      0.94      0.96       132\n",
      "          3       0.92      0.96      0.94        94\n",
      "          4       0.98      0.96      0.97       134\n",
      "          5       0.97      0.91      0.94       109\n",
      "          6       0.70      0.86      0.77        57\n",
      "          7       0.98      0.97      0.97       148\n",
      "          8       0.94      0.90      0.92        93\n",
      "\n",
      "avg / total       0.95      0.94      0.94      1000\n",
      "\n",
      "0.943\n",
      "[[ 96   3   0   0   0   0   2   1   1]\n",
      " [  0 130   0   0   0   0   0   0   0]\n",
      " [  0   0 124   1   1   0   5   1   0]\n",
      " [  0   1   0  90   0   1   0   0   2]\n",
      " [  0   1   1   2 128   0   2   0   0]\n",
      " [  0   2   0   1   0  99   5   1   1]\n",
      " [  2   2   1   2   1   0  49   0   0]\n",
      " [  0   0   0   1   1   1   1 143   1]\n",
      " [  0   1   0   1   0   1   6   0  84]]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 새로운 200개의 이미지를 test 데이터로 만들자.\n",
    "p = \"./data_test\"\n",
    "md5list = glob(os.path.join(p, \"*.png\"))\n",
    "md5list = [os.path.split(fname)[1] for fname in md5list]\n",
    "print \"the number of files is %s\" %len(md5list)\n",
    "\n",
    "features = []\n",
    "lables = []\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# captcha를 preprossing후 mnist처럼 numpy array로 만들자\n",
    "for fname in md5list:\n",
    "    lable = os.path.split(fname)[1].split(\"_\")[1][:5]\n",
    "    im = io.imread(os.path.join(p, fname))\n",
    "    w, h, _ = im.shape\n",
    "\n",
    "    for x in range(w):\n",
    "        for j in range(h):\n",
    "\n",
    "            if im[x][j][0] == im[x][j][1] and im[x][j][1] == im[x][j][2] and im[x][j][2] == im[x][j][0]:\n",
    "                im[x][j][0] = 255\n",
    "                im[x][j][1] = 255\n",
    "                im[x][j][2] = 255\n",
    "\n",
    "    im_gray = rgb2gray(im)\n",
    "    im_gray = img_as_ubyte(im_gray)\n",
    "    im_gray = morphology.opening(im_gray, square(2))\n",
    "    im_gray_equalize = exposure.equalize_hist(im_gray)\n",
    "\n",
    "    threshold = filters.threshold_otsu(im_gray_equalize).copy()\n",
    "    threshold = im_gray_equalize < threshold\n",
    "    threshold = img_as_ubyte(threshold)\n",
    "\n",
    "    bw = morphology.closing(im_gray_equalize < threshold, square(3))\n",
    "    cleared = bw.copy()\n",
    "\n",
    "    im_th = cleared\n",
    "    ctrs, hier = cv2.findContours(img_as_ubyte(im_th.copy()), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "    rects = sorted(rects, key=lambda tup: tup[0])\n",
    "\n",
    "    if len(rects) != 5:\n",
    "        continue\n",
    "\n",
    "\n",
    "    for rect, l in zip(rects, lable):\n",
    "        # Draw the rectangles\n",
    "        cv2.rectangle(threshold, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 1) \n",
    "\n",
    "        # Make the rectangular region around the digit\n",
    "        roi = threshold[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "        roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        roi = morphology.closing(roi, square(4))\n",
    "        \n",
    "        features.append(roi.ravel())\n",
    "        lables.append([l])\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(lables, 'int').ravel()\n",
    "\n",
    "# features, lables의 차원을 출력\n",
    "print features.shape\n",
    "print labels.shape\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "list_hog_fd = []\n",
    "for feature in features:\n",
    "    fd = hog(feature.reshape((28, 28)), orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "classifiers = glob(\"./pkl/hog/skt/*.pkl\")\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = joblib.load(classifier)\n",
    "    print clf\n",
    "    print classification_report(labels, clf.predict(hog_features))\n",
    "    print accuracy_score(labels, clf.predict(hog_features))\n",
    "    print confusion_matrix(labels, clf.predict(hog_features))\n",
    "    print \"=\" * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plan 2\n",
    "# train data : captcha 1000(feature : No)\n",
    "# test data : captcha 200 images (feature : No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of files is 200\n",
      "(1000, 784)\n",
      "(1000,)\n",
      "escape time :  13.622 s\n",
      "escape time :  0.014 s\n",
      "BernoulliNB(alpha=1, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.92      0.95       103\n",
      "          1       0.87      0.95      0.90       130\n",
      "          2       0.99      0.90      0.94       132\n",
      "          3       0.99      0.93      0.96        94\n",
      "          4       1.00      0.95      0.97       134\n",
      "          5       0.93      0.85      0.89       109\n",
      "          6       0.49      0.84      0.62        57\n",
      "          7       0.98      0.97      0.97       148\n",
      "          8       0.98      0.86      0.91        93\n",
      "\n",
      "avg / total       0.94      0.92      0.92      1000\n",
      "\n",
      "0.915\n",
      "[[ 95   1   0   0   0   0   5   1   1]\n",
      " [  0 123   0   0   0   0   7   0   0]\n",
      " [  1   4 119   1   0   1   5   1   0]\n",
      " [  0   1   0  87   0   0   6   0   0]\n",
      " [  0   2   1   0 127   0   4   0   0]\n",
      " [  0   5   0   0   0  93  10   1   0]\n",
      " [  2   4   0   0   0   2  48   0   1]\n",
      " [  0   1   0   0   0   3   1 143   0]\n",
      " [  0   1   0   0   0   1  11   0  80]]\n",
      "====================================================================================================\n",
      "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_density=None, min_samples_leaf=1, min_samples_split=50,\n",
      "            random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.90      0.93       103\n",
      "          1       0.87      0.99      0.92       130\n",
      "          2       0.95      0.89      0.92       132\n",
      "          3       0.87      0.91      0.89        94\n",
      "          4       0.91      0.94      0.92       134\n",
      "          5       0.93      0.84      0.88       109\n",
      "          6       0.71      0.81      0.75        57\n",
      "          7       0.97      0.95      0.96       148\n",
      "          8       0.99      0.88      0.93        93\n",
      "\n",
      "avg / total       0.92      0.91      0.91      1000\n",
      "\n",
      "0.911\n",
      "[[ 93   2   0   2   1   0   3   1   1]\n",
      " [  0 129   0   1   0   0   0   0   0]\n",
      " [  0   2 117   4   3   0   4   2   0]\n",
      " [  0   3   0  86   3   1   0   1   0]\n",
      " [  1   2   1   2 126   1   1   0   0]\n",
      " [  0   5   2   2   2  92   5   1   0]\n",
      " [  2   4   0   1   2   2  46   0   0]\n",
      " [  1   0   2   1   0   2   2 140   0]\n",
      " [  1   2   1   0   2   1   4   0  82]]\n",
      "====================================================================================================\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_neighbors=5, p=2, weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.92      0.93       103\n",
      "          1       0.87      0.99      0.92       130\n",
      "          2       0.98      0.91      0.94       132\n",
      "          3       0.97      0.97      0.97        94\n",
      "          4       0.99      0.96      0.97       134\n",
      "          5       0.95      0.89      0.92       109\n",
      "          6       0.82      0.82      0.82        57\n",
      "          7       0.97      0.97      0.97       148\n",
      "          8       0.90      0.92      0.91        93\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1000\n",
      "\n",
      "0.937\n",
      "[[ 95   2   0   0   1   1   2   1   1]\n",
      " [  0 129   0   0   0   0   0   0   1]\n",
      " [  1   4 120   3   0   0   0   2   2]\n",
      " [  0   1   0  91   0   0   1   0   1]\n",
      " [  1   1   1   0 128   0   1   0   2]\n",
      " [  0   5   0   0   0  97   2   2   3]\n",
      " [  3   5   1   0   0   1  47   0   0]\n",
      " [  0   1   0   0   0   2   1 144   0]\n",
      " [  1   1   1   0   0   1   3   0  86]]\n",
      "====================================================================================================\n",
      "LinearSVC(C=10.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
      "     random_state=None, tol=0.0001, verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.92      0.93       103\n",
      "          1       0.93      0.99      0.96       130\n",
      "          2       0.97      0.91      0.94       132\n",
      "          3       0.97      0.93      0.95        94\n",
      "          4       0.98      0.96      0.97       134\n",
      "          5       0.96      0.89      0.92       109\n",
      "          6       0.69      0.86      0.77        57\n",
      "          7       0.95      0.96      0.96       148\n",
      "          8       0.91      0.91      0.91        93\n",
      "\n",
      "avg / total       0.94      0.93      0.93      1000\n",
      "\n",
      "0.932\n",
      "[[ 95   1   0   0   0   1   3   2   1]\n",
      " [  0 129   0   0   0   0   0   0   1]\n",
      " [  2   1 120   1   0   0   5   2   1]\n",
      " [  1   2   0  87   1   2   0   1   0]\n",
      " [  0   2   0   1 128   0   1   0   2]\n",
      " [  0   1   2   1   0  97   7   1   0]\n",
      " [  2   2   1   0   0   0  49   1   2]\n",
      " [  0   1   0   0   0   1   3 142   1]\n",
      " [  2   0   1   0   2   0   3   0  85]]\n",
      "====================================================================================================\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.92      0.94       103\n",
      "          1       0.96      0.99      0.97       130\n",
      "          2       0.96      0.92      0.94       132\n",
      "          3       0.97      0.94      0.95        94\n",
      "          4       0.96      0.96      0.96       134\n",
      "          5       0.95      0.89      0.92       109\n",
      "          6       0.72      0.86      0.78        57\n",
      "          7       0.95      0.97      0.96       148\n",
      "          8       0.93      0.94      0.93        93\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1000\n",
      "\n",
      "0.939\n",
      "[[ 95   0   0   0   1   1   3   2   1]\n",
      " [  0 129   0   0   0   0   0   0   1]\n",
      " [  1   1 122   1   0   1   4   1   1]\n",
      " [  1   1   0  88   1   2   0   1   0]\n",
      " [  0   1   1   0 129   0   1   0   2]\n",
      " [  0   0   2   1   1  97   6   2   0]\n",
      " [  2   2   1   0   0   0  49   1   2]\n",
      " [  0   1   0   0   1   1   2 143   0]\n",
      " [  0   0   1   1   1   0   3   0  87]]\n",
      "====================================================================================================\n",
      "Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.001, n_components=200, n_iter=80,\n",
      "       random_state=None, verbose=True)), ('logistic', LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.92      0.95       103\n",
      "          1       0.96      0.99      0.98       130\n",
      "          2       0.95      0.92      0.93       132\n",
      "          3       0.98      0.95      0.96        94\n",
      "          4       0.98      0.96      0.97       134\n",
      "          5       0.91      0.90      0.90       109\n",
      "          6       0.68      0.82      0.75        57\n",
      "          7       0.97      0.97      0.97       148\n",
      "          8       0.91      0.92      0.92        93\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1000\n",
      "\n",
      "0.937\n",
      "[[ 95   0   1   0   1   1   3   1   1]\n",
      " [  0 129   0   0   0   0   0   1   0]\n",
      " [  1   0 121   1   0   1   5   1   2]\n",
      " [  0   1   0  89   0   0   3   0   1]\n",
      " [  0   1   1   0 129   2   1   0   0]\n",
      " [  0   2   1   0   0  98   5   1   2]\n",
      " [  2   0   1   1   1   3  47   0   2]\n",
      " [  0   0   1   0   0   2   2 143   0]\n",
      " [  0   1   1   0   1   1   3   0  86]]\n",
      "====================================================================================================\n",
      "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
      "            min_samples_split=20, n_estimators=80, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.92      0.95       103\n",
      "          1       0.95      1.00      0.97       130\n",
      "          2       0.98      0.92      0.95       132\n",
      "          3       0.98      0.95      0.96        94\n",
      "          4       0.98      0.96      0.97       134\n",
      "          5       0.90      0.89      0.89       109\n",
      "          6       0.68      0.88      0.76        57\n",
      "          7       0.97      0.97      0.97       148\n",
      "          8       0.96      0.92      0.94        93\n",
      "\n",
      "avg / total       0.95      0.94      0.94      1000\n",
      "\n",
      "0.942\n",
      "[[ 95   1   0   0   1   1   3   1   1]\n",
      " [  0 130   0   0   0   0   0   0   0]\n",
      " [  0   0 122   2   0   1   4   2   1]\n",
      " [  0   1   1  89   0   2   1   0   0]\n",
      " [  0   0   1   0 129   2   2   0   0]\n",
      " [  0   2   0   0   0  97   8   1   1]\n",
      " [  2   2   0   0   0   2  50   0   1]\n",
      " [  0   0   0   0   0   2   2 144   0]\n",
      " [  0   1   0   0   1   1   4   0  86]]\n",
      "====================================================================================================\n",
      "SVC(C=10.0, cache_size=1000, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.03125, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.92      0.95       103\n",
      "          1       0.98      1.00      0.99       130\n",
      "          2       0.98      0.92      0.95       132\n",
      "          3       0.95      0.96      0.95        94\n",
      "          4       0.99      0.96      0.98       134\n",
      "          5       0.89      0.93      0.91       109\n",
      "          6       0.68      0.86      0.76        57\n",
      "          7       0.99      0.97      0.98       148\n",
      "          8       0.98      0.95      0.96        93\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1000\n",
      "\n",
      "0.947\n",
      "[[ 95   0   0   1   0   2   3   1   1]\n",
      " [  0 130   0   0   0   0   0   0   0]\n",
      " [  0   0 122   1   0   3   5   1   0]\n",
      " [  0   1   1  90   0   1   1   0   0]\n",
      " [  0   0   0   2 129   2   1   0   0]\n",
      " [  0   0   0   0   0 101   8   0   0]\n",
      " [  2   2   0   0   1   2  49   0   1]\n",
      " [  0   0   0   0   0   2   3 143   0]\n",
      " [  0   0   1   1   0   1   2   0  88]]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 새로운 200개의 이미지를 test 데이터로 만들자.\n",
    "p = \"./data_test\"\n",
    "md5list = glob(os.path.join(p, \"*.png\"))\n",
    "md5list = [os.path.split(fname)[1] for fname in md5list]\n",
    "print \"the number of files is %s\" %len(md5list)\n",
    "\n",
    "features = []\n",
    "lables = []\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# captcha를 preprossing후 mnist처럼 numpy array로 만들자\n",
    "for fname in md5list:\n",
    "    lable = os.path.split(fname)[1].split(\"_\")[1][:5]\n",
    "    im = io.imread(os.path.join(p, fname))\n",
    "    w, h, _ = im.shape\n",
    "\n",
    "    for x in range(w):\n",
    "        for j in range(h):\n",
    "\n",
    "            if im[x][j][0] == im[x][j][1] and im[x][j][1] == im[x][j][2] and im[x][j][2] == im[x][j][0]:\n",
    "                im[x][j][0] = 255\n",
    "                im[x][j][1] = 255\n",
    "                im[x][j][2] = 255\n",
    "\n",
    "    im_gray = rgb2gray(im)\n",
    "    im_gray = img_as_ubyte(im_gray)\n",
    "    im_gray = morphology.opening(im_gray, square(2))\n",
    "    im_gray_equalize = exposure.equalize_hist(im_gray)\n",
    "\n",
    "    threshold = filters.threshold_otsu(im_gray_equalize).copy()\n",
    "    threshold = im_gray_equalize < threshold\n",
    "    threshold = img_as_ubyte(threshold)\n",
    "\n",
    "    bw = morphology.closing(im_gray_equalize < threshold, square(3))\n",
    "    cleared = bw.copy()\n",
    "\n",
    "    im_th = cleared\n",
    "    ctrs, hier = cv2.findContours(img_as_ubyte(im_th.copy()), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "    rects = sorted(rects, key=lambda tup: tup[0])\n",
    "\n",
    "    if len(rects) != 5:\n",
    "        continue\n",
    "\n",
    "\n",
    "    for rect, l in zip(rects, lable):\n",
    "        # Draw the rectangles\n",
    "        cv2.rectangle(threshold, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 1) \n",
    "\n",
    "        # Make the rectangular region around the digit\n",
    "        roi = threshold[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "        roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        roi = morphology.closing(roi, square(4))\n",
    "        \n",
    "        features.append(roi.ravel())\n",
    "        lables.append([l])\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(lables, 'int').ravel()\n",
    "\n",
    "# features, lables의 차원을 출력\n",
    "print features.shape\n",
    "print labels.shape\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "def scale(X, eps = 0.001):\n",
    "    # scale the data points s.t the columns of the feature space\n",
    "    # (i.e the predictors) are within the range [0, 1]\n",
    "    return (X - np.min(X, axis = 0)) / (np.max(X, axis = 0) + eps)\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "classifiers = glob(\"./pkl/scale/skt/*.pkl\")\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = joblib.load(classifier)\n",
    "    print clf\n",
    "    print classification_report(labels, clf.predict(features))\n",
    "    print accuracy_score(labels, clf.predict(features))\n",
    "    print confusion_matrix(labels, clf.predict(features))\n",
    "    print \"=\" * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plan 3\n",
    "# train data : MNIST(feature : HOG)\n",
    "# test data : captcha 200 images (feature : HOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of files is 200\n",
      "(1000, 784)\n",
      "(1000,)\n",
      "escape time :  10.812 s\n",
      "escape time :  0.971 s\n"
     ]
    }
   ],
   "source": [
    "# 새로운 200개의 이미지를 test 데이터로 만들자.\n",
    "p = \"./data_test\"\n",
    "md5list = glob(os.path.join(p, \"*.png\"))\n",
    "md5list = [os.path.split(fname)[1] for fname in md5list]\n",
    "print \"the number of files is %s\" %len(md5list)\n",
    "\n",
    "features = []\n",
    "lables = []\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# captcha를 preprossing후 mnist처럼 numpy array로 만들자\n",
    "for fname in md5list:\n",
    "    lable = os.path.split(fname)[1].split(\"_\")[1][:5]\n",
    "    im = io.imread(os.path.join(p, fname))\n",
    "    w, h, _ = im.shape\n",
    "\n",
    "    for x in range(w):\n",
    "        for j in range(h):\n",
    "\n",
    "            if im[x][j][0] == im[x][j][1] and im[x][j][1] == im[x][j][2] and im[x][j][2] == im[x][j][0]:\n",
    "                im[x][j][0] = 255\n",
    "                im[x][j][1] = 255\n",
    "                im[x][j][2] = 255\n",
    "\n",
    "    im_gray = rgb2gray(im)\n",
    "    im_gray = img_as_ubyte(im_gray)\n",
    "    im_gray = morphology.opening(im_gray, square(2))\n",
    "    im_gray_equalize = exposure.equalize_hist(im_gray)\n",
    "\n",
    "    threshold = filters.threshold_otsu(im_gray_equalize).copy()\n",
    "    threshold = im_gray_equalize < threshold\n",
    "    threshold = img_as_ubyte(threshold)\n",
    "\n",
    "    bw = morphology.closing(im_gray_equalize < threshold, square(3))\n",
    "    cleared = bw.copy()\n",
    "\n",
    "    im_th = cleared\n",
    "    ctrs, hier = cv2.findContours(img_as_ubyte(im_th.copy()), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "    rects = sorted(rects, key=lambda tup: tup[0])\n",
    "\n",
    "    if len(rects) != 5:\n",
    "        continue\n",
    "\n",
    "\n",
    "    for rect, l in zip(rects, lable):\n",
    "        # Draw the rectangles\n",
    "        cv2.rectangle(threshold, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 1) \n",
    "\n",
    "        # Make the rectangular region around the digit\n",
    "        roi = threshold[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "        roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        roi = morphology.closing(roi, square(4))\n",
    "        \n",
    "        features.append(roi.ravel())\n",
    "        lables.append([l])\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(lables, 'int').ravel()\n",
    "\n",
    "# features, lables의 차원을 출력\n",
    "print features.shape\n",
    "print labels.shape\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "list_hog_fd = []\n",
    "for feature in features:\n",
    "    fd = hog(feature.reshape((28, 28)), orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.79      0.66       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.42      0.48      0.45       132\n",
      "          3       0.23      0.44      0.30        94\n",
      "          4       0.11      0.05      0.07       134\n",
      "          5       0.11      0.06      0.07       109\n",
      "          6       0.05      0.07      0.06        57\n",
      "          7       0.56      0.72      0.63       148\n",
      "          8       0.38      0.47      0.42        93\n",
      "\n",
      "avg / total       0.28      0.35      0.31      1000\n",
      "\n",
      "0.353\n",
      "[[ 81   2   7   2   2   2   2   2   3]\n",
      " [  0   0  24   3  30   3   0  70   0]\n",
      " [  0   5  63  49   0   2   0   6   7]\n",
      " [  0   0   4  41   0  16   0   1  32]\n",
      " [ 38   2   8   5   7   0  68   1   5]\n",
      " [  6   6   5  66   1   6   3   2  14]\n",
      " [ 14   4   6   2   3  14   4   1   9]\n",
      " [  1   1  16   2  15   3   0 107   3]\n",
      " [  1   2  16  11   7   9   2   1  44]]\n",
      "====================================================================================================\n",
      "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_density=None, min_samples_leaf=1, min_samples_split=10,\n",
      "            random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.80      0.72       103\n",
      "          1       0.31      0.11      0.16       130\n",
      "          2       0.63      0.30      0.41       132\n",
      "          3       0.58      0.48      0.52        94\n",
      "          4       0.57      0.51      0.54       134\n",
      "          5       0.70      0.63      0.67       109\n",
      "          6       0.25      0.16      0.19        57\n",
      "          7       0.43      0.84      0.57       148\n",
      "          8       0.05      0.09      0.07        93\n",
      "\n",
      "avg / total       0.48      0.46      0.45      1000\n",
      "\n",
      "0.46\n",
      "[[ 82   3   0   2   1   0   4  10   1]\n",
      " [  4  14   0   2   1   0   0  33  76]\n",
      " [  1   4  40  14   1   7   0  47  18]\n",
      " [  0   1   3  45  27  11   0   7   0]\n",
      " [  2  12  11   1  69   0   1  31   7]\n",
      " [  6   5   2   6  10  69   3   5   3]\n",
      " [  9   3   4   1   5   3   9   5  18]\n",
      " [  2   1   0   0   1   3   1 124  16]\n",
      " [ 19   2   3   7   6   5  18  25   8]]\n",
      "====================================================================================================\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_neighbors=10, p=2, weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.93      0.69       103\n",
      "          1       0.94      0.62      0.74       130\n",
      "          2       0.94      0.78      0.85       132\n",
      "          3       0.78      0.81      0.79        94\n",
      "          4       0.95      0.93      0.94       134\n",
      "          5       0.70      0.76      0.73       109\n",
      "          6       0.08      0.02      0.03        57\n",
      "          7       0.67      0.97      0.79       148\n",
      "          8       0.32      0.20      0.25        93\n",
      "\n",
      "avg / total       0.71      0.72      0.70      1000\n",
      "\n",
      "0.725\n",
      "[[ 96   0   0   0   0   0   0   4   3]\n",
      " [  0  80   0   0   2   0   0  48   0]\n",
      " [  0   0 103  17   1   1   0   4   6]\n",
      " [  0   0   0  76   1  12   0   3   2]\n",
      " [  0   4   2   0 124   0   1   2   1]\n",
      " [  8   0   2   5   1  83   0   2   8]\n",
      " [ 25   0   2   0   2   4   1   3  20]\n",
      " [  1   1   0   0   0   2   0 143   1]\n",
      " [ 44   0   0   0   0  17  10   3  19]]\n",
      "====================================================================================================\n",
      "LinearSVC(C=10.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
      "     random_state=None, tol=0.0001, verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.92      0.86       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.80      0.89      0.84       132\n",
      "          3       0.99      0.73      0.84        94\n",
      "          4       0.57      0.90      0.70       134\n",
      "          5       0.49      0.84      0.62       109\n",
      "          6       0.00      0.00      0.00        57\n",
      "          7       0.64      0.97      0.77       148\n",
      "          8       0.79      0.25      0.38        93\n",
      "\n",
      "avg / total       0.58      0.66      0.59      1000\n",
      "\n",
      "0.66\n",
      "[[ 95   0   0   0   0   2   0   4   2]\n",
      " [  0   0   2   0  80   0   0  48   0]\n",
      " [  1   0 117   1   2   5   0   5   1]\n",
      " [  0   0   6  69   5  11   0   2   1]\n",
      " [  4   2   2   0 121   1   1   3   0]\n",
      " [  4   0   4   0   4  92   0   5   0]\n",
      " [ 14   1  12   0   1  18   0  10   1]\n",
      " [  0   1   0   0   0   3   0 143   1]\n",
      " [  1   0   3   0   0  54   8   4  23]]\n",
      "====================================================================================================\n",
      "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.76      0.92      0.83       132\n",
      "          3       0.95      0.74      0.83        94\n",
      "          4       0.57      0.90      0.70       134\n",
      "          5       0.57      0.78      0.66       109\n",
      "          6       0.00      0.00      0.00        57\n",
      "          7       0.64      0.97      0.77       148\n",
      "          8       0.83      0.41      0.55        93\n",
      "\n",
      "avg / total       0.58      0.67      0.60      1000\n",
      "\n",
      "0.673\n",
      "[[ 95   0   1   0   0   1   0   4   2]\n",
      " [  0   0   2   0  80   0   0  48   0]\n",
      " [  1   0 121   1   2   1   0   5   1]\n",
      " [  0   0   6  70   4  11   0   2   1]\n",
      " [  4   2   3   0 121   0   1   3   0]\n",
      " [  4   0   8   3   4  85   0   5   0]\n",
      " [ 19   1  14   0   1  10   0   9   3]\n",
      " [  0   1   1   0   0   2   0 143   1]\n",
      " [  1   0   3   0   0  39   8   4  38]]\n",
      "====================================================================================================\n",
      "Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.001, n_components=200, n_iter=20,\n",
      "       random_state=None, verbose=True)), ('logistic', LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.37      0.93      0.53       103\n",
      "          1       0.50      0.04      0.07       130\n",
      "          2       0.67      0.20      0.30       132\n",
      "          3       0.45      0.80      0.57        94\n",
      "          4       0.33      0.01      0.03       134\n",
      "          5       0.79      0.49      0.60       109\n",
      "          6       0.00      0.00      0.00        57\n",
      "          7       0.43      0.97      0.60       148\n",
      "          8       0.14      0.01      0.02        93\n",
      "\n",
      "avg / total       0.44      0.40      0.32      1000\n",
      "\n",
      "0.401\n",
      "[[ 96   1   0   0   0   0   0   4   2]\n",
      " [  0   5   0   0   0   0   0 125   0]\n",
      " [  6   0  26  78   0   2   0  19   1]\n",
      " [  3   1   2  75   1   3   0   7   2]\n",
      " [ 13   0   1   0   2   0 115   3   0]\n",
      " [ 32   0   2  10   1  53   0  11   0]\n",
      " [ 39   0   6   3   1   0   0   7   1]\n",
      " [  3   2   0   0   0   0   0 143   0]\n",
      " [ 66   1   2   1   1   9   0  12   1]]\n",
      "====================================================================================================\n",
      "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.93      0.71       103\n",
      "          1       0.07      0.01      0.01       130\n",
      "          2       0.94      0.88      0.91       132\n",
      "          3       0.63      0.84      0.72        94\n",
      "          4       0.75      0.95      0.84       134\n",
      "          5       0.52      0.50      0.51       109\n",
      "          6       0.00      0.00      0.00        57\n",
      "          7       0.56      0.97      0.71       148\n",
      "          8       0.53      0.22      0.31        93\n",
      "\n",
      "avg / total       0.54      0.64      0.56      1000\n",
      "\n",
      "0.637\n",
      "[[ 96   1   0   0   0   0   0   4   2]\n",
      " [  0   1   0   0  36   0   0  93   0]\n",
      " [  1   4 116   5   1   1   0   2   2]\n",
      " [  0   0   1  79   2  10   0   1   1]\n",
      " [  0   1   1   1 127   0   0   3   1]\n",
      " [  4   4   2  39   1  54   0   4   1]\n",
      " [ 29   2   3   1   2   6   0   4  10]\n",
      " [  0   1   0   1   0   1   0 144   1]\n",
      " [ 36   1   0   0   0  32   0   4  20]]\n",
      "====================================================================================================\n",
      "SVC(C=100.0, cache_size=1000, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.25, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.93      0.72       103\n",
      "          1       0.89      0.62      0.73       130\n",
      "          2       0.89      0.82      0.85       132\n",
      "          3       0.78      0.80      0.79        94\n",
      "          4       0.92      0.89      0.90       134\n",
      "          5       0.64      0.80      0.71       109\n",
      "          6       0.23      0.05      0.09        57\n",
      "          7       0.65      0.95      0.77       148\n",
      "          8       0.36      0.13      0.19        93\n",
      "\n",
      "avg / total       0.70      0.72      0.69      1000\n",
      "\n",
      "0.721\n",
      "[[ 96   0   1   0   0   1   0   3   2]\n",
      " [  0  80   0   0   2   0   0  48   0]\n",
      " [  0   0 108  16   3   1   0   3   1]\n",
      " [  0   0   0  75   2  12   0   4   1]\n",
      " [  0   8   2   0 119   0   0   3   2]\n",
      " [  3   0   6   5   2  87   0   5   1]\n",
      " [ 29   1   3   0   1   2   3   6  12]\n",
      " [  0   1   1   0   0   3   0 141   2]\n",
      " [ 36   0   1   0   0  31  10   3  12]]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "classifiers = glob(\"./pkl/hog/mnist/*.pkl\")\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = joblib.load(classifier)\n",
    "    print clf\n",
    "    print classification_report(labels, clf.predict(hog_features))\n",
    "    print accuracy_score(labels, clf.predict(hog_features))\n",
    "    print confusion_matrix(labels, clf.predict(hog_features))\n",
    "    print \"=\" * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plan 4\n",
    "# train data : MNIST(feature : No)\n",
    "# test data : captcha 200 images (feature : No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of files is 200\n",
      "(1000, 784)\n",
      "(1000,)\n",
      "escape time :  12.148 s\n",
      "escape time :  0.015 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dikien/anaconda/lib/python2.7/site-packages/skimage/util/dtype.py:107: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  \"%s to %s\" % (dtypeobj_in, dtypeobj))\n"
     ]
    }
   ],
   "source": [
    "# 새로운 200개의 이미지를 test 데이터로 만들자.\n",
    "p = \"./data_test\"\n",
    "md5list = glob(os.path.join(p, \"*.png\"))\n",
    "md5list = [os.path.split(fname)[1] for fname in md5list]\n",
    "print \"the number of files is %s\" %len(md5list)\n",
    "\n",
    "features = []\n",
    "lables = []\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# captcha를 preprossing후 mnist처럼 numpy array로 만들자\n",
    "for fname in md5list:\n",
    "    lable = os.path.split(fname)[1].split(\"_\")[1][:5]\n",
    "    im = io.imread(os.path.join(p, fname))\n",
    "    w, h, _ = im.shape\n",
    "\n",
    "    for x in range(w):\n",
    "        for j in range(h):\n",
    "\n",
    "            if im[x][j][0] == im[x][j][1] and im[x][j][1] == im[x][j][2] and im[x][j][2] == im[x][j][0]:\n",
    "                im[x][j][0] = 255\n",
    "                im[x][j][1] = 255\n",
    "                im[x][j][2] = 255\n",
    "\n",
    "    im_gray = rgb2gray(im)\n",
    "    im_gray = img_as_ubyte(im_gray)\n",
    "    im_gray = morphology.opening(im_gray, square(2))\n",
    "    im_gray_equalize = exposure.equalize_hist(im_gray)\n",
    "\n",
    "    threshold = filters.threshold_otsu(im_gray_equalize).copy()\n",
    "    threshold = im_gray_equalize < threshold\n",
    "    threshold = img_as_ubyte(threshold)\n",
    "\n",
    "    bw = morphology.closing(im_gray_equalize < threshold, square(3))\n",
    "    cleared = bw.copy()\n",
    "\n",
    "    im_th = cleared\n",
    "    ctrs, hier = cv2.findContours(img_as_ubyte(im_th.copy()), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "    rects = sorted(rects, key=lambda tup: tup[0])\n",
    "\n",
    "    if len(rects) != 5:\n",
    "        continue\n",
    "\n",
    "\n",
    "    for rect, l in zip(rects, lable):\n",
    "        # Draw the rectangles\n",
    "        cv2.rectangle(threshold, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 1) \n",
    "\n",
    "        # Make the rectangular region around the digit\n",
    "        roi = threshold[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "        roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        roi = morphology.closing(roi, square(4))\n",
    "        \n",
    "        features.append(roi.ravel())\n",
    "        lables.append([l])\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(lables, 'int').ravel()\n",
    "\n",
    "# features, lables의 차원을 출력\n",
    "print features.shape\n",
    "print labels.shape\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "def scale(X, eps = 0.001):\n",
    "    # scale the data points s.t the columns of the feature space\n",
    "    # (i.e the predictors) are within the range [0, 1]\n",
    "    return (X - np.min(X, axis = 0)) / (np.max(X, axis = 0) + eps)\n",
    "\n",
    "features = features.astype(\"float32\")\n",
    "features = scale(features)\n",
    "\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.15      0.92      0.26       132\n",
      "          3       0.00      0.00      0.00        94\n",
      "          4       0.71      0.04      0.07       134\n",
      "          5       0.03      0.02      0.02       109\n",
      "          6       0.00      0.00      0.00        57\n",
      "          7       0.00      0.00      0.00       148\n",
      "          8       0.00      0.00      0.00        93\n",
      "\n",
      "avg / total       0.12      0.13      0.05      1000\n",
      "\n",
      "0.129\n",
      "[[  0   1  99   1   0   2   0   0   0]\n",
      " [  0   0  17  80   1  19   0   0  13]\n",
      " [  0   4 122   0   0   6   0   0   0]\n",
      " [  0   0  87   0   0   7   0   0   0]\n",
      " [  0   1 122   0   5   6   0   0   0]\n",
      " [  0   4 102   0   1   2   0   0   0]\n",
      " [  0   2  45   2   0   7   0   1   0]\n",
      " [  0   1 143   0   0   4   0   0   0]\n",
      " [  0   1  81   0   0  11   0   0   0]]\n",
      "====================================================================================================\n",
      "DecisionTreeClassifier(compute_importances=None, criterion='gini',\n",
      "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "            min_density=None, min_samples_leaf=1, min_samples_split=5,\n",
      "            random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.88      0.78       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.15      0.22      0.18       132\n",
      "          3       0.18      0.47      0.26        94\n",
      "          4       0.00      0.00      0.00       134\n",
      "          5       0.63      0.68      0.65       109\n",
      "          6       0.19      0.53      0.28        57\n",
      "          7       0.47      0.16      0.24       148\n",
      "          8       0.01      0.01      0.01        93\n",
      "\n",
      "avg / total       0.26      0.29      0.25      1000\n",
      "\n",
      "0.293\n",
      "[[91  0  2  2  2  4  1  1  0]\n",
      " [ 1  0 37 75  0  0  8  9  0]\n",
      " [ 3  0 29 62  8  2 20  4  4]\n",
      " [ 3  0  7 44  2 28  7  2  1]\n",
      " [ 4  0 85 27  0  0 14  2  2]\n",
      " [16  1  4  2  2 74  1  5  4]\n",
      " [ 8  0  5  2  0  5 30  3  4]\n",
      " [ 1  0 15 31  0  2  1 24 74]\n",
      " [ 4  0  6  3  0  2 76  1  1]]\n",
      "====================================================================================================\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_neighbors=5, p=2, weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.30      0.96      0.46       103\n",
      "          1       0.09      0.02      0.04       130\n",
      "          2       0.58      0.91      0.71       132\n",
      "          3       0.45      0.91      0.60        94\n",
      "          4       0.00      0.00      0.00       134\n",
      "          5       1.00      0.09      0.17       109\n",
      "          6       0.75      0.05      0.10        57\n",
      "          7       0.13      0.01      0.02       148\n",
      "          8       0.25      0.54      0.34        93\n",
      "\n",
      "avg / total       0.36      0.37      0.26      1000\n",
      "\n",
      "0.373\n",
      "[[ 99   2   0   0   1   0   0   0   1]\n",
      " [  1   3   1  16   1   0   0  12  96]\n",
      " [  4   4 120   1   0   0   1   0   2]\n",
      " [  6   0   0  86   1   0   0   1   0]\n",
      " [124   1   3   0   0   0   0   0   6]\n",
      " [ 21   4   1  69   2  10   0   0   2]\n",
      " [ 32   2   2   0   1   0   3   0  17]\n",
      " [  1  18  79  21   2   0   0   2  25]\n",
      " [ 38   1   0   0   4   0   0   0  50]]\n",
      "====================================================================================================\n",
      "LinearSVC(C=10.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
      "     random_state=None, tol=0.0001, verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.04      0.16      0.06       132\n",
      "          3       0.00      0.00      0.00        94\n",
      "          4       0.00      0.00      0.00       134\n",
      "          5       0.07      0.05      0.06       109\n",
      "          6       0.01      0.02      0.01        57\n",
      "          7       0.00      0.00      0.00       148\n",
      "          8       0.00      0.00      0.00        93\n",
      "\n",
      "avg / total       0.01      0.03      0.01      1000\n",
      "\n",
      "0.027\n",
      "[[  0   0  99   1   0   1   0   1   1]\n",
      " [  0   0  17 102   0   0   0  11   0]\n",
      " [  0   0  21  50   0  33  28   0   0]\n",
      " [  0   0  86   0   0   7   1   0   0]\n",
      " [  0   0 122   0   0   9   0   1   2]\n",
      " [  0   0 101   1   0   5   1   1   0]\n",
      " [  0   0  46   3   0   5   1   2   0]\n",
      " [  0   0   5  45   0   1  97   0   0]\n",
      " [  0   0  86   0   0   7   0   0   0]]\n",
      "====================================================================================================\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.03      0.08      0.04       132\n",
      "          3       0.15      0.88      0.26        94\n",
      "          4       0.00      0.00      0.00       134\n",
      "          5       0.29      0.05      0.08       109\n",
      "          6       0.09      0.04      0.05        57\n",
      "          7       0.00      0.00      0.00       148\n",
      "          8       0.00      0.00      0.00        93\n",
      "\n",
      "avg / total       0.06      0.10      0.04      1000\n",
      "\n",
      "0.101\n",
      "[[  0   0  95   7   0   1   0   0   0]\n",
      " [  0   0  17  89   0   0   0  20   4]\n",
      " [  0   0  11  98   0   4  19   0   0]\n",
      " [  0   0  10  83   0   1   0   0   0]\n",
      " [  0   0 120   0   0   1   0   1  12]\n",
      " [  0   0   8  95   0   5   0   0   1]\n",
      " [  0   0  41  10   0   3   2   0   1]\n",
      " [  0   0   1 145   0   1   1   0   0]\n",
      " [  0   0  82  10   0   1   0   0   0]]\n",
      "====================================================================================================\n",
      "Pipeline(steps=[('rbm', BernoulliRBM(batch_size=10, learning_rate=0.01, n_components=200, n_iter=20,\n",
      "       random_state=None, verbose=True)), ('logistic', LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001))])\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.01      0.02       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.13      0.94      0.23       132\n",
      "          3       0.00      0.00      0.00        94\n",
      "          4       0.06      0.01      0.01       134\n",
      "          5       0.00      0.00      0.00       109\n",
      "          6       0.00      0.00      0.00        57\n",
      "          7       0.00      0.00      0.00       148\n",
      "          8       0.00      0.00      0.00        93\n",
      "\n",
      "avg / total       0.05      0.13      0.03      1000\n",
      "\n",
      "0.126\n",
      "[[  1   0 101   0   1   0   0   0   0]\n",
      " [  0   0 120   9   1   0   0   0   0]\n",
      " [  0   0 124   4   4   0   0   0   0]\n",
      " [  0   0  94   0   0   0   0   0   0]\n",
      " [  1   0 132   0   1   0   0   0   0]\n",
      " [  0   0 104   0   5   0   0   0   0]\n",
      " [  0   0  55   0   2   0   0   0   0]\n",
      " [  2   0 144   1   1   0   0   0   0]\n",
      " [  0   0  92   0   1   0   0   0   0]]\n",
      "====================================================================================================\n",
      "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, n_estimators=80, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.93      0.65       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.48      0.84      0.61       132\n",
      "          3       0.30      0.81      0.44        94\n",
      "          4       0.14      0.01      0.01       134\n",
      "          5       0.46      0.06      0.10       109\n",
      "          6       1.00      0.04      0.07        57\n",
      "          7       0.06      0.01      0.01       148\n",
      "          8       0.28      0.86      0.42        93\n",
      "\n",
      "avg / total       0.30      0.37      0.25      1000\n",
      "\n",
      "0.373\n",
      "[[ 96   0   2   0   1   0   0   1   3]\n",
      " [  1   0   0  77   1   0   0   3  48]\n",
      " [  3   0 111   1   0   0   0   4  13]\n",
      " [  3   0   0  76   1   7   0   0   7]\n",
      " [ 50   0   3   0   1   0   0   1  79]\n",
      " [ 14   0   3  76   1   6   0   4   5]\n",
      " [ 16   0   3   0   1   0   2   2  33]\n",
      " [  3   0 103  23   1   0   0   1  17]\n",
      " [  6   0   6   0   0   0   0   1  80]]\n",
      "====================================================================================================\n",
      "SVC(C=10.0, cache_size=1000, class_weight=None, coef0=0.0, degree=3,\n",
      "  gamma=0.03125, kernel='rbf', max_iter=-1, probability=False,\n",
      "  random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       103\n",
      "          1       0.00      0.00      0.00       130\n",
      "          2       0.13      0.97      0.23       132\n",
      "          3       0.00      0.00      0.00        94\n",
      "          4       0.00      0.00      0.00       134\n",
      "          5       0.00      0.00      0.00       109\n",
      "          6       0.00      0.00      0.00        57\n",
      "          7       0.00      0.00      0.00       148\n",
      "          8       0.00      0.00      0.00        93\n",
      "\n",
      "avg / total       0.02      0.13      0.03      1000\n",
      "\n",
      "0.128\n",
      "[[  0   1 102   0   0   0   0   0   0]\n",
      " [  0   0 130   0   0   0   0   0   0]\n",
      " [  0   4 128   0   0   0   0   0   0]\n",
      " [  0   0  94   0   0   0   0   0   0]\n",
      " [  0   1 133   0   0   0   0   0   0]\n",
      " [  0   4 105   0   0   0   0   0   0]\n",
      " [  0   2  55   0   0   0   0   0   0]\n",
      " [  0   1 147   0   0   0   0   0   0]\n",
      " [  0   1  92   0   0   0   0   0   0]]\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dikien/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "classifiers = glob(\"./pkl/scale/mnist/*.pkl\")\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = joblib.load(classifier)\n",
    "    print clf\n",
    "    print classification_report(labels, clf.predict(features))\n",
    "    print accuracy_score(labels, clf.predict(features))\n",
    "    print confusion_matrix(labels, clf.predict(features))\n",
    "    print \"=\" * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=labels):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(set(list(labels))))\n",
    "    plt.xticks(tick_marks, list(set(list(labels))), rotation=45)\n",
    "    plt.yticks(tick_marks, list(set(list(labels))))\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of files is 200\n",
      "(1000, 784)\n",
      "(1000,)\n",
      "escape time :  13.41 s\n",
      "escape time :  0.953 s\n",
      "Confusion matrix, without normalization\n",
      "[[ 96   3   0   0   0   0   2   1   1]\n",
      " [  0 130   0   0   0   0   0   0   0]\n",
      " [  0   0 124   1   1   0   5   1   0]\n",
      " [  0   1   0  90   0   1   0   0   2]\n",
      " [  0   1   1   2 128   0   2   0   0]\n",
      " [  0   2   0   1   0  99   5   1   1]\n",
      " [  2   2   1   2   1   0  49   0   0]\n",
      " [  0   0   0   1   1   1   1 143   1]\n",
      " [  0   1   0   1   0   1   6   0  84]]\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAUoAAAEpCAYAAAD1SWvxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHGWdx/HPdxICSThDJIQbFZBLSFxOYWZYWDayHLKi\n",
       "GFxAQEFRZAFdYFGIIaCwC+ii4EswGOUSEVCUIxFNJgjKlWAgBATlDuFKkCNIjt/+UTWhmcx093R3\n",
       "1VTPfN+86kVXdfXzezrJ/OapqudQRGBmZj1r6esKmJkVnROlmVkFTpRmZhU4UZqZVeBEaWZWgROl\n",
       "mVkFTpQDiKShkm6WtEjSz+oo5zOSbm9k3fqKpD0lzevrelixyf0oi0fSYcDJwFbA68Bs4JyI+EOd\n",
       "5R4OfBnYLSKW113RgpO0HPhgRPy1r+tizc0tyoKRdDJwETAJWA/YGPg+cGADit8UeGwgJMkS6vEN\n",
       "aXCeFbEmFhHeCrIBa5G0ID9R5pxVge8Az6XbRcCQ9L124FmS1ugC4Hngs+l73wT+AbyTxjgamAD8\n",
       "tKTszYDlQEu6/1ngCeDvwF+Bw0qOzyz53O7AvcAi4B6SFmvne9OBicCdaTm3A+v28N066/814MW0\n",
       "/h8H9gMeA14BTis5f2fgbmBheu7FwCrpex3pd3kj/b6fLCn/v4D5wJT02DPpZz6QxhiT7m8AvAS0\n",
       "9vW/DW99u7lFWSy7AasBN5Y55wySBLFDuu0MfL3k/VHAmiQ/5McA35e0VkScBZwLXBsRa0TEZKDH\n",
       "+y6ShgPfBcZFxJpp3WZ3c94I4DckyXsEcCHwG0nrlJw2niS5rgcMAb5a5vuNIvllMBo4E7gc+Aww\n",
       "BtgTOFPSpum5S4ETgXXT+u0NHA8QEa3pOR9Ov+/PS8pfB9gEOK40cEQ8AZwKXClpKHAFcEVEdJSp\n",
       "rw0ATpTFsi7wcpS/ND4MmBgRL0fEyyQtxcNL3l+Svr8sIm4laVFtlb4n3nsp2uNlaWo5sL2koRGx\n",
       "ICLmdnPOvwGPRsRVEbE8Iq4F5vHurYIgSTaPR8TbwHXAjmViLiG5H7sM+BlJ8v1ORLyZxp/b+fmI\n",
       "eCAi7knjPgX8EGir4judFRFL0vq8R0RcDjxO0jIeRfKLyQY4J8pieQUYKanc38sGwFMl+0+nx1aU\n",
       "0SXRvgWs3tuKRMSbwKHAF4DnJf1a0lbdnLpBWodST3Wp0wslrxdXqM8rEREl50JyG6H088MBJG2Z\n",
       "1mu+pNeAc0h+2ZTzUkS8U+Gcy4FtgYsjYkmFc20AcKIslrtJ7iMeXOac50nuJXbaJD1WizeAYSX7\n",
       "65e+GRFTI2Lf9Pg84LJuyniO5CFRqU3T41m7lKSF+cGIWIuk9Vfp33TZbh6SVie5jXA58M0utxBs\n",
       "gHKiLJCIeI3kvtz3JR0kaZikVSR9TNJ56WnXAF+XNFLSyPT8n9YYcjbQKmljSWsBp3e+IWm9tA7D\n",
       "SS6H3wSWdVPGrcCWksZLGizpUOBDwK9Lzql0iV+r1Uke1Lwl6UPAF7u8v4DkAU1vfBe4JyKOJbn3\n",
       "+oO6a2lNz4myYCLiQpKn1l8nefL7NMkDis4HPJOA+4A/p9t96bEVRZQrvvT9iPgtyX3AP5M8tb65\n",
       "5P0W4CSSluErJA9Svti1nIh4BdgfOAV4meRBzf4R8WoPdQoq17Hcfqmvktyz/TvJ/clru5w/AZgi\n",
       "aaGkQ8rEDgBJBwH78u73PBkYK2l8mTrYAOAO52ZmFbhFaWZWgROlmVkFTpRmZhU4UZqZVdCnkwJI\n",
       "8pMksyYVEQ3r9lVLLmhk/Er6fPaUnc75fa8/89wdP2bDvT/bq8/87pTWyid1ce7Z3+S/v3FWrz4z\n",
       "eFBtjfRJEyfw9TMn1PTZIsbJM1atcZYt7/3v6XPOnsAZ3+h9rJZe/kgX/e9p2JDGX4yuNuaEqs99\n",
       "e9bFDY9fTp8nSjMzAJRbA7HXnCjNrBjKTnHQt5oyUa6xebnJZxpnz9ZKE9E0Tmtbe7+Kk2esPL/T\n",
       "nq35xOqPf08VFbhF2acjcyRFLfcoa1HLPcpa1HqP0vJXyz3KWvX2HmXRDRvS0vCHOavtdErV5799\n",
       "7wUD62GOmRlQ6BalE6WZFUOB71FmWjNJ4yTNk/QXSadmGcvMmpxU/ZazzBKlpEHA94BxwDbAeElb\n",
       "ZxXPzJqcWqrfun5UmixpgaQ5JcfOlvSgpNmS7pC0cXp8M0mLJc1Kt0sqVS3LFuXOwOMR8WQ6nf61\n",
       "wEEZxjOzZtYyqPptZVeQNMpKnR8RO0TEjsBNQOnokccjYky6HV+xajV/qco2BJ4p2X82PWZmtrI6\n",
       "Lr0jYibJssWlx14v2V2dZGLpmmT5MMfjuM2sehk8zJF0DskqpW8Bu5a8tbmkWcBrwNcj4s5y5WSZ\n",
       "KJ8DNi7Z35ikVfnek+748YrXa2y+I2u+P5/O5GZWvY4Z0+mYMT3bIGUS5bJFf2P5oid7XWREnAGc\n",
       "Iek04CLgKJLF+DaOiIWSxgI3Sdq2Swv0vVXLqsO5pMHAoySL0j9Psk7y+Ih4pOQcdzi3PuMO57XL\n",
       "pMN5+8Sqz397+pkrxZe0GXBzRGzfTfmbALdExHbdvPd74JSIeKCneJn9VEfEUuDLwO0kS4r+rDRJ\n",
       "mpm9Rx1PvbstTtqiZPcgYFZ6fGTaKwdJ7we2AP5arqxMO5xHxK0ky5mamZVXR/9ISdcAbcBISc+Q\n",
       "POHeT9JWJMssP8G7q2u2AhMlLQGWA8dFxKJy5XtkjpkVQx0PcyKiuyWFJ/dw7g3ADb0p34nSzIrB\n",
       "Y73NzCoo8FhvJ0ozKwa3KM3MKnCL0sysArcozcwq6H6yi0JwojSzYvClt5lZBU6UPev4r/Zc4qyz\n",
       "/0W5xFn465NyiWP1G9TfBmA3O9+jNDOrwC1KM7MK3KI0M6vALUozswrcojQzK09OlGZm5TlRmplV\n",
       "Utw8melytWZmVZNU9dbNZydLWiBpTsmx/5H0iKQHJd0gaa2S906X9BdJ8yTtW6lumSbK7ipvZtad\n",
       "ehIlcAUwrsuxqcC2EbED8BhwehpnG+BQYJv0M5dI5R+5Z92i7K7yZmYrqSdRRsRMYGGXY9MiYnm6\n",
       "+ydgo/T1QcA1EbEkIp4EHgd2Lle3TBNld5U3M+uOWlT1VoOjgVvS1xsAz5a89yywYbkP+2GOmRVC\n",
       "uafeSxc8wtIFta12LekM4J2IuLrMaWUXee/zRDlp4oQVr1vb2mlta++zuphZ9zpmTKdjxvRMY5RL\n",
       "lKusvw2rrL/Niv1/PHRjtWV+FtgP2Lvk8HPAxiX7G6XHei4nomwirZukzYCbI2L7bt6LxUuyjd/J\n",
       "sweZNc7QVURENKxDj6RY5z+uqvr8hVd+ZqX4XXONpHHABUBbRLxcct42wNUk9yU3BH4LfDDKJMM+\n",
       "b1GamUF9Hc4lXQO0ASMlPQOcRfKUewgwLS377og4PiLmSroOmAssBY4vlyQh40RZUvl108qfGRFX\n",
       "ZBnTzJpUHe3TiBjfzeHJZc4/Fzi32vIzTZQ9VN7MbCUewmhmVoETpZlZBU6UZmaVFDdPOlGaWTG4\n",
       "RWlmVoETpZlZBU6UZmYV1DjZRS6cKM2sENyiLIC8xmCP+HSPgwEa7pVrjsotVl7y/GH5x5JlucUa\n",
       "MjifxQSKnGwqKXLdB0yiNLNic6I0M6ukuHnSidLMisEtSjOzCpwozcwqcKI0M6ugyIkynz4LZmaV\n",
       "qBdb149KkyUtkDSn5NgISdMkPSZpqqS10+ObSVosaVa6XVKpak6UZlYI9azrDVwBjOty7DRgWkRs\n",
       "CdyR7nd6PCLGpNvxleqWaaKUtLGk30t6WNJDkr6SZTwza171JMqImAks7HL4QGBK+noK8PFa65Z1\n",
       "i3IJcFJEbAvsCnxJ0tYZxzSzJiRVv1VpVEQsSF8vAEaVvLd5etk9XdIelQrKes2cF4AX0tdvSHoE\n",
       "2ACobSVzM+u3WspMivHW039m8TN/rrnsiAhJnSstPg9sHBELJY0FbpK0bUS83tPnc3vqna65Owb4\n",
       "U14xzax5lHvqPXzTHRi+6Q4r9l+9q6o1wBdIWj8iXpA0GngRICLeAd5JXz8g6QlgC+CBngrK5WGO\n",
       "pNWB64ETI+KNPGKaWXPJ4NL7V8CR6esjgZuSOBopaVD6+v0kSfKv5QrKvEUpaRXgF8CVEXFT1/cn\n",
       "TZyw4nVrWzutbe1ZV8nMeqljxnQ6ZkzPNEa5S+9KJF0DtAEjJT0DnAl8G7hO0jHAk8Cn0tNbgYmS\n",
       "lgDLgeMiYlHZ8iOi3Pt1UdKWngK8EhErzXMmKRYvyS5+X/A0a/XxNGv1yevPb+gqIiIaFkxSbPPf\n",
       "t1d9/txz/7Wh8SvJ+m/vo8B/AHuVdO7s2tfJzKzefpSZyvqp9524U7uZVaHAIxg91tvMiqHIY72d\n",
       "KM2sEJwozcwqKHCedKI0s2Jwi9LMrIIC50knSjMrBrcozcwqKHCedKI0s2KoZwhj1pwozawQfOld\n",
       "AFmOaS/16rVH5xIH4GPfvyu3WLd+afdc4uT19wSw6iqDcouVl2XLm3fuhALnyYGTKM2s2NyiNDOr\n",
       "oMB50onSzIrBLUozswoKnCc9BZqZFUO981FKOlHSnHRp7BPTYyMkTZP0mKSpktaupW5OlGZWCPUk\n",
       "SknbAZ8DdgJ2APaX9AHgNGBaRGwJ3JHu95oTpZkVQp2Li30I+FNEvB0Ry4AZwCeAA0mWoyH9/8dr\n",
       "qZsTpZkVQp2X3g8Be6aX2sOA/YCNgFERsSA9ZwEwqpa6ZfowR9JqJJl9VWAI8MuIOD3LmGbWnMo9\n",
       "zFn4lwdY9PisHt+PiHmSzgOmAm8Cs4FlXc4JSTX1yM96zZy3Je0VEW9JGgzcKWmPdC0dM7MVynUP\n",
       "GrHlRxix5UdW7D91+8qrnUbEZGByWtY5wLPAAknrR8QLkkYDL9ZSt8wvvSPirfTlEGAQ8GrWMc2s\n",
       "+QxqUdVbdyStl/5/E+DfgauBXwFHpqccCdxUS90y70cpqQV4APgAcGlEzM06ppk1nwb0o7xe0rrA\n",
       "EuD4iHhN0reB6yQdAzwJfKqWgjNPlBGxHNhR0lrA7ZLaI2J65/uTJk5YcW5rWzutbe1ZV8nMeqlj\n",
       "xnRmdkzPNEa9I3MiorWbY68C+9RVMKA8Z2uR9A1gcUT8b7ofi5fkEz+v75nnMCzPHlSfIg+Zq1Ve\n",
       "swetvmoLEdGwP0BJMe6SP1Z9/m3H79rQ+JVkeo9S0sjOnvCShgL/AvT86MrMBqx6R+ZkKetL79HA\n",
       "lPQ+ZQvw04i4I+OYZtaEitzA7zFRSrq4zOciIr5SqfCImAOMraViZjawiOJmynItyvuBzhsend8g\n",
       "0tfNO42ymRVSgZfM6TlRRsSPS/clDY+INzOvkZkNSEV+uFbxYY6k3SXNBeal+ztKuiTzmpnZgFLn\n",
       "pBiZquap93eAccDLABExG2jLslJmNvC0SFVveavqqXdEPN2lWbw0m+qY2UBV4CvvqhLl05I+CiBp\n",
       "CPAV4JFMa2VmA05T36MEvgh8CdgQeA4Yk+6bmTVMke9RVmxRRsRLwGE51MXMBrBBBW5RVkyU6boT\n",
       "3wF2I+k/eRdwUkT8NeO6NaU8xyr/+ou75RZrnYPKjT9onIW/PCGXOJDfuGigx6nBmjVOFpr90vtq\n",
       "4DqS4YgbAD8HrsmyUmY28LSo+i33ulVxztCI+GlELEm3K4HVsq6YmQ0sTTkphqQRJMMVb5V0Ou+2\n",
       "Ig8Fbs2hbmY2gBT4yrvsPcoHeO+Y7mPT/3eO9a5pfVwzs+7U01KUtBVwbcmh9wNnAuuQrPf9Unr8\n",
       "9Ii4rbfllxvrvVlvCzMzq1U99x4j4lGSroudy888B9wAHA1cGBEX1lO3qkbmSNoO2IaSe5MR8ZN6\n",
       "ApuZlWrgvcd9gMcj4hklhdZdcDWTYkwALga+B+wFnA8cWG9gM7NS6sVWwad595lKACdIelDSjzpX\n",
       "XOitalqUhwA7AA9ExFGSRgFX1RLMzKwn5Sa7mP/wvcyfe2/FMtJh1gcAp6aHLgUmpq/PBi4Ajult\n",
       "3apJlIsjYpmkpelKii8CG1cbQNIg4D7g2Yg4oLcVNLOBodyV9wbb7cQG2+20Yn/WLy7t6dSPAfen\n",
       "IwqJiBffLV+XAzfXUrdqEuW9ktYBLiNJeG+SjM6p1onAXGCN3lfPzAaKBt2jHE/JgBhJoyNifrp7\n",
       "MDCnlkKrGet9fPryB5JuB9aMiAerKVzSRsB+wDnAybVU0MwGhnrzpKThJA9yPl9y+DxJO5Lcq/wb\n",
       "cFwtZZfrcP4RelgbR9LYiHigivIvAr4GrFlL5cxs4Kh3nHq6VM3ILseOqKvQVLkW5QWUX0Rsr3IF\n",
       "S9ofeDEiZklqr6FuZjaAFHlSjHIdztvrLHt34EBJ+5H0v1xT0k+6ZvhJEyeseN3a1k5rW71hzazR\n",
       "OmZMp2PG9ExjVDPxRF9RHtOCSWoDvtr1qbekWLwkn6mu8pz+LC85zhLGyIO/l0scT7PWHIauIiKi\n",
       "YV9KUpxwY/ULJ1x88NYNjV9JVSNzGqT/ZSoza5gi/y7JJVFGxAxgRh6xzKw5FTlRVjOEsUXS4ZLO\n",
       "TPc3kbRz9lUzs4GkyPNRVnP/9BKSZSA61815Iz1mZtYwRZ7hvJpL710iYoykWQAR8aqkVTKul5kN\n",
       "MAXuHVRVonwnHa8NgKT3Acuzq5KZDUTlJsXoa9Vcel8M3AisJ+lc4A/AtzKtlZkNOC292PJWzVjv\n",
       "KyXdD+ydHjooIqrv8GRmVoUCNyirWtd7E5IZgzqnJwpJm0TE05nWzMwGlCJfeldzj/IW3u0svhqw\n",
       "OfAosG1WlTKzgafAebKqS+/tSvcljQW+lFmNzGxAGlzgHue9HpkTEQ9I2iWLymQpr2G9eY7pbclx\n",
       "VGheY7B3nXRHLnEAZpzanlusFhV5yodiaOoWpaRTSnZbgLEkS0GamTVMgRuUVT1pX71kGwL8Gjgo\n",
       "y0qZ2cCjXvzX7eeltSVdL+kRSXMl7SJphKRpkh6TNDWTVRjTjuZrRsQp5c4zM6tXA1qU3wVuiYhD\n",
       "JA0GhgNnANMi4nxJpwKnpVvv6tbTG5IGR8Qy4KMq8tTDZtYv1DPWO10hds+ImAwQEUsj4jXgQGBK\n",
       "etoU4OO11K1ci/IekvuRs4FfSvo58Fb6XkTEDbUENDPrTp3tsc2BlyRdAewA3A/8JzAqIhak5ywA\n",
       "RtVSeLlE2Vnr1YBXgH/u8r4TpZk1TLlL78dn/ZEnZv+p3McHkzTsvhwR90r6Dl0usSMiJNXUVaRc\n",
       "onyfpJOpcR1cM7PeKNeg3GLsrmwxdtcV+9Om/F/XU54Fno2Ie9P964HTgRckrR8RL0gaDbxYS93K\n",
       "PfUeBKzBe596l25mZg3TIlW9dRURLwDPSNoyPbQP8DDJ0Osj02NHAjfVUrdyLcoXIuKbtRRaStKT\n",
       "wN+BZcCSiPDs6Ga2kgY89T4BuErSEOAJ4CiSBt91ko4BngQ+VUvBeayZE0B7RLyaQywza1L19q2J\n",
       "iAeBnbp5a5/6Si6fKOsuvIS7F5lZWS0FThM93qOMiFcaFCOA30q6T9LnG1SmmfUzg1qq3/KWx6X3\n",
       "RyNifrqExDRJ8yJiZuebkyZOWHFia1s7rW3tOVTJzHqjY8Z0OmZMzzRGkeejVER+M9BIOgt4IyIu\n",
       "SPdj8ZJ84i/LafqgPGcPyvnvLpc4/XX2oCGD+9fsQcOGtBARDftHISl++Mcnqz7/2F03a2j8SjL9\n",
       "25M0TNIa6evhwL64X6aZdaOe7kFZy/rSexRwY9oaGQxcFRFTM45pZk2owFfe2SbKiPgbsGOWMcys\n",
       "fyjyzYk8HuaYmVVU5EnKnCjNrBCKmyadKM2sIIrcPciJ0swKobhp0onSzAqiwA1KJ0ozKwY/zDEz\n",
       "q8Ddg8zMKnCLsoy8xmDnJc/x13n+0bWQT7A/fn3vXOIA/HLOc7nFOmj7DXOL1awa8dQ7XWL7PpJl\n",
       "IQ6QNAH4HPBSesrpEXFbb8vt80RpZgYNu/Q+EZhLsowNJNM8XhgRF9ZTaJFvC5jZACKp6q2Hz28E\n",
       "7Adczru9jUQDeh45UZpZIagXWw8uAr4GLC85FsAJkh6U9CNJa9dSNydKMysEqfpt5c9qf+DFiJjF\n",
       "e3PppcDmJJPzzAcuqKVuvkdpZoVQbs2cOff+gTn33lXu47sDB0raD1gNWFPSTyLiiM4TJF1Osnxt\n",
       "r+U6w/lKwaV44x/LK5/YRHKc4Dzfp945fa88u4j4qXfthq6ihs9wfvOcF6o+/4Dt1+8xvqQ24Kvp\n",
       "U+/RETE/PX4SsFNEHNbb+rlFaWaFoMaN9has6M92vqQd0v2/AcfVUqATpZkVQqMuJiJiOjA9fX14\n",
       "I8rMes2ctSVdL+kRSXMl7ZplPDNrXi2o6i1vWbcovwvcEhGHSBoMDM84npk1qQKPYMwuUUpaC9gz\n",
       "Io4EiIilwGtZxTOz5lbkRJnlpffmwEuSrpD0gKTLJA3LMJ6ZNTH14r+8ZZkoBwNjgUsiYizwJnBa\n",
       "hvHMrIkNkqre8pblPcpnSWbwuDfdv55uEuU5Z09Y8XrP1nZa29ozrJKZ1aJjxnQ6ZkzPNEaRL70z\n",
       "7XAuqQP4XEQ8lk53NDQiTi153x3O6+AO5/Vxh/PaZdHh/PfzXqn6/L0+tG5D41eS9VPvE4CrJA0B\n",
       "ngCOyjiemTWpPBsZvZVpooyIB4GdsoxhZv1DXzykqZZH5phZIRT5HqUTpZkVQoHzpBOlmRVDI9bM\n",
       "yYoTpZkVQnHTpBOlmRVFgTOlE6WZFYKfepuZVVDgW5ReXMzMiqGeVRglrSbpT5Jmp3Pffis9PkLS\n",
       "NEmPSZrqVRjNrKnVs653RLwN7BUROwIfBvaStAfJ/BLTImJL4A5qnJinzy+9BxV53FLBtdB3C8Nl\n",
       "Jc/F7g7cboPcYq2z05dzifPqPRfnEicL9V56R8Rb6cshwCBgIXAg0JYen0KyRESvk6VblGZWCPVc\n",
       "egNIapE0G1gA/D4iHgZGRcSC9JQFwKha6tbnLUozM6Du7kERsRzYMV1d4XZJe3V5PyTVdMniRGlm\n",
       "hVCue9B9d8/kvj/OrKqciHhN0m+AjwALJK0fES9IGg28WFPd8rwntFJwKRYv6X/32fLSl3931jsj\n",
       "dj4hlzh53aMcNqSl4fNRznrq71WfP2bTNd8TX9JIYGlELJI0FLgd+Cbwr8ArEXGepNOAtSOi1/co\n",
       "3aI0s0KoM+uOBqZIaiF59vLTiLhD0izgOknHAE8Cn6qlcCdKMyuGOjJlRMwhWaOr6/FXgX1qLznh\n",
       "RGlmheAhjGZmFQzYIYyStpI0q2R7TdJXsoxpZs2p3n6UWcp6zZxHgTGQdAYFngNuzDKmmTWpArco\n",
       "87z03gd4IiKeyTGmmTUJ36NMfBq4Osd4ZtZEinyPMpdEma7rfQBwatf3Jk2csOJ1a1s7rW3teVTJ\n",
       "zHqhY8Z0OmZMzzRGkRNlLiNzJB0EfDEixnU57pE5dfDInObhkTnlSYpHnn+z6vO33mB4Q+NXktel\n",
       "93jgmpximVkTKnKLMvNp1iQNJ3mQc0PWscyseQ3Y7kEAEfEmMDLrOGbW5ArcovTIHDMrBHcPMjOr\n",
       "oMj3KJ0ozawQCpwnnSjNrCAKnCmdKM2sEIp8j9KrMJpZIUjVbyt/VpMlLZA0p+TYBEnPlsxeNm7l\n",
       "T1bHidLMCqHOfpRXAF0TYQAXRsSYdLut1ro5UZpZMdSRKSNiJrCwh1LrNmDuUeY1LlpF7uNQh7y+\n",
       "V57j1/+xZHlusRbe+71c4hx6xb25xMlCSzb/xk6QdARwH3BKRCyqpRC3KM2sEDIYwngpsDmwIzAf\n",
       "uKDWug2YFqWZFVu5BuXdd87g7js7elVeRLz4btm6HLi51ro5UZpZQfScKXfbo53d9mhfsX/R+edU\n",
       "Lk0aHRHz092DgTnlzi/HidLMCqGeW5SSrgHagJGSngHOAtol7Ujy9PtvwHG1lu9EaWaFUM+jnIgY\n",
       "383hyXUU+R5OlGZWCEXuMOJEaWaFUOQhjE6UZlYMxc2T2fajlHS6pIclzZF0taRVs4xnZs2ryEtB\n",
       "ZJYoJW0GfB4YGxHbA4NI1vY2M1tJPZNiZC3LS++/A0uAYZKWAcOA5zKMZ2ZNrMj3KDNrUUbEqyRD\n",
       "hp4GngcWRcRvs4pnZk2uwNfeWV56fwD4T2AzYANgdUmfySqemTW3AufJTC+9/wm4KyJeAZB0A7A7\n",
       "cFXpSZMmTljxurWtnda29gyrZGa1ePnR+3n50fszjZHR7EENoaymtZK0A0lS3Al4G/gxcE9EfL/k\n",
       "nFi8JJ9ptfrjNGt5Tknmadbqs9qQQbnEyWuatV8duzMR0bB/FJLi1TeXVn3+iOGDGxq/kizvUT4I\n",
       "/IRkHrg/p4d/mFU8M7OsZNrhPCLOB87PMoaZ9Q8FvvL2yBwzK4Yidw9yojSzQnCL0sysggLnSSdK\n",
       "MyuIAmdKLy5mZoWgXvzX7eelcZLmSfqLpFMbWbemTJQdM6b3qzh5xvJ3qs+dHfnEyvM7Zd2RvFr1\n",
       "TIohaRDwPWAcsA0wXtLWjaqbE2UB4uQZy9+pPnfOnJFLnAGZKHuxdWNn4PGIeDIilgDXAgc1qm5N\n",
       "mSjNrB+qL1NuCDxTsv9seqwh/DDHzAqhzn6UmY59zWysd1XBpb4LbmZ1afRY73riS9oVmBAR49L9\n",
       "04HlEXFeQ+rXl4nSzKwRJA0GHgX2Jpn/9h5gfEQ80ojyfeltZk0vIpZK+jJwO8myMz9qVJIEtyjN\n",
       "CkXS6IiY39f1sPfyU+9upH2yso7xQUn/5JUpayPpAEn/mVOs4cphQk5J/wrcIGmTrGNZ7zRFopS0\n",
       "laTdJK2SZRKTtCVARCzLOM4BwA3A/wJTOuNmGO/DkvaRtH7GcfaQdHiWMdI4+wJnA3NziPVx4Dxg\n",
       "vSyTZZokzwNGA1/NKk4aazdJh6f/H5JlrH4jIgq9AZ8guUl7B/BT4ERgrQziHAAsBq4pOTYogzi7\n",
       "A4+QLOMLcAlwRYZ/fvsBDwO/Am4G1sgghoA10jiPAF8ofS+DP78XgZ3T/bWBTYFhGXyvdmAesG9W\n",
       "fz9pnH2Ax4FtgSHAVKA1o1gHkUyk/RPgF8CWWX63/rIVukWZ/rY7FDgmIvYGfglsBPyXpLUaGGcY\n",
       "8CWSxdDekXQlrGhZNvqBl4DzI+KBdH8CMELSag2Og6S9gO8AR0fEgcBSYJdGx4rE6yQ/fJcDu0s6\n",
       "qfO9RsYOI6JYAAAG1klEQVQCXiVZBnm0pJHAjcAPSFrmhzQ41ljg8oiYKmkDSf8iaZdG/ttLDQKO\n",
       "iIiHgeEkDYNtARrZipU0iqSh8ZmIOAJ4DdhB0nqShjYqTn9U6ESZWhPYIn19I/Brkt+6h0lqSP0j\n",
       "4i3gKOBq4BRgaEmyrH4hj+r8keSyu7NLwxBgE5IWGekPf6MsIGnd/UnSaGBX4GSSpPKpRgUp+WFe\n",
       "QvJdpgA7S7pQ0reVakSsiJhH0kq+iKRldA3wb8CtwCckrduIOKllJa+vB44GTgAukbROo4JExO0R\n",
       "cZeklohYCPwGOEvShxv8i+YdYDVgC0lrA3sBR5D8Mj1D0uoNjNWvFDpRRsQ7JGuD/7ukPSNiGfAH\n",
       "YDawR4NjzY+I1yPiZeA4kmR5FYCkj0j6UIPiLIuI10oOvQa8GhEvpcv5nt2o3+4RMTcifpfuHgN8\n",
       "PyL2I0kqBzXqh73kh/lXwAsRcQdwP/BFkkv9aOQPfCTrMe0PnBsRP4yI5RExGViHJFE3yu+AYyX9\n",
       "DLgsIsYDZwJvkIwtbrSQpIi4DbgM2F9SSwMbBAtJ7oufRNLgmBwRB5BcBWwEfLARcfqjQifK1EyS\n",
       "vlFHSGqNiKURcRXJWuEfziJgSbJcImke8DOSH45Gx1maXrI+K+lbJK29SyNicQaxJkXEpPT1j4G1\n",
       "aGxSAXgL2ErS54EvAN8GNpF0XIPjEBFzgdIVPQ8B1gMa1rUmIuaQXGHsAmyeHvsryc/Neo2KUxKv\n",
       "9BfKbJKWcktENGy5yIi4AfgYyYOweemx35FcuW3aqDj9TeE7nEfE22nLLoD/Tlt279DgH4pu4r4s\n",
       "6UGSaZv+JSKebXSM9HJ0CLAnyd/FPhHxWKPjdBP3E8D6wAuNLDcinpf0NPAN4EsRcbOkfwb+0sg4\n",
       "JfEi/TM8Cvga8MmIaOh3Iml9n0VyKfxUemwsyRPqzETELyR9mqSl92SDy35D0kySFuvfgVWBzYAH\n",
       "GxmnP2maDufpg52PkrT03gb+r+SBSBbx1gF+DpwcEX+udH6dsY4iWfP84YzjrAocTnLpdWhEPJRB\n",
       "jI2B9SLi/nS/oS2ibuKJ5On0/PT+ZVZxPkLSA2M1kl4KczKMpQwegnWNsTYwHjiEpLfHGektDetG\n",
       "0yTKTukDkEjvV2Yda9WI+EcOcTL/wUjjrALsCzyRZVJJYwkyeeptDSRpOEkeaPitpf6k6RKlmVne\n",
       "muFhjplZn3KiNDOrwInSzKwCJ0ozswqcKM3MKnCi7EckLZM0S9IcSdfVMxRS0o/TjulIukxl1kiW\n",
       "1CZptxpiPClpRLXHu5zTq+4skiZIOqW3dTQDJ8r+5q2IGBMR25OMXvpC6Zu9nAkp0o2I+HyUn1Z/\n",
       "L5Lpz3qrp75p1fRZ622/NveDs5o5UfZfM4EPpq29mZJ+CTyUTrLwP5LukfSgpGMh6SAu6XuS5kma\n",
       "RslYZknT05EpSBon6X5JsyVNk7QpyWipk9LW7EclvU/S9WmMeyTtnn52XUlTJT0k6TJ6XMv+XZJu\n",
       "lHRf+pnPd3nvwvT4b5XOuiTpA5JuTT/TIWmrxvxx2kBW+LHe1ntpy3E/4Jb00Bhg24h4Kk2MiyJi\n",
       "53RI452SppKMX94S2JpkHPhc4Efp54NkZpv3AT8E9kzLWjsiFkn6AfB6RFyYxr8auCgi/qBkWYPb\n",
       "gG1Ixkx3RMQkSfuRzGhUydERsTC9jXCPpOvTWXCGA/dGxMmSvpGWfUJav+Mi4nFJu5BMjLx3jX+U\n",
       "ZoATZX8zVNKs9HUHMJlkfPw9EdE5ocO+wPZ6d5Lbzvk+9wSuTocczpf0O95LJPNZdnSWFRGLurzf\n",
       "aR9ga707BeUa6VC5PYGD08/eImlhFd/pRCXLMQBsnNb1HmA5yaxOAFeSrDUznOQWwM9LYnupA6ub\n",
       "E2X/sjgixpQeSBPGm13O+3JETOty3n5UvhSu9j6fgF3S+US71qXqCXwltZO0BndNZ5H6PcmkFN3F\n",
       "C5JbSQu7/hmY1cv3KAee24HjOx/sSNpSyVIYHcCh6T3M0SQPaEoFyezsrZI2Sz/b+WT6ddIZ2lNT\n",
       "ga907kjaIX3ZARyWHvsYyUS75axJkvjeVjK93q4l77UAn0xfHwbMTOf2/Ftnazm975rJnKU2sDhR\n",
       "9i/dtfiiy/HLSe4/PiBpDnApySJqN5LMGzmXZCmHu1YqKJnQ+FiSy9zZJMswQLJo2cGdD3NIkuQ/\n",
       "pQ+LHiZ52APwTZJE+xDJJfhTdK+zvrcBgyXNBb4F3F1yzpsky03MIZlmbWJ6/DPAMWn9HgIOrPDn\n",
       "Y1aRZw8yM6vALUozswqcKM3MKnCiNDOrwInSzKwCJ0ozswqcKM3MKnCiNDOrwInSzKyC/wewavl1\n",
       "phWzdwAAAABJRU5ErkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ac790d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix of SVC on Plan1\n",
    "# 새로운 200개의 이미지를 test 데이터로 만들자.\n",
    "p = \"./data_test\"\n",
    "md5list = glob(os.path.join(p, \"*.png\"))\n",
    "md5list = [os.path.split(fname)[1] for fname in md5list]\n",
    "print \"the number of files is %s\" %len(md5list)\n",
    "\n",
    "features = []\n",
    "lables = []\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# captcha를 preprossing후 mnist처럼 numpy array로 만들자\n",
    "for fname in md5list:\n",
    "    lable = os.path.split(fname)[1].split(\"_\")[1][:5]\n",
    "    im = io.imread(os.path.join(p, fname))\n",
    "    w, h, _ = im.shape\n",
    "\n",
    "    for x in range(w):\n",
    "        for j in range(h):\n",
    "\n",
    "            if im[x][j][0] == im[x][j][1] and im[x][j][1] == im[x][j][2] and im[x][j][2] == im[x][j][0]:\n",
    "                im[x][j][0] = 255\n",
    "                im[x][j][1] = 255\n",
    "                im[x][j][2] = 255\n",
    "\n",
    "    im_gray = rgb2gray(im)\n",
    "    im_gray = img_as_ubyte(im_gray)\n",
    "    im_gray = morphology.opening(im_gray, square(2))\n",
    "    im_gray_equalize = exposure.equalize_hist(im_gray)\n",
    "\n",
    "    threshold = filters.threshold_otsu(im_gray_equalize).copy()\n",
    "    threshold = im_gray_equalize < threshold\n",
    "    threshold = img_as_ubyte(threshold)\n",
    "\n",
    "    bw = morphology.closing(im_gray_equalize < threshold, square(3))\n",
    "    cleared = bw.copy()\n",
    "\n",
    "    im_th = cleared\n",
    "    ctrs, hier = cv2.findContours(img_as_ubyte(im_th.copy()), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "    rects = sorted(rects, key=lambda tup: tup[0])\n",
    "\n",
    "    if len(rects) != 5:\n",
    "        continue\n",
    "\n",
    "\n",
    "    for rect, l in zip(rects, lable):\n",
    "        # Draw the rectangles\n",
    "        cv2.rectangle(threshold, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 1) \n",
    "\n",
    "        # Make the rectangular region around the digit\n",
    "        roi = threshold[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "        roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        roi = morphology.closing(roi, square(4))\n",
    "        \n",
    "        features.append(roi.ravel())\n",
    "        lables.append([l])\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(lables, 'int').ravel()\n",
    "\n",
    "# features, lables의 차원을 출력\n",
    "print features.shape\n",
    "print labels.shape\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "list_hog_fd = []\n",
    "for feature in features:\n",
    "    fd = hog(feature.reshape((28, 28)), orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "clf = joblib.load(\"./pkl/hog/skt/digits_SVC.pkl\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(labels, clf.predict(hog_features))\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, labels=labels)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "# cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "# print('Normalized confusion matrix')\n",
    "# print(cm_normalized)\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of files is 200\n",
      "(1000, 784)\n",
      "(1000,)\n",
      "escape time :  13.174 s\n",
      "escape time :  0.874 s\n",
      "Confusion matrix, without normalization\n",
      "[[ 96   0   0   0   0   0   0   4   3]\n",
      " [  0  80   0   0   2   0   0  48   0]\n",
      " [  0   0 103  17   1   1   0   4   6]\n",
      " [  0   0   0  76   1  12   0   3   2]\n",
      " [  0   4   2   0 124   0   1   2   1]\n",
      " [  8   0   2   5   1  83   0   2   8]\n",
      " [ 25   0   2   0   2   4   1   3  20]\n",
      " [  1   1   0   0   0   2   0 143   1]\n",
      " [ 44   0   0   0   0  17  10   3  19]]\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAUoAAAEpCAYAAAD1SWvxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHHWd//HXexJCSLiJhCCnyH0myk0OFhYjy6ErioEf\n",
       "ILCKosgCusCiEMKhsAvoouBDMBCVQ0RAUY5ENAf3lUAgBATlCCThSsIRYq7P74+qCc1kprunu6um\n",
       "eub95FEPuquqv59vJ5nPfKvqeygiMDOzjrV0dQXMzIrOidLMrAInSjOzCpwozcwqcKI0M6vAidLM\n",
       "rAInyh5E0mqSbpc0X9Jv6ijnSEl3N7JuXUXSUEkzu7oeVmxyP8rikXQEcCqwNfAuMA24ICLuq7Pc\n",
       "o4BvAXtGxPK6K1pwkpYDn4yIv3d1Xay5uUVZMJJOBS4DzgfWBzYGfgoc0oDiNwWe6wlJsoQ6PCD1\n",
       "zrMi1sQiwltBNmAtkhbkF8qcsyrwI+DVdLsM6JMeGwHMImmNzgVeA76SHjsX+CewOI1xHDAa+FVJ\n",
       "2ZsBy4GW9P1XgBeAd4C/A0eU7J9S8rm9gEeA+cDDJC3W1mMTgTHAvWk5dwPrdfDdWuv/XeD1tP6f\n",
       "Aw4EngPeAs4oOX834AFgXnru5cAq6bHJ6Xd5L/2+Xywp/7+A2cC4dN8r6We2SGMMTt9vCLwBDOvq\n",
       "fxveunZzi7JY9gT6AreWOecskgSxc7rtBnyv5PhAYE2SH/LjgZ9KWisizgEuBG6MiDUiYizQ4X0X\n",
       "Sf2BHwMjI2LNtG7T2jlvXeBPJMl7XeBS4E+S1ik5bRRJcl0f6AN8p8z3G0jyy2AQcDZwNXAkMBgY\n",
       "CpwtadP03KXAycB6af32A04EiIhh6Tk7pd/3tyXlrwNsApxQGjgiXgBOB34taTXgGuCaiJhcpr7W\n",
       "AzhRFst6wJtR/tL4CGBMRLwZEW+StBSPKjm+JD2+LCLuJGlRbZ0eEx+9FO3wsjS1HNhR0moRMTci\n",
       "ZrRzzr8Bz0bEdRGxPCJuBGby4a2CIEk2z0fEIuAmYJcyMZeQ3I9dBvyGJPn+KCLeT+PPaP18RDwe\n",
       "EQ+ncV8Cfg4Mr+I7nRMRS9L6fEREXA08T9IyHkjyi8l6OCfKYnkLGCCp3N/LhsBLJe9fTvetKKNN\n",
       "ol0IrN7ZikTE+8DhwNeB1yT9UdLW7Zy6YVqHUi+1qdOcktcfVKjPWxERJedCchuh9PP9ASRtldZr\n",
       "tqQFwAUkv2zKeSMiFlc452pge+DyiFhS4VzrAZwoi+UBkvuIny9zzmsk9xJbbZLuq8V7QL+S9xuU\n",
       "HoyI8RFxQLp/JnBVO2W8SvKQqNSm6f6sXUnSwvxkRKxF0vqr9G+6bDcPSauT3Ea4Gji3zS0E66Gc\n",
       "KAskIhaQ3Jf7qaRDJfWTtIqkz0q6KD3tBuB7kgZIGpCe/6saQ04DhknaWNJawJmtByStn9ahP8nl\n",
       "8PvAsnbKuBPYStIoSb0lHQ5sA/yx5JxKl/i1Wp3kQc1CSdsA32hzfC7JA5rO+DHwcER8jeTe68/q\n",
       "rqU1PSfKgomIS0meWn+P5MnvyyQPKFof8JwPPAo8mW6PpvtWFFGu+NLjEfFnkvuAT5I8tb695HgL\n",
       "cApJy/Atkgcp32hbTkS8BRwEnAa8SfKg5qCIeLuDOgWV61jufanvkNyzfYfk/uSNbc4fDYyTNE/S\n",
       "YWViB4CkQ4ED+PB7ngoMkTSqTB2sB3CHczOzCtyiNDOrwInSzKwCJ0ozswqcKM3MKujSSQEk+UmS\n",
       "WZOKiIZ1+6olFzQyfiVdPnvKrhf8tdOfefWea/n4fl/p1Gcm/9eITsc5f8xovnf26E5/rhZ5xfJ3\n",
       "6ppYi5d2bsKmH5x/Lmd+75xOx2mpIXVceN65/Pf3Oxdrjb69Oh+ogr6DT6r63EVTL294/HK6PFGa\n",
       "mQGg3BqIneZEaWbFUHaKg67VlIlyjc3LTT7TOMOGj8glTp6x/J2aI9Y+wypNgtQ4Q3OMVVaBW5Rd\n",
       "OjJHUtRyj7IWtdyjNGuUzt6jrFUt9yhrsUbfXg1/mNN319OqPn/RI5f0rIc5ZmZAoVuUTpRmVgwF\n",
       "vkeZac0kjZQ0U9LfJJ2eZSwza3JS9VvOMkuUknoBPwFGAtsBoyRtm1U8M2tyaql+a/tRaaykuZKm\n",
       "l+w7T9ITkqZJukfSxun+zSR9IGlqul1RqWpZtih3A56PiBfT6fRvBA7NMJ6ZNbOWXtVvK7uGpFFW\n",
       "6uKI2DkidgFuA0p71T8fEYPT7cSKVav5S1X2ceCVkvez0n1mZiur49I7IqaQLFtcuu/dkrerk0ws\n",
       "XZMsH+Z4HLeZVS+DhzmSLiBZpXQhsEfJoc0lTQUWAN+LiHvLlZNlonwV2Ljk/cYkrcqPnnTPtSte\n",
       "r7H5Lqz5iXw6k5tZ9aZMmsiUyZOyDVImUS6b/w+Wz3+x00VGxFnAWZLOAC4DjiVZjG/jiJgnaQhw\n",
       "m6Tt27RAP1q1rDqcS+oNPEuyKP1rJOskj4qIZ0rOcYdz6xHc4bw8SdF3xJiqz1808eyV4kvaDLg9\n",
       "InZsp/xNgDsiYod2jv0VOC0iHu8oXmb3KCNiKfAt4G6SJUV/U5okzcw+oo6n3u0WJ21Z8vZQYGq6\n",
       "f0DaKwdJnwC2BP5erqxMO5xHxJ0ky5mamZVXR/9ISTcAw4EBkl4hecJ9oKStSZZZfoEPV9ccBoyR\n",
       "tARYDpwQEfPLle+ROWZWDHU8zImI9pYUHtvBubcAt3SmfCdKMysGj/U2M6ugwGO9nSjNrBjcojQz\n",
       "q8AtSjOzCtyiNDOroP3JLgrBidLMisGX3mZmFThRdiyvMdhfuW5qLnGuPXJwLnHytmx5PpNB9cpr\n",
       "sHLOxs+ck0ucg3bYMJc4mfA9SjOzCtyiNDOrwC1KM7MK3KI0M6vALUozs/LkRGlmVp4TpZlZJcXN\n",
       "k5kuV2tmVjVJVW/tfHaspLmSppfs+x9Jz0h6QtItktYqOXampL9JminpgEp1yzRRtld5M7P21JMo\n",
       "gWuAkW32jQe2j4idgeeAM9M42wGHA9uln7lCKv/IPesWZXuVNzNbST2JMiKmAPPa7JsQEa3LXz4E\n",
       "bJS+PhS4ISKWRMSLwPPAbuXqlmmibK/yZmbtUYuq3mpwHHBH+npDYFbJsVnAx8t92A9zzKwQyj31\n",
       "Xjr3GZbOrW21a0lnAYsj4voyp5WdzKDLE+X5Y0aveD1s+AiGDR/RZXUxs/ZNnjSRyZMmZhqjXKJc\n",
       "ZYPtWGWD7Va8/+dTt1Zb5leAA4H9Sna/Cmxc8n6jdF+HujxRfu/s0V1dBTOroG0j5oLzzm14jEb3\n",
       "o5Q0EvguMDwiFpUc+gNwvaRLSS65twQeLldWlydKMzOoL1FKugEYDgyQ9ApwDslT7j7AhLTsByLi\n",
       "xIiYIekmYAawFDgxIrru0ruk8uullT87Iq7JMqaZNak6GpQRMaqd3WPLnH8hcGG15WeaKDuovJnZ\n",
       "SjyE0cysAidKM7MKnCjNzCopbp50ojSzYnCL0sysAidKM7MKnCjNzCqocbKLXDhRmlkhuEVZANce\n",
       "OTiXOIO/f3cucQDuPG14brEGrrVqLnEqjCRrqDx/MA/YZoNc4ixavCyXOFlwojQzq8CJ0syskuLm\n",
       "SSdKMysGtyjNzCpwojQzq8CJ0sysgiInyqyXqzUzq446sbX9qDRW0lxJ00v2rStpgqTnJI2XtHa6\n",
       "fzNJH0iamm5XVKqaE6WZFUI963oD1wAj2+w7A5gQEVsB96TvWz0fEYPT7cRKdcs0UUraWNJfJT0t\n",
       "6SlJ384ynpk1r3oSZURMAea12X0IMC59PQ74XK11y7pFuQQ4JSK2B/YAvilp24xjmlkTkqrfqjQw\n",
       "Iuamr+cCA0uObZ5edk+UtE+lgrJeM2cOMCd9/Z6kZ4ANgdpWMjezbqulzKQYC19+kg9eebLmsiMi\n",
       "JLWOj30N2Dgi5kkaAtwmafuIeLejz+f21FvSZsBg4KG8YppZ8yj31Lv/pjvTf9OdV7x/+/7rqily\n",
       "rqQNImKOpEHA6wARsRhYnL5+XNILJGt7P95RQbk8zJG0OnAzcHJEvJdHTDNrLhlcev8BOCZ9fQxw\n",
       "WxJHAyT1Sl9/giRJ/r1cQZm3KCWtAvwO+HVE3Nb2+PljRq94PWz4CIYNH5F1lcysk+6dPJF7p0zK\n",
       "NEa5S+9KJN0ADAcGSHoFOBv4IXCTpOOBF4EvpacPA8ZIWgIsB06IiPlly89yWislbelxwFsRcUo7\n",
       "x+ODJflNq5UHT7PWPPLs4Lx46fJc4ixfns/P0zr9exMRDfsDlBTb/Xf1PzszLvxMQ+NXkvWl997A\n",
       "/wP2Lenc2bavk5lZvf0oM5X1U+97cad2M6tCgUcweqy3mRVDkcd6O1GaWSE4UZqZVVDgPOlEaWbF\n",
       "4BalmVkFBc6TTpRmVgxuUZqZVVDgPOlEaWbFUM8Qxqw5UZpZIfjSuweZet5ncov1jd/WPj9fZ11x\n",
       "2I65xJm/cEkucQDW6d8nt1h5NZZ69W7egXAFzpNOlGZWDG5RmplVUOA86URpZsXgFqWZWQUFzpOe\n",
       "As3MiqHe+SglnSxpero09snpvnUlTZD0nKTxktaupW5OlGZWCPUkSkk7AP8B7ArsDBwkaQvgDGBC\n",
       "RGwF3JO+7zQnSjMrhDoXF9sGeCgiFkXEMmAS8AXgEJLlaEj//7la6uZEaWaFUOel91PA0PRSux9w\n",
       "ILARMDAi5qbnzAUG1lK3TB/mSOpLktlXBfoAv4+IM7OMaWbNqdzDnHl/e5z5z0/t8HhEzJR0ETAe\n",
       "eB+YBixrc05Iqmn1tazXzFkkad+IWCipN3CvpH3StXTMzFYo1z1o3a0+xbpbfWrF+5fuHrvSOREx\n",
       "FhiblnUBMAuYK2mDiJgjaRDwei11y/zSOyIWpi/7AL2At7OOaWbNp1eLqt7aI2n99P+bAP8OXA/8\n",
       "ATgmPeUY4LZa6pZ5P0pJLcDjwBbAlRExI+uYZtZ8GtCP8mZJ6wFLgBMjYoGkHwI3SToeeBH4Ui0F\n",
       "Z54oI2I5sIuktYC7JY2IiImtx88fM3rFucOGj2DY8BFZV8nMOmnypIlMmTwx0xj1jsyJiGHt7Hsb\n",
       "2L+uggFF1HRvs7Zg0veBDyLif9P38cGS/OJ3N549qD55zh60dNnyXOLkNQxw9VVbiIiGBZMUI694\n",
       "sOrz7zpxj4bGryTTe5SSBrT2hJe0GvCvQMePrsysx6p3ZE6Wsr70HgSMS+9TtgC/ioh7Mo5pZk2o\n",
       "yGO9O0yUki4v87mIiG9XKjwipgNDaqmYmfUsoriZslyL8jGg9QZi6zeI9LVvLJpZQxV4yZyOE2VE\n",
       "XFv6XlL/iHg/8xqZWY9U5PkoKz7MkbSXpBnAzPT9LpKuyLxmZtaj1DkpRqaqeer9I2Ak8CZAREwD\n",
       "hmdZKTPreVqkqre8VfXUOyJebtMsXppNdcyspyrwlXdVifJlSXsDSOoDfBt4JtNamVmP09T3KIFv\n",
       "AN8EPg68CgxO35uZNUyR71FWbFFGxBvAETnUxcx6sF4FblFWTJTpuhM/AvYk6T95P3BKRPw947o1\n",
       "1OKl+Yy17WgKqCxc+cWdcou17pdXnv8vC2/feFwucQBynucglzhF7otYSbNfel8P3EQyHHFD4LfA\n",
       "DVlWysx6nhZVv+VetyrOWS0ifhURS9Lt10DfrCtmZj1LU06KIWldkuGKd0o6kw9bkYcDd+ZQNzPr\n",
       "QQp85V32HuXjfHRM99fS/7eO9a5pfVwzs/bU01KUtDVwY8muTwBnA+uQrPf9Rrr/zIi4q7Pllxvr\n",
       "vVlnCzMzq1U99x4j4lmSrouty8+8CtwCHAdcGhGX1lO3qkbmSNoB2I6Se5MR8ct6ApuZlWrgvcf9\n",
       "gecj4hUlhdZdcDWTYowGLgd+AuwLXAwcUm9gM7NS6sRWwZf58JlKACdJekLSL1pXXOisalqUhwE7\n",
       "A49HxLGSBgLX1RLMzKwj5Sa7mP30I8ye8UjFMtJh1gcDp6e7rgTGpK/PAy4Bju9s3apJlB9ExDJJ\n",
       "S9OVFF8HNq42gKRewKPArIg4uLMVNLOeodyV94Y77MqGO+y64v3U313Z0amfBR5LRxQSEa9/WL6u\n",
       "Bm6vpW7VJMpHJK0DXEWS8N4nGZ1TrZOBGcAana+emfUUDbpHOYqSATGSBkXE7PTt54HptRRazVjv\n",
       "E9OXP5N0N7BmRDxRTeGSNgIOBC4ATq2lgmbWM9SbJyX1J3mQ89WS3RdJ2oXkXuU/gBNqKbtch/NP\n",
       "0cHaOJKGRMTjVZR/GfBdYM1aKmdmPUe98ySkS9UMaLPv6LoKTZVrUV5C+UXE9i1XsKSDgNcjYqqk\n",
       "ETXUzcx6kCJPilGuw/mIOsveCzhE0oEk/S/XlPTLthn+/DGjV7weNnwEw4bXG9bMGm3ypIlMnjQx\n",
       "0xjVTDzRVZTHVFOShgPfafvUW1J8sCSfqa664zRrecbyNGv1WZ5TqLz+SfTr00JENCyapDjp1uoX\n",
       "Trj889s2NH4lVY3MaRCvBW5mHSryXJq5JMqImARMyiOWmTWnIifKaoYwtkg6StLZ6ftNJO2WfdXM\n",
       "rCcp8nyU1dw/vYJkGYjWdXPeS/eZmTVMkWc4r+bSe/eIGCxpKkBEvC1plYzrZWY9TIF7B1WVKBen\n",
       "47UBkPQxIJ9HyGbWY5SbFKOrVXPpfTlwK7C+pAuB+4AfZForM+txWjqx5a2asd6/lvQYsF+669CI\n",
       "qL7Dk5lZFQrcoKxqXe9NSGYMap2eKCRtEhEvZ1ozM+tRinzpXc09yjv4sLN4X2Bz4Flg+6wqZWY9\n",
       "T4HzZFWX3juUvpc0BPhmZjUysx6pd4F7nHd6ZE5EPC5p90ZV4P1FSxtVVFn9++YzWnNZXoN6gX8u\n",
       "WZZbrLduODaXOKOufTSXOAA3fOXTucUip3HlC/+Z37+JRmvqFqWk00retgBDSJaCNDNrmAI3KKt6\n",
       "0r56ydYH+CNwaJaVMrOeR534r93PS2tLulnSM5JmSNpd0rqSJkh6TtL4TFZhTDuarxkRp5U7z8ys\n",
       "Xg1oUf4YuCMiDpPUG+gPnAVMiIiLJZ0OnJFunatbRwck9Y6IZcDeKvLUw2bWLdQz1jtdIXZoRIwF\n",
       "iIilEbEAOAQYl542DvhcLXUr16J8mOR+5DTg95J+CyxMj0VE3FJLQDOz9tTZHtsceEPSNcDOwGPA\n",
       "fwIDI2Jues5cYGAthZdLlK217gu8BfxLm+NOlGbWMOUuvZ+f+iAvTHuo3Md7kzTsvhURj0j6EW0u\n",
       "sSMiJNXU/aBcovyYpFOpcR1cM7POKNeg3HLIHmw5ZI8V7yeM+7+2p8wCZkXEI+n7m4EzgTmSNoiI\n",
       "OZIGAa/XUrdyT717AWvw0afepZuZWcO0SFVvbUXEHOAVSVulu/YHniYZen1Muu8Y4LZa6lauRTkn\n",
       "Is6tpdBSkl4E3gGWAUsiwrOjm9lKGvDU+yTgOkl9gBeAY0kafDdJOh54EfhSLQXnMVwlgBER8XYO\n",
       "scysSdXbtyYingB2befQ/vWVXD5R1l14CXcvMrOyWgqcJjq8RxkRbzUoRgB/lvSopK82qEwz62Z6\n",
       "tVS/5S2PS++9I2J2uoTEBEkzI2JK68GLLhzz4YlDh7PP0OE5VMnMOuPeKZO4b0q2K04XeT5KRU6z\n",
       "mgBIOgd4LyIuSd/Hm+8uySV2d5w9aOmy/JYu6tM7n1/jR4x7LJc4kO/sQXn9u1i0OJ/ZgwassQoR\n",
       "0bDMJil+/uCLVZ//tT02a2j8SjL91y+pn6Q10tf9gQNwv0wza0c93YOylnUzayBwazo0qTdwXUSM\n",
       "zzimmTWhAl95Z5soI+IfwC5ZxjCz7qErVlesVj437szMKijyJGVOlGZWCMVNk06UZlYQRe4e5ERp\n",
       "ZoVQ3DTpRGlmBVHgBqUTpZkVgx/mmJlV4O5BZmYVuEVZxpwFi3KJs0Xf7jcp+6qr9MotVl5jlcf9\n",
       "vyG5xAHIc56DvGLNW5jP3AlZaMRT73SJ7UdJloU4WNJo4D+AN9JTzoyIuzpbbpcnSjMzaNil98nA\n",
       "DJJlbCCZ5vHSiLi0nkKLfFvAzHoQSVVvHXx+I+BA4Go+7G0kGtDzyInSzApBndg6cBnwXaB0/sEA\n",
       "TpL0hKRfSFq7lro5UZpZIUjVbyt/VgcBr0fEVD6aS68ENieZnGc2cEktdfM9SjMrhHJr5kx/5D6m\n",
       "P3J/uY/vBRwi6UCgL7CmpF9GxNGtJ0i6mmT52k7LdYbzlYJL8dSsd3OJtcXAfJ565znDea8GrO9Z\n",
       "rby+V55/fqv06n5/fnMW/DOXOFsO7NfwGc5vnz6n6vMP3nGDDuNLGg58J33qPSgiZqf7TwF2jYgj\n",
       "Ols/tyjNrBDUuNHeIrk3CXCxpJ3T9/8ATqilQCdKMyuERvU3j4iJwMT09VGNKDPrNXPWlnSzpGck\n",
       "zZC0R5bxzKx5taCqt7xl3aL8MXBHRBwmqTfQP+N4ZtakCjyCMbtEKWktYGhEHAMQEUuBBVnFM7Pm\n",
       "VuREmeWl9+bAG5KukfS4pKsk9cswnpk1MXXiv7xlmSh7A0OAKyJiCPA+cEaG8cysifWSqt7yluU9\n",
       "ylkkM3g8kr6/mXYS5U8vuXDF6133HMpuew3NsEpmVouH7pvMQ/dPzjRGkS+9M+1wLmky8B8R8Vw6\n",
       "3dFqEXF6yXF3OK+DO5zXxx3Oa5dFh/O/znyr6vP33Wa9hsavJOun3icB10nqA7wAHJtxPDNrUjn+\n",
       "3u+0TBNlRDwB7JplDDPrHrriIU21PDLHzAqhyPconSjNrBAKnCedKM2sGBqxZk5WnCjNrBCKmyad\n",
       "KM2sKAqcKZ0ozawQ/NTbzKyCAt+i9OJiZlYM9azCKKmvpIckTUvnvv1Bun9dSRMkPSdpvFdhNLOm\n",
       "Vs+63hGxCNg3InYBdgL2lbQPyfwSEyJiK+AeapyYp8svvT+xfj5z+ea1iFqe46/z1B2/V3s/cFn5\n",
       "2B4n5RLn7YcvzyVOFur964iIhenLPkAvYB5wCDA83T+OZImITidLtyjNrBDqufQGkNQiaRowF/hr\n",
       "RDwNDIyIuekpc4GBtdSty1uUZmZA3d2DImI5sEu6usLdkvZtczwk1XRp6URpZoVQrnvQow9M4dEH\n",
       "p1RVTkQskPQn4FPAXEkbRMQcSYOA12uqW1737toNLsXCxcu7LH4W8rzv1R111/k819n1W7nEyese\n",
       "Zb8+LQ2fj3LqS+9Uff7gTdf8SHxJA4ClETFf0mrA3cC5wGeAtyLiIklnAGtHRKfvUbpFaWaFUGfW\n",
       "HQSMk9RC8uzlVxFxj6SpwE2SjgdeBL5US+FOlGZWDHVkyoiYTrJGV9v9bwP7115ywonSzArBQxjN\n",
       "zCoo8u39TPtRStpa0tSSbYGkb2cZ08yaU739KLOU9Zo5zwKDIekMCrwK3JplTDNrUgVuUeZ56b0/\n",
       "8EJEvJJjTDNrEr5HmfgycH2O8cysiRT5HmUuiTJd1/tg4PS2x84fM3rF62HDRzBs+Ig8qmRmnTB5\n",
       "0kQmT5qYaYwiJ8pcRuZIOhT4RkSMbLPfI3PsIzwypz7NPDLnmdfer/r8bTfs39D4leR16T0KuCGn\n",
       "WGbWhIrcxsh8mjVJ/Uke5NySdSwza149tnsQQES8DwzIOo6ZNbkCtyg9MsfMCsHdg8zMKijyPUon\n",
       "SjMrhALnSSdKMyuIAmdKJ0ozK4Qi36P0KoxmVghS9dvKn9VYSXMlTS/ZN1rSrJLZy0au/MnqOFGa\n",
       "WSHU2Y/yGqBtIgzg0ogYnG531Vo3J0ozK4Y6MmVETAHmdVBq3br8HuVfnq1p9chO22+bmtY9t5y9\n",
       "8c4/c4vVb9VeucV648H/yyXOa/MW5RInCy3Z9A86SdLRwKPAaRExv5ZC3KI0s0LIYAjjlcDmwC7A\n",
       "bOCSWuvW5S1KMzMo3+H8gXsn8cC9kztVXkSsuFyVdDVwe611c6I0s4LoOFPuuc8I9txnxIr3l118\n",
       "QeXSpEERMTt9+3lgernzy3GiNLNCqOcWpaQbgOHAAEmvAOcAIyTtQvL0+x/ACbWW70RpZoVQz6Oc\n",
       "iBjVzu6xdRT5EU6UZlYInhTDzKyCIg9hdKI0s2Iobp7Mth+lpDMlPS1puqTrJa2aZTwza15FXgoi\n",
       "s0QpaTPgq8CQiNgR6EWytreZ2UrqmRQja1leer8DLAH6SVoG9ANezTCemTWxIt+jzKxFGRFvkwwZ\n",
       "ehl4DZgfEX/OKp6ZNbkCX3tneem9BfCfwGbAhsDqko7MKp6ZNbcC58lML70/DdwfEW8BSLoF2Au4\n",
       "rvSk6674nxWvd9x1L3bade8Mq2RmtXjwvsk8dH/nxlp3VkazBzWEIiKbgqWdSZLirsAi4Frg4Yj4\n",
       "ack58cfpczKJ35anWWsOc+bnN01YntOs9euTT6y5C/KZpu6TA/sREQ3LbJLi7feXVn3+uv17NzR+\n",
       "JVneo3wC+CXJPHBPprt/nlU8M7OsZNrhPCIuBi7OMoaZdQ8FvvL2yBwzK4Yidw9yojSzQnCL0sys\n",
       "ggLnSSdKMyuIAmdKLy5mZoWgTvzX7uelkZJmSvqbpNMbWbemTJRPPnJfLnEmT5qYS5w8Y3XH7/Tg\n",
       "fdl2hC5135RJucSZkuPfU55/fuXUMymGpF7AT4CRwHbAKEnbNqpuTZkopz9yfy5xumNS6Y7fKc8f\n",
       "9PvzSpST84kDZD7iplp1DmHcDXg+Il6MiCXAjcChjapbUyZKM+uG6suUHwdeKXk/K93XEH6YY2aF\n",
       "UGc/ymzGYqcyG+tdVXCp64KbWV0aPda7nviS9gBGR8TI9P2ZwPKIuKgh9evKRGlm1giSegPPAvuR\n",
       "zH/7MDAqIp5pRPm+9DazphcRSyV9C7ibZNmZXzQqSYJblGaFImlQRMzu6nrYR/mpdzvSPllZx/ik\n",
       "pE97ZcraSDpY0n/mFKu/lP1IZEmfAW6RtEnWsaxzmiJRStpa0p6SVskyiUnaCiAilmUc52DgFuB/\n",
       "gXGtcTOMt5Ok/SVtkHGcfSQdlWWMNM4BwHnAjBxifQ64CFg/y2SZJsmLgEHAd7KKk8baU9JR6f/7\n",
       "ZBmr24iIQm/AF0hu0t4D/Ao4GVgrgzgHAx8AN5Ts65VBnL2AZ0iW8QW4Argmwz+/A4GngT8AtwNr\n",
       "ZBBDwBppnGeAr5cey+DP73Vgt/T92sCmQL8MvtcIYCZwQFZ/P2mc/YHnge2BPsB4YFhGsQ4lmUj7\n",
       "l8DvgK3V52LsAAAHLklEQVSy/G7dZSt0izL9bXc4cHxE7Af8HtgI+C9JazUwTj/gmySLoS2W9GtY\n",
       "0bJs9AMvARdHxOPp+9HAupL6NjgOkvYFfgQcFxGHAEuB3RsdKxLvkvzwXQ3sJemU1mONjAW8TbIM\n",
       "8iBJA4BbgZ+RtMwPa3CsIcDVETFe0oaS/lXS7o38t5fqBRwdEU8D/UkaBtsDNLIVK2kgSUPjyIg4\n",
       "GlgA7CxpfUmrNSpOd1ToRJlaE9gyfX0r8EeS37pHSGpI/SNiIXAscD1wGrBaSbKsfiGP6jxIctnd\n",
       "2qWhD7AJSYuM9Ie/UeaStO4ekjQI2AM4lSSpfKlRQUp+mJeQfJdxwG6SLpX0Q6UaESsiZpK0ki8j\n",
       "aRndAPwbcCfwBUnrNSJOalnJ65uB44CTgCskrdOoIBFxd0TcL6klIuYBfwLOkbRTg3/RLAb6AltK\n",
       "WhvYFzia5JfpWZJWb2CsbqXQiTIiFpOsDf7vkoZGxDLgPmAasE+DY82OiHcj4k3gBJJkeR2ApE9J\n",
       "2qZBcZZFxIKSXQuAtyPijXQ53/Ma9ds9ImZExF/St8cDP42IA0mSyqGN+mEv+WH+AzAnIu4BHgO+\n",
       "QXKpH438gY9kPaaDgAsj4ucRsTwixgLrkCTqRvkL8DVJvwGuiohRwNnAeyRjixstJCki7gKuAg6S\n",
       "1NLABsE8kvvip5A0OMZGxMEkVwEbAZ9sRJzuqNCJMjWFpG/U0ZKGRcTSiLiOZK3wnbIIWJIsl0ia\n",
       "CfyG5Iej0XGWppessyT9gKS1d2VEfJBBrPMj4vz09bXAWjQ2qQAsBLaW9FXg68APgU0kndDgOETE\n",
       "DKB0Rc/DgPWBhnWtiYjpJFcYuwObp/v+TvJzs36j4pTEK/2FMo2kpdwSEcsbGOMW4LMkD8Jmpvv+\n",
       "QnLltmmj4nQ3he9wHhGL0pZdAP+dtuwW0+AfinbivinpCZJpm/41ImY1OkZ6OdoHGEryd7F/RDzX\n",
       "6DjtxP0CsAHQ0LWCI+I1SS8D3we+GRG3S/oX4G+NjFMSL9I/w2OB7wJfjIhGr398J3AOyaXwS+m+\n",
       "ISRPqDMTEb+T9GWSlt6LDS77PUlTSFqs7wCrApsBTzQyTnfSNB3O0wc7e5O09BYB/1fyQCSLeOsA\n",
       "vwVOjYgnK51fZ6xjSdY8fzrjOKsCR5Fceh0eEU9lEGNjYP2IeCx939AWUTvxRPJ0enZ6/zKrOJ8i\n",
       "6YHRl6SXwvQMYymDh2BtY6wNjAIOI+ntcVZ6S8Pa0TSJslX6ACTS+5VZx1o1IjJfUT6PH4w0zirA\n",
       "AcALWSaVNJYgk6fe1kCS+pPkgYbfWupOmi5RmpnlrRke5piZdSknSjOzCpwozcwqcKI0M6vAidLM\n",
       "rAInym5E0jJJUyVNl3RTPUMhJV2bdkxH0lUqs0aypOGS9qwhxouS1q12f5tzOtWdRdJoSad1to5m\n",
       "4ETZ3SyMiMERsSPJ6KWvlx7s5ExIkW5ExFej/LT6+5JMf9ZZHfVNq6bPWmf7tbkfnNXMibL7mgJ8\n",
       "Mm3tTZH0e+CpdJKF/5H0sKQnJH0Nkg7ikn4iaaakCZSMZZY0MR2ZgqSRkh6TNE3SBEmbkoyWOiVt\n",
       "ze4t6WOSbk5jPCxpr/Sz60kaL+kpSVfR4Vr2H5J0q6RH0898tc2xS9P9f1Y665KkLSTdmX5msqSt\n",
       "G/PHaT1Z4cd6W+elLccDgTvSXYOB7SPipTQxzo+I3dIhjfdKGk8yfnkrYFuSceAzgF+knw+SmW0+\n",
       "BvwcGJqWtXZEzJf0M+DdiLg0jX89cFlE3KdkWYO7gO1IxkxPjojzJR1IMqNRJcdFxLz0NsLDkm5O\n",
       "Z8HpDzwSEadK+n5a9klp/U6IiOcl7U4yMfJ+Nf5RmgFOlN3NapKmpq8nA2NJxsc/HBGtEzocAOyo\n",
       "Dye5bZ3vcyhwfTrkcLakv/BRIpnPcnJrWRExv83xVvsD2+rDKSjXSIfKDQU+n372DknzqvhOJytZ\n",
       "jgFg47SuDwPLSWZ1Avg1yVoz/UluAfy2JLaXOrC6OVF2Lx9ExODSHWnCeL/Ned+KiAltzjuQypfC\n",
       "1d7nE7B7Op9o27pUPYGvpBEkrcE90lmk/koyKUV78YLkVtK8tn8GZvXyPcqe527gxNYHO5K2UrIU\n",
       "xmTg8PQe5iCSBzSlgmR29mGSNks/2/pk+l3SGdpT44Fvt76RtHP6cjJwRLrvsyQT7ZazJkniW6Rk\n",
       "er09So61AF9MXx8BTEnn9vxHa2s5ve+ayZyl1rM4UXYv7bX4os3+q0nuPz4uaTpwJckiareSzBs5\n",
       "g2Qph/tXKiiZ0PhrJJe500iWYYBk0bLPtz7MIUmSn04fFj1N8rAH4FySRPsUySX4S7Svtb53Ab0l\n",
       "zQB+ADxQcs77JMtNTCeZZm1Muv9I4Pi0fk8Bh1T48zGryLMHmZlV4BalmVkFTpRmZhU4UZqZVeBE\n",
       "aWZWgROlmVkFTpRmZhU4UZqZVeBEaWZWwf8HWw/7gQYJh0wAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117847f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix of KNeighbors on Plan3\n",
    "\n",
    "# 새로운 200개의 이미지를 test 데이터로 만들자.\n",
    "p = \"./data_test\"\n",
    "md5list = glob(os.path.join(p, \"*.png\"))\n",
    "md5list = [os.path.split(fname)[1] for fname in md5list]\n",
    "print \"the number of files is %s\" %len(md5list)\n",
    "\n",
    "features = []\n",
    "lables = []\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "# captcha를 preprossing후 mnist처럼 numpy array로 만들자\n",
    "for fname in md5list:\n",
    "    lable = os.path.split(fname)[1].split(\"_\")[1][:5]\n",
    "    im = io.imread(os.path.join(p, fname))\n",
    "    w, h, _ = im.shape\n",
    "\n",
    "    for x in range(w):\n",
    "        for j in range(h):\n",
    "\n",
    "            if im[x][j][0] == im[x][j][1] and im[x][j][1] == im[x][j][2] and im[x][j][2] == im[x][j][0]:\n",
    "                im[x][j][0] = 255\n",
    "                im[x][j][1] = 255\n",
    "                im[x][j][2] = 255\n",
    "\n",
    "    im_gray = rgb2gray(im)\n",
    "    im_gray = img_as_ubyte(im_gray)\n",
    "    im_gray = morphology.opening(im_gray, square(2))\n",
    "    im_gray_equalize = exposure.equalize_hist(im_gray)\n",
    "\n",
    "    threshold = filters.threshold_otsu(im_gray_equalize).copy()\n",
    "    threshold = im_gray_equalize < threshold\n",
    "    threshold = img_as_ubyte(threshold)\n",
    "\n",
    "    bw = morphology.closing(im_gray_equalize < threshold, square(3))\n",
    "    cleared = bw.copy()\n",
    "\n",
    "    im_th = cleared\n",
    "    ctrs, hier = cv2.findContours(img_as_ubyte(im_th.copy()), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "    rects = sorted(rects, key=lambda tup: tup[0])\n",
    "\n",
    "    if len(rects) != 5:\n",
    "        continue\n",
    "\n",
    "\n",
    "    for rect, l in zip(rects, lable):\n",
    "        # Draw the rectangles\n",
    "        cv2.rectangle(threshold, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 1) \n",
    "\n",
    "        # Make the rectangular region around the digit\n",
    "        roi = threshold[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
    "        roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "        roi = morphology.closing(roi, square(4))\n",
    "        \n",
    "        features.append(roi.ravel())\n",
    "        lables.append([l])\n",
    "\n",
    "features = np.array(features, 'int16')\n",
    "labels = np.array(lables, 'int').ravel()\n",
    "\n",
    "# features, lables의 차원을 출력\n",
    "print features.shape\n",
    "print labels.shape\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "t0 = time()\n",
    "list_hog_fd = []\n",
    "for feature in features:\n",
    "    fd = hog(feature.reshape((28, 28)), orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1), visualise=False)\n",
    "    list_hog_fd.append(fd)\n",
    "hog_features = np.array(list_hog_fd, 'float64')\n",
    "print \"escape time : \", round(time()-t0, 3), \"s\"\n",
    "\n",
    "clf = joblib.load(\"./pkl/hog/mnist/digits_KNeighborsClassifier.pkl\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(labels, clf.predict(hog_features))\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
